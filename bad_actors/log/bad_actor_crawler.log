2019-01-24 16:23:07 - run.py - <module> - INFO - Start Execution ... 
2019-01-24 16:23:07 - run.py - <module> - INFO - SETUP global variables
2019-01-24 16:23:07 - run.py - <module> - INFO - CREATE pipeline
2019-01-24 16:23:07 - run.py - <module> - INFO - SETUP pipeline
2019-01-24 16:23:07 - run.py - <module> - INFO - setup module: <DB.schema_definition.DB instance at 0x0000000014B93488>
2019-01-24 16:23:07 - run.py - <module> - INFO - setup module: <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x000000000F3A6AC8>
2019-01-24 16:23:07 - run.py - <module> - INFO - checking module definition
2019-01-24 16:23:07 - run.py - <module> - INFO - module <DB.schema_definition.DB instance at 0x0000000014B93488> is well defined
2019-01-24 16:23:07 - run.py - <module> - INFO - module <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x000000000F3A6AC8> is well defined
2019-01-24 16:23:07 - run.py - <module> - INFO - execute module: <DB.schema_definition.DB instance at 0x0000000014B93488>
2019-01-24 16:23:07 - run.py - <module> - INFO - *********Started executing DB
2019-01-24 16:23:07 - run.py - <module> - INFO - *********Finished executing DB
2019-01-24 16:23:07 - run.py - <module> - INFO - execute module: <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x000000000F3A6AC8>
2019-01-24 16:23:07 - run.py - <module> - INFO - *********Started executing AddAuthorConnectionClaimId
2019-01-24 16:24:01 - run.py - <module> - INFO - *********Finished executing AddAuthorConnectionClaimId
2019-01-24 16:25:28 - run.py - <module> - INFO - Start Execution ... 
2019-01-24 16:25:28 - run.py - <module> - INFO - SETUP global variables
2019-01-24 16:25:28 - run.py - <module> - INFO - CREATE pipeline
2019-01-24 16:25:28 - run.py - <module> - INFO - SETUP pipeline
2019-01-24 16:25:28 - run.py - <module> - INFO - setup module: <DB.schema_definition.DB instance at 0x0000000014205488>
2019-01-24 16:25:28 - run.py - <module> - INFO - setup module: <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x000000000E6659B0>
2019-01-24 16:25:28 - run.py - <module> - INFO - checking module definition
2019-01-24 16:25:28 - run.py - <module> - INFO - module <DB.schema_definition.DB instance at 0x0000000014205488> is well defined
2019-01-24 16:25:28 - run.py - <module> - INFO - module <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x000000000E6659B0> is well defined
2019-01-24 16:25:28 - run.py - <module> - INFO - execute module: <DB.schema_definition.DB instance at 0x0000000014205488>
2019-01-24 16:25:28 - run.py - <module> - INFO - *********Started executing DB
2019-01-24 16:25:28 - run.py - <module> - INFO - *********Finished executing DB
2019-01-24 16:25:28 - run.py - <module> - INFO - execute module: <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x000000000E6659B0>
2019-01-24 16:25:28 - run.py - <module> - INFO - *********Started executing AddAuthorConnectionClaimId
2019-01-24 16:26:16 - run.py - <module> - INFO - *********Finished executing AddAuthorConnectionClaimId
2019-01-24 16:58:09 - run.py - <module> - INFO - Start Execution ... 
2019-01-24 16:58:09 - run.py - <module> - INFO - SETUP global variables
2019-01-24 16:58:09 - run.py - <module> - INFO - CREATE pipeline
2019-01-24 16:58:09 - run.py - <module> - INFO - SETUP pipeline
2019-01-24 16:58:09 - run.py - <module> - INFO - setup module: <DB.schema_definition.DB instance at 0x0000000013DDB208>
2019-01-24 16:58:09 - run.py - <module> - INFO - setup module: <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x000000000E1B9080>
2019-01-24 16:58:09 - run.py - <module> - INFO - setup module: <dataset_builder.feature_extractor.cooperation_topic_feature_generator.CooperationTopicFeatureGenerator object at 0x0000000013DD0908>
2019-01-24 16:58:09 - run.py - <module> - INFO - checking module definition
2019-01-24 16:58:09 - run.py - <module> - INFO - module <DB.schema_definition.DB instance at 0x0000000013DDB208> is well defined
2019-01-24 16:58:09 - run.py - <module> - INFO - module <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x000000000E1B9080> is well defined
2019-01-24 16:58:09 - run.py - <module> - INFO - module <dataset_builder.feature_extractor.cooperation_topic_feature_generator.CooperationTopicFeatureGenerator object at 0x0000000013DD0908> is well defined
2019-01-24 16:58:09 - run.py - <module> - INFO - execute module: <DB.schema_definition.DB instance at 0x0000000013DDB208>
2019-01-24 16:58:09 - run.py - <module> - INFO - *********Started executing DB
2019-01-24 16:58:09 - run.py - <module> - INFO - *********Finished executing DB
2019-01-24 16:58:09 - run.py - <module> - INFO - execute module: <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x000000000E1B9080>
2019-01-24 16:58:09 - run.py - <module> - INFO - *********Started executing AddAuthorConnectionClaimId
2019-01-24 16:58:53 - run.py - <module> - INFO - *********Finished executing AddAuthorConnectionClaimId
2019-01-24 16:58:53 - run.py - <module> - INFO - execute module: <dataset_builder.feature_extractor.cooperation_topic_feature_generator.CooperationTopicFeatureGenerator object at 0x0000000013DD0908>
2019-01-24 16:58:53 - run.py - <module> - INFO - *********Started executing CooperationTopicFeatureGenerator
2019-01-24 16:58:53 - cooperation_topic_feature_generator.py - execute - INFO - execute started for Cooperation topic feature generator started at 1548341933.7
2019-01-24 16:58:53 - run.py - <module> - ERROR - *********Failed in executing : CooperationTopicFeatureGenerator
Traceback (most recent call last):
  File "C:/Users/Developer_1/Documents/GitHub/measurement-of-online-discussion-authenticity/bad_actors/run.py", line 206, in <module>
    module.execute(window_start)
  File "C:\Users\Developer_1\Documents\GitHub\measurement-of-online-discussion-authenticity\bad_actors\dataset_builder\feature_extractor\cooperation_topic_feature_generator.py", line 66, in execute
    claims = self._db.get_claims()
  File "C:\Users\Developer_1\Documents\GitHub\measurement-of-online-discussion-authenticity\bad_actors\DB\schema_definition.py", line 1498, in get_claims
    return self.session.query(Claim).all()
  File "C:\Python27\lib\site-packages\sqlalchemy\orm\query.py", line 2836, in all
    return list(self)
  File "C:\Python27\lib\site-packages\sqlalchemy\orm\query.py", line 2988, in __iter__
    return self._execute_and_instances(context)
  File "C:\Python27\lib\site-packages\sqlalchemy\orm\query.py", line 3011, in _execute_and_instances
    result = conn.execute(querycontext.statement, self._params)
  File "C:\Python27\lib\site-packages\sqlalchemy\engine\base.py", line 948, in execute
    return meth(self, multiparams, params)
  File "C:\Python27\lib\site-packages\sqlalchemy\sql\elements.py", line 269, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "C:\Python27\lib\site-packages\sqlalchemy\engine\base.py", line 1060, in _execute_clauseelement
    compiled_sql, distilled_params
  File "C:\Python27\lib\site-packages\sqlalchemy\engine\base.py", line 1200, in _execute_context
    context)
  File "C:\Python27\lib\site-packages\sqlalchemy\engine\base.py", line 1413, in _handle_dbapi_exception
    exc_info
  File "C:\Python27\lib\site-packages\sqlalchemy\util\compat.py", line 265, in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
  File "C:\Python27\lib\site-packages\sqlalchemy\engine\base.py", line 1193, in _execute_context
    context)
  File "C:\Python27\lib\site-packages\sqlalchemy\engine\default.py", line 509, in do_execute
    cursor.execute(statement, parameters)
OperationalError: (sqlite3.OperationalError) no such column: claims.main_category [SQL: u'SELECT claims.claim_id AS claims_claim_id, claims.claim_topic AS claims_claim_topic, claims.claim_post_id AS claims_claim_post_id, claims.claim_ext_id AS claims_claim_ext_id, claims.title AS claims_title, claims.description AS claims_description, claims.main_category AS claims_main_category, claims.secondary_category AS claims_secondary_category, claims.url AS claims_url, claims.verdict_date AS claims_verdict_date, claims.keywords AS claims_keywords, claims.domain AS claims_domain, claims.verdict AS claims_verdict \nFROM claims'] (Background on this error at: http://sqlalche.me/e/e3q8)
2019-01-24 17:20:28 - run.py - <module> - INFO - Start Execution ... 
2019-01-24 17:20:28 - run.py - <module> - INFO - SETUP global variables
2019-01-24 17:20:28 - run.py - <module> - INFO - CREATE pipeline
2019-01-24 17:20:28 - run.py - <module> - INFO - SETUP pipeline
2019-01-24 17:20:28 - run.py - <module> - INFO - setup module: <DB.schema_definition.DB instance at 0x0000000014B303C8>
2019-01-24 17:20:28 - run.py - <module> - INFO - setup module: <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x000000000F3452E8>
2019-01-24 17:20:28 - run.py - <module> - INFO - setup module: <dataset_builder.feature_extractor.cooperation_topic_feature_generator.CooperationTopicFeatureGenerator object at 0x0000000014B2FC88>
2019-01-24 17:20:28 - run.py - <module> - INFO - checking module definition
2019-01-24 17:20:28 - run.py - <module> - INFO - module <DB.schema_definition.DB instance at 0x0000000014B303C8> is well defined
2019-01-24 17:20:28 - run.py - <module> - INFO - module <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x000000000F3452E8> is well defined
2019-01-24 17:20:28 - run.py - <module> - INFO - module <dataset_builder.feature_extractor.cooperation_topic_feature_generator.CooperationTopicFeatureGenerator object at 0x0000000014B2FC88> is well defined
2019-01-24 17:20:28 - run.py - <module> - INFO - execute module: <DB.schema_definition.DB instance at 0x0000000014B303C8>
2019-01-24 17:20:28 - run.py - <module> - INFO - *********Started executing DB
2019-01-24 17:20:28 - run.py - <module> - INFO - *********Finished executing DB
2019-01-24 17:20:28 - run.py - <module> - INFO - execute module: <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x000000000F3452E8>
2019-01-24 17:20:28 - run.py - <module> - INFO - *********Started executing AddAuthorConnectionClaimId
2019-01-24 17:21:19 - run.py - <module> - INFO - *********Finished executing AddAuthorConnectionClaimId
2019-01-24 17:21:19 - run.py - <module> - INFO - execute module: <dataset_builder.feature_extractor.cooperation_topic_feature_generator.CooperationTopicFeatureGenerator object at 0x0000000014B2FC88>
2019-01-24 17:21:19 - run.py - <module> - INFO - *********Started executing CooperationTopicFeatureGenerator
2019-01-24 17:21:19 - cooperation_topic_feature_generator.py - execute - INFO - execute started for Cooperation topic feature generator started at 1548343279.42
2019-01-27 09:43:51 - run.py - <module> - INFO - Start Execution ... 
2019-01-27 09:43:51 - run.py - <module> - INFO - SETUP global variables
2019-01-27 09:43:51 - run.py - <module> - INFO - CREATE pipeline
2019-01-27 09:43:51 - run.py - <module> - INFO - SETUP pipeline
2019-01-27 09:43:51 - run.py - <module> - INFO - setup module: <DB.schema_definition.DB instance at 0x00000000146FC648>
2019-01-27 09:43:51 - run.py - <module> - INFO - setup module: <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x000000000E8F2080>
2019-01-27 09:43:51 - run.py - <module> - INFO - setup module: <dataset_builder.feature_extractor.cooperation_topic_feature_generator.CooperationTopicFeatureGenerator object at 0x00000000146FEA58>
2019-01-27 09:43:51 - run.py - <module> - INFO - checking module definition
2019-01-27 09:43:51 - run.py - <module> - INFO - module <DB.schema_definition.DB instance at 0x00000000146FC648> is well defined
2019-01-27 09:43:51 - run.py - <module> - INFO - module <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x000000000E8F2080> is well defined
2019-01-27 09:43:51 - run.py - <module> - INFO - module <dataset_builder.feature_extractor.cooperation_topic_feature_generator.CooperationTopicFeatureGenerator object at 0x00000000146FEA58> is well defined
2019-01-27 09:43:51 - run.py - <module> - INFO - execute module: <DB.schema_definition.DB instance at 0x00000000146FC648>
2019-01-27 09:43:51 - run.py - <module> - INFO - *********Started executing DB
2019-01-27 09:43:51 - run.py - <module> - INFO - *********Finished executing DB
2019-01-27 09:43:51 - run.py - <module> - INFO - execute module: <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x000000000E8F2080>
2019-01-27 09:43:51 - run.py - <module> - INFO - *********Started executing AddAuthorConnectionClaimId
2019-01-27 09:44:42 - run.py - <module> - ERROR - *********Failed in executing : AddAuthorConnectionClaimId
Traceback (most recent call last):
  File "C:/Users/Developer_1/Documents/GitHub/measurement-of-online-discussion-authenticity/bad_actors/run.py", line 206, in <module>
    module.execute(window_start)
  File "C:\Users\Developer_1\Documents\GitHub\measurement-of-online-discussion-authenticity\bad_actors\missing_data_complementor\add_author_connection_claim_id.py", line 10, in execute
    self._db.add_claim_id_to_author_connections()
  File "C:\Users\Developer_1\Documents\GitHub\measurement-of-online-discussion-authenticity\bad_actors\DB\schema_definition.py", line 1016, in add_claim_id_to_author_connections
    self.delete_author_connections_missing_claim()
  File "C:\Users\Developer_1\Documents\GitHub\measurement-of-online-discussion-authenticity\bad_actors\DB\schema_definition.py", line 2012, in delete_author_connections_missing_claim
    self.session.query(AuthorConnection).filter(AuthorConnection.claim_id.is_(None)).delete()
  File "C:\Python27\lib\site-packages\sqlalchemy\orm\query.py", line 3346, in delete
    delete_op.exec_()
  File "C:\Python27\lib\site-packages\sqlalchemy\orm\persistence.py", line 1326, in exec_
    self._do_exec()
  File "C:\Python27\lib\site-packages\sqlalchemy\orm\persistence.py", line 1518, in _do_exec
    self._execute_stmt(delete_stmt)
  File "C:\Python27\lib\site-packages\sqlalchemy\orm\persistence.py", line 1333, in _execute_stmt
    mapper=self.mapper)
  File "C:\Python27\lib\site-packages\sqlalchemy\orm\session.py", line 1176, in execute
    bind, close_with_result=True).execute(clause, params or {})
  File "C:\Python27\lib\site-packages\sqlalchemy\engine\base.py", line 948, in execute
    return meth(self, multiparams, params)
  File "C:\Python27\lib\site-packages\sqlalchemy\sql\elements.py", line 269, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "C:\Python27\lib\site-packages\sqlalchemy\engine\base.py", line 1060, in _execute_clauseelement
    compiled_sql, distilled_params
  File "C:\Python27\lib\site-packages\sqlalchemy\engine\base.py", line 1200, in _execute_context
    context)
  File "C:\Python27\lib\site-packages\sqlalchemy\engine\base.py", line 1413, in _handle_dbapi_exception
    exc_info
  File "C:\Python27\lib\site-packages\sqlalchemy\util\compat.py", line 265, in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
  File "C:\Python27\lib\site-packages\sqlalchemy\engine\base.py", line 1193, in _execute_context
    context)
  File "C:\Python27\lib\site-packages\sqlalchemy\engine\default.py", line 509, in do_execute
    cursor.execute(statement, parameters)
OperationalError: (sqlite3.OperationalError) database is locked [SQL: u'DELETE FROM author_connections WHERE author_connections.claim_id IS NULL'] (Background on this error at: http://sqlalche.me/e/e3q8)
2019-01-27 09:46:15 - run.py - <module> - INFO - Start Execution ... 
2019-01-27 09:46:15 - run.py - <module> - INFO - SETUP global variables
2019-01-27 09:46:15 - run.py - <module> - INFO - CREATE pipeline
2019-01-27 09:46:15 - run.py - <module> - INFO - SETUP pipeline
2019-01-27 09:46:15 - run.py - <module> - INFO - setup module: <DB.schema_definition.DB instance at 0x0000000013FDE648>
2019-01-27 09:46:15 - run.py - <module> - INFO - setup module: <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x000000000E319080>
2019-01-27 09:46:15 - run.py - <module> - INFO - setup module: <dataset_builder.feature_extractor.cooperation_topic_feature_generator.CooperationTopicFeatureGenerator object at 0x0000000013FE0A58>
2019-01-27 09:46:15 - run.py - <module> - INFO - checking module definition
2019-01-27 09:46:15 - run.py - <module> - INFO - module <DB.schema_definition.DB instance at 0x0000000013FDE648> is well defined
2019-01-27 09:46:15 - run.py - <module> - INFO - module <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x000000000E319080> is well defined
2019-01-27 09:46:15 - run.py - <module> - INFO - module <dataset_builder.feature_extractor.cooperation_topic_feature_generator.CooperationTopicFeatureGenerator object at 0x0000000013FE0A58> is well defined
2019-01-27 09:46:15 - run.py - <module> - INFO - execute module: <DB.schema_definition.DB instance at 0x0000000013FDE648>
2019-01-27 09:46:15 - run.py - <module> - INFO - *********Started executing DB
2019-01-27 09:46:15 - run.py - <module> - INFO - *********Finished executing DB
2019-01-27 09:46:15 - run.py - <module> - INFO - execute module: <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x000000000E319080>
2019-01-27 09:46:15 - run.py - <module> - INFO - *********Started executing AddAuthorConnectionClaimId
2019-01-27 09:46:56 - run.py - <module> - INFO - *********Finished executing AddAuthorConnectionClaimId
2019-01-27 09:46:56 - run.py - <module> - INFO - execute module: <dataset_builder.feature_extractor.cooperation_topic_feature_generator.CooperationTopicFeatureGenerator object at 0x0000000013FE0A58>
2019-01-27 09:46:56 - run.py - <module> - INFO - *********Started executing CooperationTopicFeatureGenerator
2019-01-27 09:46:56 - cooperation_topic_feature_generator.py - execute - INFO - execute started for Cooperation topic feature generator started at 1548575216.94
2019-01-27 09:46:56 - run.py - <module> - ERROR - *********Failed in executing : CooperationTopicFeatureGenerator
Traceback (most recent call last):
  File "C:/Users/Developer_1/Documents/GitHub/measurement-of-online-discussion-authenticity/bad_actors/run.py", line 206, in <module>
    module.execute(window_start)
  File "C:\Users\Developer_1\Documents\GitHub\measurement-of-online-discussion-authenticity\bad_actors\dataset_builder\feature_extractor\cooperation_topic_feature_generator.py", line 66, in execute
    claims = self._db.get_claims()
  File "C:\Users\Developer_1\Documents\GitHub\measurement-of-online-discussion-authenticity\bad_actors\DB\schema_definition.py", line 1498, in get_claims
    return self.session.query(Claim).all()
  File "C:\Python27\lib\site-packages\sqlalchemy\orm\query.py", line 2836, in all
    return list(self)
  File "C:\Python27\lib\site-packages\sqlalchemy\orm\query.py", line 2988, in __iter__
    return self._execute_and_instances(context)
  File "C:\Python27\lib\site-packages\sqlalchemy\orm\query.py", line 3011, in _execute_and_instances
    result = conn.execute(querycontext.statement, self._params)
  File "C:\Python27\lib\site-packages\sqlalchemy\engine\base.py", line 948, in execute
    return meth(self, multiparams, params)
  File "C:\Python27\lib\site-packages\sqlalchemy\sql\elements.py", line 269, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "C:\Python27\lib\site-packages\sqlalchemy\engine\base.py", line 1060, in _execute_clauseelement
    compiled_sql, distilled_params
  File "C:\Python27\lib\site-packages\sqlalchemy\engine\base.py", line 1200, in _execute_context
    context)
  File "C:\Python27\lib\site-packages\sqlalchemy\engine\base.py", line 1413, in _handle_dbapi_exception
    exc_info
  File "C:\Python27\lib\site-packages\sqlalchemy\util\compat.py", line 265, in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
  File "C:\Python27\lib\site-packages\sqlalchemy\engine\base.py", line 1193, in _execute_context
    context)
  File "C:\Python27\lib\site-packages\sqlalchemy\engine\default.py", line 509, in do_execute
    cursor.execute(statement, parameters)
OperationalError: (sqlite3.OperationalError) no such column: claims.secondary_category [SQL: u'SELECT claims.claim_id AS claims_claim_id, claims.claim_topic AS claims_claim_topic, claims.claim_post_id AS claims_claim_post_id, claims.claim_ext_id AS claims_claim_ext_id, claims.title AS claims_title, claims.description AS claims_description, claims.main_category AS claims_main_category, claims.secondary_category AS claims_secondary_category, claims.url AS claims_url, claims.verdict_date AS claims_verdict_date, claims.keywords AS claims_keywords, claims.domain AS claims_domain, claims.verdict AS claims_verdict \nFROM claims'] (Background on this error at: http://sqlalche.me/e/e3q8)
2019-01-27 09:58:59 - run.py - <module> - INFO - Start Execution ... 
2019-01-27 09:58:59 - run.py - <module> - INFO - SETUP global variables
2019-01-27 09:58:59 - run.py - <module> - INFO - CREATE pipeline
2019-01-27 09:58:59 - run.py - <module> - INFO - SETUP pipeline
2019-01-27 09:58:59 - run.py - <module> - INFO - setup module: <DB.schema_definition.DB instance at 0x000000001404E648>
2019-01-27 09:58:59 - run.py - <module> - INFO - setup module: <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x000000000E349080>
2019-01-27 09:58:59 - run.py - <module> - INFO - setup module: <dataset_builder.feature_extractor.cooperation_topic_feature_generator.CooperationTopicFeatureGenerator object at 0x0000000014050A58>
2019-01-27 09:58:59 - run.py - <module> - INFO - checking module definition
2019-01-27 09:58:59 - run.py - <module> - INFO - module <DB.schema_definition.DB instance at 0x000000001404E648> is well defined
2019-01-27 09:58:59 - run.py - <module> - INFO - module <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x000000000E349080> is well defined
2019-01-27 09:58:59 - run.py - <module> - INFO - module <dataset_builder.feature_extractor.cooperation_topic_feature_generator.CooperationTopicFeatureGenerator object at 0x0000000014050A58> is well defined
2019-01-27 09:58:59 - run.py - <module> - INFO - execute module: <DB.schema_definition.DB instance at 0x000000001404E648>
2019-01-27 09:58:59 - run.py - <module> - INFO - *********Started executing DB
2019-01-27 09:58:59 - run.py - <module> - INFO - *********Finished executing DB
2019-01-27 09:58:59 - run.py - <module> - INFO - execute module: <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x000000000E349080>
2019-01-27 09:58:59 - run.py - <module> - INFO - *********Started executing AddAuthorConnectionClaimId
2019-01-27 09:59:41 - run.py - <module> - INFO - *********Finished executing AddAuthorConnectionClaimId
2019-01-27 09:59:41 - run.py - <module> - INFO - execute module: <dataset_builder.feature_extractor.cooperation_topic_feature_generator.CooperationTopicFeatureGenerator object at 0x0000000014050A58>
2019-01-27 09:59:41 - run.py - <module> - INFO - *********Started executing CooperationTopicFeatureGenerator
2019-01-27 09:59:41 - cooperation_topic_feature_generator.py - execute - INFO - execute started for Cooperation topic feature generator started at 1548575981.97
2019-01-27 09:59:41 - cooperation_topic_feature_generator.py - execute - INFO - Cooperation execute window_start 2000-06-07 00:00:00
2019-01-27 10:03:00 - cooperation_topic_feature_generator.py - execute - ERROR - Failed in extraction process!
2019-01-27 10:03:00 - cooperation_topic_feature_generator.py - execute - INFO - execute ended at 1548576180.32
2019-01-27 10:03:00 - schema_definition.py - add_author_features - INFO - total Author Features inserted to DB: 0
2019-01-27 10:03:50 - run.py - <module> - INFO - *********Finished executing CooperationTopicFeatureGenerator
2019-01-27 10:12:46 - run.py - <module> - INFO - Start Execution ... 
2019-01-27 10:12:46 - run.py - <module> - INFO - SETUP global variables
2019-01-27 10:12:46 - run.py - <module> - INFO - CREATE pipeline
2019-01-27 10:12:46 - run.py - <module> - INFO - SETUP pipeline
2019-01-27 10:12:46 - run.py - <module> - INFO - setup module: <DB.schema_definition.DB instance at 0x0000000015326C08>
2019-01-27 10:12:46 - run.py - <module> - INFO - setup module: <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x0000000010760390>
2019-01-27 10:12:46 - run.py - <module> - INFO - setup module: <dataset_builder.feature_extractor.cooperation_topic_feature_generator.CooperationTopicFeatureGenerator object at 0x0000000015341B38>
2019-01-27 10:12:46 - run.py - <module> - INFO - checking module definition
2019-01-27 10:12:46 - run.py - <module> - INFO - module <DB.schema_definition.DB instance at 0x0000000015326C08> is well defined
2019-01-27 10:12:46 - run.py - <module> - INFO - module <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x0000000010760390> is well defined
2019-01-27 10:12:46 - run.py - <module> - INFO - module <dataset_builder.feature_extractor.cooperation_topic_feature_generator.CooperationTopicFeatureGenerator object at 0x0000000015341B38> is well defined
2019-01-27 10:12:46 - run.py - <module> - INFO - execute module: <DB.schema_definition.DB instance at 0x0000000015326C08>
2019-01-27 10:12:46 - run.py - <module> - INFO - *********Started executing DB
2019-01-27 10:12:46 - run.py - <module> - INFO - *********Finished executing DB
2019-01-27 10:12:46 - run.py - <module> - INFO - execute module: <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x0000000010760390>
2019-01-27 10:12:46 - run.py - <module> - INFO - *********Started executing AddAuthorConnectionClaimId
2019-01-27 10:13:30 - run.py - <module> - INFO - *********Finished executing AddAuthorConnectionClaimId
2019-01-27 10:13:30 - run.py - <module> - INFO - execute module: <dataset_builder.feature_extractor.cooperation_topic_feature_generator.CooperationTopicFeatureGenerator object at 0x0000000015341B38>
2019-01-27 10:13:30 - run.py - <module> - INFO - *********Started executing CooperationTopicFeatureGenerator
2019-01-27 10:13:30 - cooperation_topic_feature_generator.py - execute - INFO - execute started for Cooperation topic feature generator started at 1548576810.68
2019-01-27 11:45:13 - run.py - <module> - INFO - Start Execution ... 
2019-01-27 11:45:13 - run.py - <module> - INFO - SETUP global variables
2019-01-27 11:45:13 - run.py - <module> - INFO - CREATE pipeline
2019-01-27 11:45:13 - run.py - <module> - INFO - SETUP pipeline
2019-01-27 11:45:13 - run.py - <module> - INFO - setup module: <DB.schema_definition.DB instance at 0x000000001539D948>
2019-01-27 11:45:13 - run.py - <module> - INFO - setup module: <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x00000000107702B0>
2019-01-27 11:45:13 - run.py - <module> - INFO - setup module: <dataset_builder.feature_extractor.cooperation_topic_feature_generator.CooperationTopicFeatureGenerator object at 0x000000001539EA58>
2019-01-27 11:45:14 - run.py - <module> - INFO - checking module definition
2019-01-27 11:45:14 - run.py - <module> - INFO - module <DB.schema_definition.DB instance at 0x000000001539D948> is well defined
2019-01-27 11:45:14 - run.py - <module> - INFO - module <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x00000000107702B0> is well defined
2019-01-27 11:45:14 - run.py - <module> - INFO - module <dataset_builder.feature_extractor.cooperation_topic_feature_generator.CooperationTopicFeatureGenerator object at 0x000000001539EA58> is well defined
2019-01-27 11:45:14 - run.py - <module> - INFO - execute module: <DB.schema_definition.DB instance at 0x000000001539D948>
2019-01-27 11:45:14 - run.py - <module> - INFO - *********Started executing DB
2019-01-27 11:45:14 - run.py - <module> - INFO - *********Finished executing DB
2019-01-27 11:45:14 - run.py - <module> - INFO - execute module: <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x00000000107702B0>
2019-01-27 11:45:14 - run.py - <module> - INFO - *********Started executing AddAuthorConnectionClaimId
2019-01-27 11:45:58 - run.py - <module> - INFO - *********Finished executing AddAuthorConnectionClaimId
2019-01-27 11:45:58 - run.py - <module> - INFO - execute module: <dataset_builder.feature_extractor.cooperation_topic_feature_generator.CooperationTopicFeatureGenerator object at 0x000000001539EA58>
2019-01-27 11:45:58 - run.py - <module> - INFO - *********Started executing CooperationTopicFeatureGenerator
2019-01-27 11:45:58 - cooperation_topic_feature_generator.py - execute - INFO - execute started for Cooperation topic feature generator started at 1548582358.4
2019-01-27 11:46:07 - cooperation_topic_feature_generator.py - execute - INFO - Cooperation execute window_start 2000-06-07 00:00:00
2019-01-27 12:00:19 - run.py - <module> - INFO - Start Execution ... 
2019-01-27 12:00:19 - run.py - <module> - INFO - SETUP global variables
2019-01-27 12:00:19 - run.py - <module> - INFO - CREATE pipeline
2019-01-27 12:00:19 - run.py - <module> - INFO - SETUP pipeline
2019-01-27 12:00:19 - run.py - <module> - INFO - setup module: <DB.schema_definition.DB instance at 0x0000000015398BC8>
2019-01-27 12:00:20 - run.py - <module> - INFO - setup module: <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x00000000107BC390>
2019-01-27 12:00:20 - run.py - <module> - INFO - setup module: <dataset_builder.feature_extractor.cooperation_topic_feature_generator.CooperationTopicFeatureGenerator object at 0x00000000153B5B38>
2019-01-27 12:00:20 - run.py - <module> - INFO - checking module definition
2019-01-27 12:00:20 - run.py - <module> - INFO - module <DB.schema_definition.DB instance at 0x0000000015398BC8> is well defined
2019-01-27 12:00:20 - run.py - <module> - INFO - module <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x00000000107BC390> is well defined
2019-01-27 12:00:20 - run.py - <module> - INFO - module <dataset_builder.feature_extractor.cooperation_topic_feature_generator.CooperationTopicFeatureGenerator object at 0x00000000153B5B38> is well defined
2019-01-27 12:00:20 - run.py - <module> - INFO - execute module: <DB.schema_definition.DB instance at 0x0000000015398BC8>
2019-01-27 12:00:20 - run.py - <module> - INFO - *********Started executing DB
2019-01-27 12:00:20 - run.py - <module> - INFO - *********Finished executing DB
2019-01-27 12:00:20 - run.py - <module> - INFO - execute module: <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x00000000107BC390>
2019-01-27 12:00:20 - run.py - <module> - INFO - *********Started executing AddAuthorConnectionClaimId
2019-01-27 12:01:08 - run.py - <module> - INFO - *********Finished executing AddAuthorConnectionClaimId
2019-01-27 12:01:08 - run.py - <module> - INFO - execute module: <dataset_builder.feature_extractor.cooperation_topic_feature_generator.CooperationTopicFeatureGenerator object at 0x00000000153B5B38>
2019-01-27 12:01:08 - run.py - <module> - INFO - *********Started executing CooperationTopicFeatureGenerator
2019-01-27 12:01:08 - cooperation_topic_feature_generator.py - execute - INFO - execute started for Cooperation topic feature generator started at 1548583268.43
2019-01-27 12:01:08 - cooperation_topic_feature_generator.py - execute - INFO - Cooperation execute window_start 2000-06-07 00:00:00
2019-01-27 13:11:11 - run.py - <module> - INFO - Start Execution ... 
2019-01-27 13:11:11 - run.py - <module> - INFO - SETUP global variables
2019-01-27 13:11:11 - run.py - <module> - INFO - CREATE pipeline
2019-01-27 13:11:11 - run.py - <module> - INFO - SETUP pipeline
2019-01-27 13:11:11 - run.py - <module> - INFO - setup module: <DB.schema_definition.DB instance at 0x00000000141E9408>
2019-01-27 13:11:11 - run.py - <module> - INFO - setup module: <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x000000000E4F2080>
2019-01-27 13:11:11 - run.py - <module> - INFO - setup module: <dataset_builder.feature_extractor.cooperation_topic_feature_generator.CooperationTopicFeatureGenerator object at 0x00000000141DE908>
2019-01-27 13:11:11 - run.py - <module> - INFO - checking module definition
2019-01-27 13:11:11 - run.py - <module> - INFO - module <DB.schema_definition.DB instance at 0x00000000141E9408> is well defined
2019-01-27 13:11:11 - run.py - <module> - INFO - module <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x000000000E4F2080> is well defined
2019-01-27 13:11:11 - run.py - <module> - INFO - module <dataset_builder.feature_extractor.cooperation_topic_feature_generator.CooperationTopicFeatureGenerator object at 0x00000000141DE908> is well defined
2019-01-27 13:11:11 - run.py - <module> - INFO - execute module: <DB.schema_definition.DB instance at 0x00000000141E9408>
2019-01-27 13:11:11 - run.py - <module> - INFO - *********Started executing DB
2019-01-27 13:11:11 - run.py - <module> - INFO - *********Finished executing DB
2019-01-27 13:11:11 - run.py - <module> - INFO - execute module: <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x000000000E4F2080>
2019-01-27 13:11:11 - run.py - <module> - INFO - *********Started executing AddAuthorConnectionClaimId
2019-01-27 13:11:56 - run.py - <module> - INFO - *********Finished executing AddAuthorConnectionClaimId
2019-01-27 13:11:56 - run.py - <module> - INFO - execute module: <dataset_builder.feature_extractor.cooperation_topic_feature_generator.CooperationTopicFeatureGenerator object at 0x00000000141DE908>
2019-01-27 13:11:56 - run.py - <module> - INFO - *********Started executing CooperationTopicFeatureGenerator
2019-01-27 13:11:56 - cooperation_topic_feature_generator.py - execute - INFO - execute started for Cooperation topic feature generator started at 1548587516.03
2019-01-27 13:11:56 - cooperation_topic_feature_generator.py - execute - INFO - Cooperation execute window_start 2000-06-07 00:00:00
2019-01-27 13:14:38 - cooperation_topic_feature_generator.py - execute - ERROR - Failed in extraction process!
2019-01-27 13:14:38 - cooperation_topic_feature_generator.py - execute - INFO - execute ended at 1548587678.56
2019-01-27 13:14:38 - schema_definition.py - add_author_features - INFO - total Author Features inserted to DB: 0
2019-01-28 08:36:39 - run.py - <module> - INFO - Start Execution ... 
2019-01-28 08:36:39 - run.py - <module> - INFO - SETUP global variables
2019-01-28 08:36:40 - run.py - <module> - INFO - CREATE pipeline
2019-01-28 08:36:40 - run.py - <module> - INFO - SETUP pipeline
2019-01-28 08:36:40 - run.py - <module> - INFO - setup module: <DB.schema_definition.DB instance at 0x000000002EAE0988>
2019-01-28 08:36:40 - run.py - <module> - INFO - setup module: <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x000000002967B320>
2019-01-28 08:36:40 - run.py - <module> - INFO - setup module: <dataset_builder.feature_extractor.cooperation_topic_feature_generator.CooperationTopicFeatureGenerator object at 0x000000002EAF7D68>
2019-01-28 08:36:40 - run.py - <module> - INFO - checking module definition
2019-01-28 08:36:40 - run.py - <module> - INFO - module <DB.schema_definition.DB instance at 0x000000002EAE0988> is well defined
2019-01-28 08:36:40 - run.py - <module> - INFO - module <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x000000002967B320> is well defined
2019-01-28 08:36:40 - run.py - <module> - INFO - module <dataset_builder.feature_extractor.cooperation_topic_feature_generator.CooperationTopicFeatureGenerator object at 0x000000002EAF7D68> is well defined
2019-01-28 08:36:40 - run.py - <module> - INFO - execute module: <DB.schema_definition.DB instance at 0x000000002EAE0988>
2019-01-28 08:36:40 - run.py - <module> - INFO - *********Started executing DB
2019-01-28 08:36:40 - run.py - <module> - INFO - *********Finished executing DB
2019-01-28 08:36:40 - run.py - <module> - INFO - execute module: <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x000000002967B320>
2019-01-28 08:36:40 - run.py - <module> - INFO - *********Started executing AddAuthorConnectionClaimId
2019-01-28 08:37:21 - run.py - <module> - INFO - *********Finished executing AddAuthorConnectionClaimId
2019-01-28 08:37:21 - run.py - <module> - INFO - execute module: <dataset_builder.feature_extractor.cooperation_topic_feature_generator.CooperationTopicFeatureGenerator object at 0x000000002EAF7D68>
2019-01-28 08:37:21 - run.py - <module> - INFO - *********Started executing CooperationTopicFeatureGenerator
2019-01-28 08:37:21 - cooperation_topic_feature_generator.py - execute - INFO - execute started for Cooperation topic feature generator started at 1548657441.95
2019-01-28 08:37:21 - cooperation_topic_feature_generator.py - execute - INFO - Cooperation execute window_start 2000-06-07 00:00:00
2019-01-28 08:44:09 - run.py - <module> - INFO - Start Execution ... 
2019-01-28 08:44:09 - run.py - <module> - INFO - SETUP global variables
2019-01-28 08:44:09 - run.py - <module> - INFO - CREATE pipeline
2019-01-28 08:44:09 - run.py - <module> - INFO - SETUP pipeline
2019-01-28 08:44:09 - run.py - <module> - INFO - setup module: <DB.schema_definition.DB instance at 0x000000002E5F7488>
2019-01-28 08:44:09 - run.py - <module> - INFO - setup module: <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x00000000294FE208>
2019-01-28 08:44:09 - run.py - <module> - INFO - setup module: <dataset_builder.feature_extractor.cooperation_topic_feature_generator.CooperationTopicFeatureGenerator object at 0x000000002E7C49E8>
2019-01-28 08:44:09 - run.py - <module> - INFO - checking module definition
2019-01-28 08:44:09 - run.py - <module> - INFO - module <DB.schema_definition.DB instance at 0x000000002E5F7488> is well defined
2019-01-28 08:44:09 - run.py - <module> - INFO - module <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x00000000294FE208> is well defined
2019-01-28 08:44:09 - run.py - <module> - INFO - module <dataset_builder.feature_extractor.cooperation_topic_feature_generator.CooperationTopicFeatureGenerator object at 0x000000002E7C49E8> is well defined
2019-01-28 08:44:09 - run.py - <module> - INFO - execute module: <DB.schema_definition.DB instance at 0x000000002E5F7488>
2019-01-28 08:44:09 - run.py - <module> - INFO - *********Started executing DB
2019-01-28 08:44:09 - run.py - <module> - INFO - *********Finished executing DB
2019-01-28 08:44:09 - run.py - <module> - INFO - execute module: <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x00000000294FE208>
2019-01-28 08:44:09 - run.py - <module> - INFO - *********Started executing AddAuthorConnectionClaimId
2019-01-28 08:44:45 - run.py - <module> - INFO - *********Finished executing AddAuthorConnectionClaimId
2019-01-28 08:44:45 - run.py - <module> - INFO - execute module: <dataset_builder.feature_extractor.cooperation_topic_feature_generator.CooperationTopicFeatureGenerator object at 0x000000002E7C49E8>
2019-01-28 08:44:45 - run.py - <module> - INFO - *********Started executing CooperationTopicFeatureGenerator
2019-01-28 08:44:45 - cooperation_topic_feature_generator.py - execute - INFO - execute started for Cooperation topic feature generator started at 1548657885.62
2019-01-28 08:44:45 - cooperation_topic_feature_generator.py - execute - INFO - Cooperation execute window_start 2000-06-07 00:00:00
2019-01-28 08:52:32 - cooperation_topic_feature_generator.py - execute - INFO - Started 1 claim from 398 claims
2019-01-28 08:56:40 - cooperation_topic_feature_generator.py - execute - ERROR - Failed in extraction process!
2019-01-28 08:56:40 - cooperation_topic_feature_generator.py - execute - INFO - execute ended at 1548658600.56
2019-01-28 08:56:40 - schema_definition.py - add_author_features - INFO - total Author Features inserted to DB: 0
2019-01-28 08:57:13 - run.py - <module> - INFO - *********Finished executing CooperationTopicFeatureGenerator
2019-01-28 08:58:36 - run.py - <module> - INFO - Start Execution ... 
2019-01-28 08:58:36 - run.py - <module> - INFO - SETUP global variables
2019-01-28 08:58:36 - run.py - <module> - INFO - CREATE pipeline
2019-01-28 08:58:36 - run.py - <module> - INFO - SETUP pipeline
2019-01-28 08:58:36 - run.py - <module> - INFO - setup module: <DB.schema_definition.DB instance at 0x000000002ECFE648>
2019-01-28 08:58:36 - run.py - <module> - INFO - setup module: <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x00000000299B2208>
2019-01-28 08:58:36 - run.py - <module> - INFO - setup module: <dataset_builder.feature_extractor.cooperation_topic_feature_generator.CooperationTopicFeatureGenerator object at 0x000000002EDDBA20>
2019-01-28 08:58:36 - run.py - <module> - INFO - checking module definition
2019-01-28 08:58:36 - run.py - <module> - INFO - module <DB.schema_definition.DB instance at 0x000000002ECFE648> is well defined
2019-01-28 08:58:36 - run.py - <module> - INFO - module <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x00000000299B2208> is well defined
2019-01-28 08:58:36 - run.py - <module> - INFO - module <dataset_builder.feature_extractor.cooperation_topic_feature_generator.CooperationTopicFeatureGenerator object at 0x000000002EDDBA20> is well defined
2019-01-28 08:58:36 - run.py - <module> - INFO - execute module: <DB.schema_definition.DB instance at 0x000000002ECFE648>
2019-01-28 08:58:36 - run.py - <module> - INFO - *********Started executing DB
2019-01-28 08:58:36 - run.py - <module> - INFO - *********Finished executing DB
2019-01-28 08:58:36 - run.py - <module> - INFO - execute module: <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x00000000299B2208>
2019-01-28 08:58:36 - run.py - <module> - INFO - *********Started executing AddAuthorConnectionClaimId
2019-01-28 08:59:13 - run.py - <module> - INFO - *********Finished executing AddAuthorConnectionClaimId
2019-01-28 08:59:13 - run.py - <module> - INFO - execute module: <dataset_builder.feature_extractor.cooperation_topic_feature_generator.CooperationTopicFeatureGenerator object at 0x000000002EDDBA20>
2019-01-28 08:59:13 - run.py - <module> - INFO - *********Started executing CooperationTopicFeatureGenerator
2019-01-28 08:59:13 - cooperation_topic_feature_generator.py - execute - INFO - execute started for Cooperation topic feature generator started at 1548658753.52
2019-01-28 08:59:13 - cooperation_topic_feature_generator.py - execute - INFO - Cooperation execute window_start 2000-06-07 00:00:00
2019-01-28 09:01:44 - cooperation_topic_feature_generator.py - execute - INFO - Started 1 claim from 398 claims
2019-01-28 09:02:35 - cooperation_topic_feature_generator.py - execute - INFO - Started 1 feature from 6 features
2019-01-28 09:03:43 - cooperation_topic_feature_generator.py - execute - INFO - Started 2 feature from 6 features
2019-01-28 14:01:14 - run.py - <module> - INFO - Start Execution ... 
2019-01-28 14:01:14 - run.py - <module> - INFO - SETUP global variables
2019-01-28 14:01:14 - run.py - <module> - INFO - CREATE pipeline
2019-01-28 14:01:14 - run.py - <module> - INFO - SETUP pipeline
2019-01-28 14:01:14 - run.py - <module> - INFO - setup module: <DB.schema_definition.DB instance at 0x000000002E300B88>
2019-01-28 14:01:14 - run.py - <module> - INFO - setup module: <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x0000000029118208>
2019-01-28 14:01:14 - run.py - <module> - INFO - setup module: <dataset_builder.feature_extractor.cooperation_topic_feature_generator.CooperationTopicFeatureGenerator object at 0x000000002E4CEAC8>
2019-01-28 14:01:14 - run.py - <module> - INFO - checking module definition
2019-01-28 14:01:14 - run.py - <module> - INFO - module <DB.schema_definition.DB instance at 0x000000002E300B88> is well defined
2019-01-28 14:01:14 - run.py - <module> - INFO - module <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x0000000029118208> is well defined
2019-01-28 14:01:14 - run.py - <module> - INFO - module <dataset_builder.feature_extractor.cooperation_topic_feature_generator.CooperationTopicFeatureGenerator object at 0x000000002E4CEAC8> is well defined
2019-01-28 14:01:14 - run.py - <module> - INFO - execute module: <DB.schema_definition.DB instance at 0x000000002E300B88>
2019-01-28 14:01:14 - run.py - <module> - INFO - *********Started executing DB
2019-01-28 14:01:14 - run.py - <module> - INFO - *********Finished executing DB
2019-01-28 14:01:14 - run.py - <module> - INFO - execute module: <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x0000000029118208>
2019-01-28 14:01:14 - run.py - <module> - INFO - *********Started executing AddAuthorConnectionClaimId
2019-01-28 14:01:51 - run.py - <module> - INFO - *********Finished executing AddAuthorConnectionClaimId
2019-01-28 14:01:51 - run.py - <module> - INFO - execute module: <dataset_builder.feature_extractor.cooperation_topic_feature_generator.CooperationTopicFeatureGenerator object at 0x000000002E4CEAC8>
2019-01-28 14:01:51 - run.py - <module> - INFO - *********Started executing CooperationTopicFeatureGenerator
2019-01-28 14:01:51 - cooperation_topic_feature_generator.py - execute - INFO - execute started for Cooperation topic feature generator started at 1548676911.54
2019-01-28 14:01:51 - cooperation_topic_feature_generator.py - execute - INFO - Cooperation execute window_start 2000-06-07 00:00:00
2019-01-28 14:04:15 - cooperation_topic_feature_generator.py - execute - INFO - Started 1 claim from 398 claims
2019-01-28 14:04:29 - cooperation_topic_feature_generator.py - execute - ERROR - Failed in extraction process!
2019-01-28 14:04:29 - cooperation_topic_feature_generator.py - execute - INFO - execute ended at 1548677069.24
2019-01-28 14:04:29 - schema_definition.py - add_author_features - INFO - total Author Features inserted to DB: 0
2019-01-28 14:05:04 - run.py - <module> - INFO - *********Finished executing CooperationTopicFeatureGenerator
2019-01-28 14:05:48 - run.py - <module> - INFO - Start Execution ... 
2019-01-28 14:05:48 - run.py - <module> - INFO - SETUP global variables
2019-01-28 14:05:48 - run.py - <module> - INFO - CREATE pipeline
2019-01-28 14:05:48 - run.py - <module> - INFO - SETUP pipeline
2019-01-28 14:05:48 - run.py - <module> - INFO - setup module: <DB.schema_definition.DB instance at 0x00000000297DE448>
2019-01-28 14:05:48 - run.py - <module> - INFO - setup module: <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x00000000297E1240>
2019-01-28 14:05:48 - run.py - <module> - INFO - setup module: <dataset_builder.feature_extractor.cooperation_topic_feature_generator.CooperationTopicFeatureGenerator object at 0x000000002EB73B00>
2019-01-28 14:05:48 - run.py - <module> - INFO - checking module definition
2019-01-28 14:05:48 - run.py - <module> - INFO - module <DB.schema_definition.DB instance at 0x00000000297DE448> is well defined
2019-01-28 14:05:48 - run.py - <module> - INFO - module <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x00000000297E1240> is well defined
2019-01-28 14:05:48 - run.py - <module> - INFO - module <dataset_builder.feature_extractor.cooperation_topic_feature_generator.CooperationTopicFeatureGenerator object at 0x000000002EB73B00> is well defined
2019-01-28 14:05:48 - run.py - <module> - INFO - execute module: <DB.schema_definition.DB instance at 0x00000000297DE448>
2019-01-28 14:05:48 - run.py - <module> - INFO - *********Started executing DB
2019-01-28 14:05:48 - run.py - <module> - INFO - *********Finished executing DB
2019-01-28 14:05:48 - run.py - <module> - INFO - execute module: <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x00000000297E1240>
2019-01-28 14:05:48 - run.py - <module> - INFO - *********Started executing AddAuthorConnectionClaimId
2019-01-28 14:06:25 - run.py - <module> - INFO - *********Finished executing AddAuthorConnectionClaimId
2019-01-28 14:06:25 - run.py - <module> - INFO - execute module: <dataset_builder.feature_extractor.cooperation_topic_feature_generator.CooperationTopicFeatureGenerator object at 0x000000002EB73B00>
2019-01-28 14:06:25 - run.py - <module> - INFO - *********Started executing CooperationTopicFeatureGenerator
2019-01-28 14:06:25 - cooperation_topic_feature_generator.py - execute - INFO - execute started for Cooperation topic feature generator started at 1548677185.11
2019-01-28 14:06:25 - cooperation_topic_feature_generator.py - execute - INFO - Cooperation execute window_start 2000-06-07 00:00:00
2019-01-28 14:08:48 - cooperation_topic_feature_generator.py - execute - INFO - Started 1 claim from 398 claims
2019-01-28 14:14:01 - run.py - <module> - INFO - Start Execution ... 
2019-01-28 14:14:01 - run.py - <module> - INFO - SETUP global variables
2019-01-28 14:14:01 - run.py - <module> - INFO - CREATE pipeline
2019-01-28 14:14:01 - run.py - <module> - INFO - SETUP pipeline
2019-01-28 14:14:01 - run.py - <module> - INFO - setup module: <DB.schema_definition.DB instance at 0x000000002E4FEB48>
2019-01-28 14:14:01 - run.py - <module> - INFO - setup module: <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x0000000029504208>
2019-01-28 14:14:01 - run.py - <module> - INFO - setup module: <dataset_builder.feature_extractor.cooperation_topic_feature_generator.CooperationTopicFeatureGenerator object at 0x000000002E5DBA90>
2019-01-28 14:14:01 - run.py - <module> - INFO - checking module definition
2019-01-28 14:14:01 - run.py - <module> - INFO - module <DB.schema_definition.DB instance at 0x000000002E4FEB48> is well defined
2019-01-28 14:14:01 - run.py - <module> - INFO - module <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x0000000029504208> is well defined
2019-01-28 14:14:01 - run.py - <module> - INFO - module <dataset_builder.feature_extractor.cooperation_topic_feature_generator.CooperationTopicFeatureGenerator object at 0x000000002E5DBA90> is well defined
2019-01-28 14:14:01 - run.py - <module> - INFO - execute module: <DB.schema_definition.DB instance at 0x000000002E4FEB48>
2019-01-28 14:14:01 - run.py - <module> - INFO - *********Started executing DB
2019-01-28 14:14:01 - run.py - <module> - INFO - *********Finished executing DB
2019-01-28 14:14:01 - run.py - <module> - INFO - execute module: <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x0000000029504208>
2019-01-28 14:14:01 - run.py - <module> - INFO - *********Started executing AddAuthorConnectionClaimId
2019-01-28 14:14:39 - run.py - <module> - INFO - *********Finished executing AddAuthorConnectionClaimId
2019-01-28 14:14:39 - run.py - <module> - INFO - execute module: <dataset_builder.feature_extractor.cooperation_topic_feature_generator.CooperationTopicFeatureGenerator object at 0x000000002E5DBA90>
2019-01-28 14:14:39 - run.py - <module> - INFO - *********Started executing CooperationTopicFeatureGenerator
2019-01-28 14:14:39 - cooperation_topic_feature_generator.py - execute - INFO - execute started for Cooperation topic feature generator started at 1548677679.26
2019-01-28 14:14:39 - cooperation_topic_feature_generator.py - execute - INFO - Cooperation execute window_start 2000-06-07 00:00:00
2019-01-28 14:17:02 - cooperation_topic_feature_generator.py - execute - INFO - Started 1 claim from 398 claims
2019-01-28 14:29:37 - cooperation_topic_feature_generator.py - execute - ERROR - Failed in extraction process!
2019-01-28 14:29:37 - cooperation_topic_feature_generator.py - execute - INFO - execute ended at 1548678577.47
2019-01-28 14:29:37 - schema_definition.py - add_author_features - INFO - total Author Features inserted to DB: 0
2019-01-28 14:30:11 - run.py - <module> - INFO - *********Finished executing CooperationTopicFeatureGenerator
2019-01-28 14:44:15 - run.py - <module> - INFO - Start Execution ... 
2019-01-28 14:44:15 - run.py - <module> - INFO - SETUP global variables
2019-01-28 14:44:15 - run.py - <module> - INFO - CREATE pipeline
2019-01-28 14:44:15 - run.py - <module> - INFO - SETUP pipeline
2019-01-28 14:44:15 - run.py - <module> - INFO - setup module: <DB.schema_definition.DB instance at 0x000000002E4BD288>
2019-01-28 14:44:15 - run.py - <module> - INFO - setup module: <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x00000000290D7240>
2019-01-28 14:44:15 - run.py - <module> - INFO - setup module: <dataset_builder.feature_extractor.cooperation_topic_feature_generator.CooperationTopicFeatureGenerator object at 0x000000002E4C4A58>
2019-01-28 14:44:15 - run.py - <module> - INFO - checking module definition
2019-01-28 14:44:15 - run.py - <module> - INFO - module <DB.schema_definition.DB instance at 0x000000002E4BD288> is well defined
2019-01-28 14:44:15 - run.py - <module> - INFO - module <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x00000000290D7240> is well defined
2019-01-28 14:44:15 - run.py - <module> - INFO - module <dataset_builder.feature_extractor.cooperation_topic_feature_generator.CooperationTopicFeatureGenerator object at 0x000000002E4C4A58> is well defined
2019-01-28 14:44:15 - run.py - <module> - INFO - execute module: <DB.schema_definition.DB instance at 0x000000002E4BD288>
2019-01-28 14:44:15 - run.py - <module> - INFO - *********Started executing DB
2019-01-28 14:44:15 - run.py - <module> - INFO - *********Finished executing DB
2019-01-28 14:44:15 - run.py - <module> - INFO - execute module: <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x00000000290D7240>
2019-01-28 14:44:15 - run.py - <module> - INFO - *********Started executing AddAuthorConnectionClaimId
2019-01-28 14:44:54 - run.py - <module> - INFO - *********Finished executing AddAuthorConnectionClaimId
2019-01-28 14:44:54 - run.py - <module> - INFO - execute module: <dataset_builder.feature_extractor.cooperation_topic_feature_generator.CooperationTopicFeatureGenerator object at 0x000000002E4C4A58>
2019-01-28 14:44:54 - run.py - <module> - INFO - *********Started executing CooperationTopicFeatureGenerator
2019-01-28 14:44:54 - cooperation_topic_feature_generator.py - execute - INFO - execute started for Cooperation topic feature generator started at 1548679494.21
2019-01-28 14:44:54 - cooperation_topic_feature_generator.py - execute - INFO - Cooperation execute window_start 2000-06-07 00:00:00
2019-01-28 14:47:17 - cooperation_topic_feature_generator.py - execute - INFO - Started 1 claim from 398 claims
2019-01-28 14:59:05 - run.py - <module> - INFO - Start Execution ... 
2019-01-28 14:59:05 - run.py - <module> - INFO - SETUP global variables
2019-01-28 14:59:05 - run.py - <module> - INFO - CREATE pipeline
2019-01-28 14:59:05 - run.py - <module> - INFO - SETUP pipeline
2019-01-28 14:59:05 - run.py - <module> - INFO - setup module: <DB.schema_definition.DB instance at 0x000000002E479BC8>
2019-01-28 14:59:05 - run.py - <module> - INFO - setup module: <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x0000000029502208>
2019-01-28 14:59:05 - run.py - <module> - INFO - setup module: <dataset_builder.feature_extractor.cooperation_topic_feature_generator.CooperationTopicFeatureGenerator object at 0x000000002E5F9A20>
2019-01-28 14:59:05 - run.py - <module> - INFO - checking module definition
2019-01-28 14:59:05 - run.py - <module> - INFO - module <DB.schema_definition.DB instance at 0x000000002E479BC8> is well defined
2019-01-28 14:59:05 - run.py - <module> - INFO - module <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x0000000029502208> is well defined
2019-01-28 14:59:05 - run.py - <module> - INFO - module <dataset_builder.feature_extractor.cooperation_topic_feature_generator.CooperationTopicFeatureGenerator object at 0x000000002E5F9A20> is well defined
2019-01-28 14:59:05 - run.py - <module> - INFO - execute module: <DB.schema_definition.DB instance at 0x000000002E479BC8>
2019-01-28 14:59:05 - run.py - <module> - INFO - *********Started executing DB
2019-01-28 14:59:05 - run.py - <module> - INFO - *********Finished executing DB
2019-01-28 14:59:05 - run.py - <module> - INFO - execute module: <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x0000000029502208>
2019-01-28 14:59:05 - run.py - <module> - INFO - *********Started executing AddAuthorConnectionClaimId
2019-01-28 14:59:43 - run.py - <module> - INFO - *********Finished executing AddAuthorConnectionClaimId
2019-01-28 14:59:43 - run.py - <module> - INFO - execute module: <dataset_builder.feature_extractor.cooperation_topic_feature_generator.CooperationTopicFeatureGenerator object at 0x000000002E5F9A20>
2019-01-28 14:59:43 - run.py - <module> - INFO - *********Started executing CooperationTopicFeatureGenerator
2019-01-28 14:59:43 - cooperation_topic_feature_generator.py - execute - INFO - execute started for Cooperation topic feature generator started at 1548680383.42
2019-01-28 14:59:43 - cooperation_topic_feature_generator.py - execute - INFO - Cooperation execute window_start 2000-06-07 00:00:00
2019-01-28 15:02:07 - cooperation_topic_feature_generator.py - execute - INFO - Started 1 claim from 398 claims
2019-01-28 15:06:15 - run.py - <module> - INFO - Start Execution ... 
2019-01-28 15:06:15 - run.py - <module> - INFO - SETUP global variables
2019-01-28 15:06:15 - run.py - <module> - INFO - CREATE pipeline
2019-01-28 15:06:15 - run.py - <module> - INFO - SETUP pipeline
2019-01-28 15:06:15 - run.py - <module> - INFO - setup module: <DB.schema_definition.DB instance at 0x0000000029DEA448>
2019-01-28 15:06:15 - run.py - <module> - INFO - setup module: <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x0000000029DED208>
2019-01-28 15:06:15 - run.py - <module> - INFO - setup module: <dataset_builder.feature_extractor.cooperation_topic_feature_generator.CooperationTopicFeatureGenerator object at 0x000000002F22AA20>
2019-01-28 15:06:15 - run.py - <module> - INFO - checking module definition
2019-01-28 15:06:15 - run.py - <module> - INFO - module <DB.schema_definition.DB instance at 0x0000000029DEA448> is well defined
2019-01-28 15:06:15 - run.py - <module> - INFO - module <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x0000000029DED208> is well defined
2019-01-28 15:06:15 - run.py - <module> - INFO - module <dataset_builder.feature_extractor.cooperation_topic_feature_generator.CooperationTopicFeatureGenerator object at 0x000000002F22AA20> is well defined
2019-01-28 15:06:15 - run.py - <module> - INFO - execute module: <DB.schema_definition.DB instance at 0x0000000029DEA448>
2019-01-28 15:06:15 - run.py - <module> - INFO - *********Started executing DB
2019-01-28 15:06:15 - run.py - <module> - INFO - *********Finished executing DB
2019-01-28 15:06:15 - run.py - <module> - INFO - execute module: <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x0000000029DED208>
2019-01-28 15:06:15 - run.py - <module> - INFO - *********Started executing AddAuthorConnectionClaimId
2019-01-28 15:06:54 - run.py - <module> - INFO - *********Finished executing AddAuthorConnectionClaimId
2019-01-28 15:06:54 - run.py - <module> - INFO - execute module: <dataset_builder.feature_extractor.cooperation_topic_feature_generator.CooperationTopicFeatureGenerator object at 0x000000002F22AA20>
2019-01-28 15:06:54 - run.py - <module> - INFO - *********Started executing CooperationTopicFeatureGenerator
2019-01-28 15:06:54 - cooperation_topic_feature_generator.py - execute - INFO - execute started for Cooperation topic feature generator started at 1548680814.33
2019-01-28 15:06:54 - cooperation_topic_feature_generator.py - execute - INFO - Cooperation execute window_start 2000-06-07 00:00:00
2019-01-28 15:09:17 - cooperation_topic_feature_generator.py - execute - INFO - Started 1 claim from 398 claims
2019-01-28 15:15:47 - run.py - <module> - INFO - Start Execution ... 
2019-01-28 15:15:47 - run.py - <module> - INFO - SETUP global variables
2019-01-28 15:15:47 - run.py - <module> - INFO - CREATE pipeline
2019-01-28 15:15:47 - run.py - <module> - INFO - SETUP pipeline
2019-01-28 15:15:47 - run.py - <module> - INFO - setup module: <DB.schema_definition.DB instance at 0x000000002EC8F148>
2019-01-28 15:15:47 - run.py - <module> - INFO - setup module: <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x0000000029844240>
2019-01-28 15:15:47 - run.py - <module> - INFO - setup module: <dataset_builder.feature_extractor.cooperation_topic_feature_generator.CooperationTopicFeatureGenerator object at 0x000000002EC95A58>
2019-01-28 15:15:47 - run.py - <module> - INFO - checking module definition
2019-01-28 15:15:47 - run.py - <module> - INFO - module <DB.schema_definition.DB instance at 0x000000002EC8F148> is well defined
2019-01-28 15:15:47 - run.py - <module> - INFO - module <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x0000000029844240> is well defined
2019-01-28 15:15:47 - run.py - <module> - INFO - module <dataset_builder.feature_extractor.cooperation_topic_feature_generator.CooperationTopicFeatureGenerator object at 0x000000002EC95A58> is well defined
2019-01-28 15:15:47 - run.py - <module> - INFO - execute module: <DB.schema_definition.DB instance at 0x000000002EC8F148>
2019-01-28 15:15:47 - run.py - <module> - INFO - *********Started executing DB
2019-01-28 15:15:47 - run.py - <module> - INFO - *********Finished executing DB
2019-01-28 15:15:47 - run.py - <module> - INFO - execute module: <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x0000000029844240>
2019-01-28 15:15:47 - run.py - <module> - INFO - *********Started executing AddAuthorConnectionClaimId
2019-01-28 15:16:25 - run.py - <module> - INFO - *********Finished executing AddAuthorConnectionClaimId
2019-01-28 15:16:25 - run.py - <module> - INFO - execute module: <dataset_builder.feature_extractor.cooperation_topic_feature_generator.CooperationTopicFeatureGenerator object at 0x000000002EC95A58>
2019-01-28 15:16:25 - run.py - <module> - INFO - *********Started executing CooperationTopicFeatureGenerator
2019-01-28 15:16:25 - cooperation_topic_feature_generator.py - execute - INFO - execute started for Cooperation topic feature generator started at 1548681385.76
2019-01-28 15:16:25 - cooperation_topic_feature_generator.py - execute - INFO - Cooperation execute window_start 2000-06-07 00:00:00
2019-01-28 15:18:49 - cooperation_topic_feature_generator.py - execute - INFO - Started 1 claim from 398 claims
2019-01-28 15:28:49 - run.py - <module> - INFO - Start Execution ... 
2019-01-28 15:28:49 - run.py - <module> - INFO - SETUP global variables
2019-01-28 15:28:49 - run.py - <module> - INFO - CREATE pipeline
2019-01-28 15:28:49 - run.py - <module> - INFO - SETUP pipeline
2019-01-28 15:28:49 - run.py - <module> - INFO - setup module: <DB.schema_definition.DB instance at 0x000000002E67C648>
2019-01-28 15:28:49 - run.py - <module> - INFO - setup module: <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x00000000294FC208>
2019-01-28 15:28:49 - run.py - <module> - INFO - setup module: <dataset_builder.feature_extractor.cooperation_topic_feature_generator.CooperationTopicFeatureGenerator object at 0x000000002E67EA20>
2019-01-28 15:28:49 - run.py - <module> - INFO - checking module definition
2019-01-28 15:28:49 - run.py - <module> - INFO - module <DB.schema_definition.DB instance at 0x000000002E67C648> is well defined
2019-01-28 15:28:49 - run.py - <module> - INFO - module <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x00000000294FC208> is well defined
2019-01-28 15:28:49 - run.py - <module> - INFO - module <dataset_builder.feature_extractor.cooperation_topic_feature_generator.CooperationTopicFeatureGenerator object at 0x000000002E67EA20> is well defined
2019-01-28 15:28:49 - run.py - <module> - INFO - execute module: <DB.schema_definition.DB instance at 0x000000002E67C648>
2019-01-28 15:28:49 - run.py - <module> - INFO - *********Started executing DB
2019-01-28 15:28:49 - run.py - <module> - INFO - *********Finished executing DB
2019-01-28 15:28:49 - run.py - <module> - INFO - execute module: <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x00000000294FC208>
2019-01-28 15:28:49 - run.py - <module> - INFO - *********Started executing AddAuthorConnectionClaimId
2019-01-28 15:29:28 - run.py - <module> - INFO - *********Finished executing AddAuthorConnectionClaimId
2019-01-28 15:29:28 - run.py - <module> - INFO - execute module: <dataset_builder.feature_extractor.cooperation_topic_feature_generator.CooperationTopicFeatureGenerator object at 0x000000002E67EA20>
2019-01-28 15:29:28 - run.py - <module> - INFO - *********Started executing CooperationTopicFeatureGenerator
2019-01-28 15:29:28 - cooperation_topic_feature_generator.py - execute - INFO - execute started for Cooperation topic feature generator started at 1548682168.08
2019-01-28 15:29:28 - cooperation_topic_feature_generator.py - execute - INFO - Cooperation execute window_start 2000-06-07 00:00:00
2019-01-28 15:31:51 - cooperation_topic_feature_generator.py - execute - INFO - Started 1 claim from 398 claims
2019-01-29 08:41:56 - run.py - <module> - INFO - Start Execution ... 
2019-01-29 08:41:56 - run.py - <module> - INFO - SETUP global variables
2019-01-29 08:41:56 - run.py - <module> - INFO - CREATE pipeline
2019-01-29 08:41:56 - run.py - <module> - INFO - SETUP pipeline
2019-01-29 08:41:56 - run.py - <module> - INFO - setup module: <DB.schema_definition.DB instance at 0x000000002E85EE88>
2019-01-29 08:41:56 - run.py - <module> - INFO - setup module: <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x00000000295B3320>
2019-01-29 08:41:56 - run.py - <module> - INFO - setup module: <dataset_builder.feature_extractor.cooperation_topic_feature_generator.CooperationTopicFeatureGenerator object at 0x000000002EA2EE10>
2019-01-29 08:41:56 - run.py - <module> - INFO - checking module definition
2019-01-29 08:41:56 - run.py - <module> - INFO - module <DB.schema_definition.DB instance at 0x000000002E85EE88> is well defined
2019-01-29 08:41:56 - run.py - <module> - INFO - module <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x00000000295B3320> is well defined
2019-01-29 08:41:56 - run.py - <module> - INFO - module <dataset_builder.feature_extractor.cooperation_topic_feature_generator.CooperationTopicFeatureGenerator object at 0x000000002EA2EE10> is well defined
2019-01-29 08:41:56 - run.py - <module> - INFO - execute module: <DB.schema_definition.DB instance at 0x000000002E85EE88>
2019-01-29 08:41:56 - run.py - <module> - INFO - *********Started executing DB
2019-01-29 08:41:56 - run.py - <module> - INFO - *********Finished executing DB
2019-01-29 08:41:56 - run.py - <module> - INFO - execute module: <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x00000000295B3320>
2019-01-29 08:41:56 - run.py - <module> - INFO - *********Started executing AddAuthorConnectionClaimId
2019-01-29 08:42:34 - run.py - <module> - INFO - *********Finished executing AddAuthorConnectionClaimId
2019-01-29 08:42:34 - run.py - <module> - INFO - execute module: <dataset_builder.feature_extractor.cooperation_topic_feature_generator.CooperationTopicFeatureGenerator object at 0x000000002EA2EE10>
2019-01-29 08:42:34 - run.py - <module> - INFO - *********Started executing CooperationTopicFeatureGenerator
2019-01-29 08:42:34 - cooperation_topic_feature_generator.py - execute - INFO - execute started for Cooperation topic feature generator started at 1548744154.84
2019-01-29 08:42:34 - cooperation_topic_feature_generator.py - execute - INFO - Cooperation execute window_start 2000-06-07 00:00:00
2019-01-29 08:45:24 - cooperation_topic_feature_generator.py - execute - INFO - Started 1 claim from 398 claims
2019-01-29 08:48:17 - run.py - <module> - INFO - Start Execution ... 
2019-01-29 08:48:17 - run.py - <module> - INFO - SETUP global variables
2019-01-29 08:48:17 - run.py - <module> - INFO - CREATE pipeline
2019-01-29 08:48:17 - run.py - <module> - INFO - SETUP pipeline
2019-01-29 08:48:17 - run.py - <module> - INFO - setup module: <DB.schema_definition.DB instance at 0x000000002ED62548>
2019-01-29 08:48:17 - run.py - <module> - INFO - setup module: <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x0000000029BEF208>
2019-01-29 08:48:17 - run.py - <module> - INFO - setup module: <dataset_builder.feature_extractor.cooperation_topic_feature_generator.CooperationTopicFeatureGenerator object at 0x000000002ED63AC8>
2019-01-29 08:48:17 - run.py - <module> - INFO - checking module definition
2019-01-29 08:48:17 - run.py - <module> - INFO - module <DB.schema_definition.DB instance at 0x000000002ED62548> is well defined
2019-01-29 08:48:17 - run.py - <module> - INFO - module <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x0000000029BEF208> is well defined
2019-01-29 08:48:17 - run.py - <module> - INFO - module <dataset_builder.feature_extractor.cooperation_topic_feature_generator.CooperationTopicFeatureGenerator object at 0x000000002ED63AC8> is well defined
2019-01-29 08:48:17 - run.py - <module> - INFO - execute module: <DB.schema_definition.DB instance at 0x000000002ED62548>
2019-01-29 08:48:17 - run.py - <module> - INFO - *********Started executing DB
2019-01-29 08:48:17 - run.py - <module> - INFO - *********Finished executing DB
2019-01-29 08:48:17 - run.py - <module> - INFO - execute module: <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x0000000029BEF208>
2019-01-29 08:48:17 - run.py - <module> - INFO - *********Started executing AddAuthorConnectionClaimId
2019-01-29 08:48:55 - run.py - <module> - INFO - *********Finished executing AddAuthorConnectionClaimId
2019-01-29 08:48:55 - run.py - <module> - INFO - execute module: <dataset_builder.feature_extractor.cooperation_topic_feature_generator.CooperationTopicFeatureGenerator object at 0x000000002ED63AC8>
2019-01-29 08:48:55 - run.py - <module> - INFO - *********Started executing CooperationTopicFeatureGenerator
2019-01-29 08:48:55 - cooperation_topic_feature_generator.py - execute - INFO - execute started for Cooperation topic feature generator started at 1548744535.89
2019-01-29 08:48:55 - cooperation_topic_feature_generator.py - execute - INFO - Cooperation execute window_start 2000-06-07 00:00:00
2019-01-29 08:51:12 - cooperation_topic_feature_generator.py - execute - INFO - Started 1 claim from 398 claims
2019-01-29 08:59:59 - run.py - <module> - INFO - Start Execution ... 
2019-01-29 08:59:59 - run.py - <module> - INFO - SETUP global variables
2019-01-29 08:59:59 - run.py - <module> - INFO - CREATE pipeline
2019-01-29 08:59:59 - run.py - <module> - INFO - SETUP pipeline
2019-01-29 08:59:59 - run.py - <module> - INFO - setup module: <DB.schema_definition.DB instance at 0x000000002D82E088>
2019-01-29 08:59:59 - run.py - <module> - INFO - setup module: <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x000000002D7DCB38>
2019-01-29 08:59:59 - run.py - <module> - INFO - setup module: <dataset_builder.feature_extractor.cooperation_topic_feature_generator.CooperationTopicFeatureGenerator object at 0x000000002D7E8908>
2019-01-29 08:59:59 - run.py - <module> - INFO - checking module definition
2019-01-29 08:59:59 - run.py - <module> - INFO - module <DB.schema_definition.DB instance at 0x000000002D82E088> is well defined
2019-01-29 08:59:59 - run.py - <module> - INFO - module <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x000000002D7DCB38> is well defined
2019-01-29 08:59:59 - run.py - <module> - INFO - module <dataset_builder.feature_extractor.cooperation_topic_feature_generator.CooperationTopicFeatureGenerator object at 0x000000002D7E8908> is well defined
2019-01-29 08:59:59 - run.py - <module> - INFO - execute module: <DB.schema_definition.DB instance at 0x000000002D82E088>
2019-01-29 08:59:59 - run.py - <module> - INFO - *********Started executing DB
2019-01-29 08:59:59 - run.py - <module> - INFO - *********Finished executing DB
2019-01-29 08:59:59 - run.py - <module> - INFO - execute module: <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x000000002D7DCB38>
2019-01-29 08:59:59 - run.py - <module> - INFO - *********Started executing AddAuthorConnectionClaimId
2019-01-29 09:00:34 - run.py - <module> - INFO - *********Finished executing AddAuthorConnectionClaimId
2019-01-29 09:00:34 - run.py - <module> - INFO - execute module: <dataset_builder.feature_extractor.cooperation_topic_feature_generator.CooperationTopicFeatureGenerator object at 0x000000002D7E8908>
2019-01-29 09:00:34 - run.py - <module> - INFO - *********Started executing CooperationTopicFeatureGenerator
2019-01-29 09:00:34 - cooperation_topic_feature_generator.py - execute - INFO - execute started for Cooperation topic feature generator started at 1548745234.4
2019-01-29 09:00:34 - cooperation_topic_feature_generator.py - execute - INFO - Cooperation execute window_start 2000-06-07 00:00:00
2019-01-29 09:01:41 - cooperation_topic_feature_generator.py - execute - INFO - Started 1 claim from 398 claims
2019-01-29 09:33:27 - run.py - <module> - INFO - Start Execution ... 
2019-01-29 09:33:27 - run.py - <module> - INFO - SETUP global variables
2019-01-29 09:33:27 - run.py - <module> - INFO - CREATE pipeline
2019-01-29 09:33:27 - run.py - <module> - INFO - SETUP pipeline
2019-01-29 09:33:27 - run.py - <module> - INFO - setup module: <DB.schema_definition.DB instance at 0x000000002E1F6648>
2019-01-29 09:33:27 - run.py - <module> - INFO - setup module: <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x0000000028882080>
2019-01-29 09:33:27 - run.py - <module> - INFO - setup module: <dataset_builder.feature_extractor.cooperation_topic_feature_generator.CooperationTopicFeatureGenerator object at 0x000000002E1F8A90>
2019-01-29 09:33:27 - run.py - <module> - INFO - checking module definition
2019-01-29 09:33:27 - run.py - <module> - INFO - module <DB.schema_definition.DB instance at 0x000000002E1F6648> is well defined
2019-01-29 09:33:27 - run.py - <module> - INFO - module <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x0000000028882080> is well defined
2019-01-29 09:33:27 - run.py - <module> - INFO - module <dataset_builder.feature_extractor.cooperation_topic_feature_generator.CooperationTopicFeatureGenerator object at 0x000000002E1F8A90> is well defined
2019-01-29 09:33:27 - run.py - <module> - INFO - execute module: <DB.schema_definition.DB instance at 0x000000002E1F6648>
2019-01-29 09:33:27 - run.py - <module> - INFO - *********Started executing DB
2019-01-29 09:33:27 - run.py - <module> - INFO - *********Finished executing DB
2019-01-29 09:33:27 - run.py - <module> - INFO - execute module: <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x0000000028882080>
2019-01-29 09:33:27 - run.py - <module> - INFO - *********Started executing AddAuthorConnectionClaimId
2019-01-29 09:34:02 - run.py - <module> - INFO - *********Finished executing AddAuthorConnectionClaimId
2019-01-29 09:34:02 - run.py - <module> - INFO - execute module: <dataset_builder.feature_extractor.cooperation_topic_feature_generator.CooperationTopicFeatureGenerator object at 0x000000002E1F8A90>
2019-01-29 09:34:02 - run.py - <module> - INFO - *********Started executing CooperationTopicFeatureGenerator
2019-01-29 09:34:02 - cooperation_topic_feature_generator.py - execute - INFO - execute started for Cooperation topic feature generator started at 1548747242.16
2019-01-29 09:34:02 - cooperation_topic_feature_generator.py - execute - INFO - Cooperation execute window_start 2000-06-07 00:00:00
2019-01-29 09:35:09 - cooperation_topic_feature_generator.py - execute - INFO - Started 1 claim from 398 claims
2019-01-29 10:49:47 - run.py - <module> - INFO - Start Execution ... 
2019-01-29 10:49:47 - run.py - <module> - INFO - SETUP global variables
2019-01-29 10:49:47 - run.py - <module> - INFO - CREATE pipeline
2019-01-29 10:49:47 - run.py - <module> - INFO - SETUP pipeline
2019-01-29 10:49:47 - run.py - <module> - INFO - setup module: <DB.schema_definition.DB instance at 0x000000002E1D7B88>
2019-01-29 10:49:47 - run.py - <module> - INFO - setup module: <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x0000000028EAD1D0>
2019-01-29 10:49:47 - run.py - <module> - INFO - setup module: <dataset_builder.feature_extractor.cooperation_topic_feature_generator.CooperationTopicFeatureGenerator object at 0x000000002E2B9B38>
2019-01-29 10:49:47 - run.py - <module> - INFO - checking module definition
2019-01-29 10:49:47 - run.py - <module> - INFO - module <DB.schema_definition.DB instance at 0x000000002E1D7B88> is well defined
2019-01-29 10:49:47 - run.py - <module> - INFO - module <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x0000000028EAD1D0> is well defined
2019-01-29 10:49:47 - run.py - <module> - INFO - module <dataset_builder.feature_extractor.cooperation_topic_feature_generator.CooperationTopicFeatureGenerator object at 0x000000002E2B9B38> is well defined
2019-01-29 10:49:47 - run.py - <module> - INFO - execute module: <DB.schema_definition.DB instance at 0x000000002E1D7B88>
2019-01-29 10:49:47 - run.py - <module> - INFO - *********Started executing DB
2019-01-29 10:49:47 - run.py - <module> - INFO - *********Finished executing DB
2019-01-29 10:49:47 - run.py - <module> - INFO - execute module: <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x0000000028EAD1D0>
2019-01-29 10:49:47 - run.py - <module> - INFO - *********Started executing AddAuthorConnectionClaimId
2019-01-29 10:50:28 - run.py - <module> - INFO - *********Finished executing AddAuthorConnectionClaimId
2019-01-29 10:50:28 - run.py - <module> - INFO - execute module: <dataset_builder.feature_extractor.cooperation_topic_feature_generator.CooperationTopicFeatureGenerator object at 0x000000002E2B9B38>
2019-01-29 10:50:28 - run.py - <module> - INFO - *********Started executing CooperationTopicFeatureGenerator
2019-01-29 10:50:28 - cooperation_topic_feature_generator.py - execute - INFO - execute started for Cooperation topic feature generator started at 1548751828.03
2019-01-29 10:50:28 - cooperation_topic_feature_generator.py - execute - INFO - Cooperation execute window_start 2000-06-07 00:00:00
2019-01-29 10:52:52 - cooperation_topic_feature_generator.py - execute - INFO - Started 1 claim from 398 claims
2019-01-29 12:44:52 - run.py - <module> - INFO - Start Execution ... 
2019-01-29 12:44:52 - run.py - <module> - INFO - SETUP global variables
2019-01-29 12:44:52 - run.py - <module> - INFO - CREATE pipeline
2019-01-29 12:44:52 - run.py - <module> - INFO - SETUP pipeline
2019-01-29 12:44:52 - run.py - <module> - INFO - setup module: <DB.schema_definition.DB instance at 0x000000002DC2F508>
2019-01-29 12:44:52 - run.py - <module> - INFO - setup module: <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x0000000028282080>
2019-01-29 12:44:52 - run.py - <module> - INFO - setup module: <dataset_builder.feature_extractor.cooperation_topic_feature_generator.CooperationTopicFeatureGenerator object at 0x000000002DC249B0>
2019-01-29 12:44:52 - run.py - <module> - INFO - checking module definition
2019-01-29 12:44:52 - run.py - <module> - INFO - module <DB.schema_definition.DB instance at 0x000000002DC2F508> is well defined
2019-01-29 12:44:52 - run.py - <module> - INFO - module <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x0000000028282080> is well defined
2019-01-29 12:44:52 - run.py - <module> - INFO - module <dataset_builder.feature_extractor.cooperation_topic_feature_generator.CooperationTopicFeatureGenerator object at 0x000000002DC249B0> is well defined
2019-01-29 12:44:52 - run.py - <module> - INFO - execute module: <DB.schema_definition.DB instance at 0x000000002DC2F508>
2019-01-29 12:44:52 - run.py - <module> - INFO - *********Started executing DB
2019-01-29 12:44:52 - run.py - <module> - INFO - *********Finished executing DB
2019-01-29 12:44:52 - run.py - <module> - INFO - execute module: <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x0000000028282080>
2019-01-29 12:44:52 - run.py - <module> - INFO - *********Started executing AddAuthorConnectionClaimId
2019-01-29 21:58:35 - run.py - <module> - INFO - Start Execution ... 
2019-01-29 21:58:35 - run.py - <module> - INFO - SETUP global variables
2019-01-29 21:58:35 - run.py - <module> - INFO - CREATE pipeline
2019-01-29 21:58:35 - run.py - <module> - INFO - SETUP pipeline
2019-01-29 21:58:35 - run.py - <module> - INFO - setup module: <DB.schema_definition.DB instance at 0x000000002E282648>
2019-01-29 21:58:35 - run.py - <module> - INFO - setup module: <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x00000000288E2080>
2019-01-29 21:58:35 - run.py - <module> - INFO - setup module: <dataset_builder.feature_extractor.cooperation_topic_feature_generator.CooperationTopicFeatureGenerator object at 0x000000002E284A90>
2019-01-29 21:58:35 - run.py - <module> - INFO - checking module definition
2019-01-29 21:58:35 - run.py - <module> - INFO - module <DB.schema_definition.DB instance at 0x000000002E282648> is well defined
2019-01-29 21:58:35 - run.py - <module> - INFO - module <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x00000000288E2080> is well defined
2019-01-29 21:58:35 - run.py - <module> - INFO - module <dataset_builder.feature_extractor.cooperation_topic_feature_generator.CooperationTopicFeatureGenerator object at 0x000000002E284A90> is well defined
2019-01-29 21:58:35 - run.py - <module> - INFO - execute module: <DB.schema_definition.DB instance at 0x000000002E282648>
2019-01-29 21:58:35 - run.py - <module> - INFO - *********Started executing DB
2019-01-29 21:58:35 - run.py - <module> - INFO - *********Finished executing DB
2019-01-29 21:58:35 - run.py - <module> - INFO - execute module: <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x00000000288E2080>
2019-01-29 21:58:35 - run.py - <module> - INFO - *********Started executing AddAuthorConnectionClaimId
2019-01-30 00:23:12 - run.py - <module> - INFO - Start Execution ... 
2019-01-30 00:23:12 - run.py - <module> - INFO - SETUP global variables
2019-01-30 00:23:12 - run.py - <module> - INFO - CREATE pipeline
2019-01-30 00:23:12 - run.py - <module> - INFO - SETUP pipeline
2019-01-30 00:23:12 - run.py - <module> - INFO - setup module: <DB.schema_definition.DB instance at 0x000000002E06F508>
2019-01-30 00:23:12 - run.py - <module> - INFO - setup module: <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x00000000287B2080>
2019-01-30 00:23:12 - run.py - <module> - INFO - setup module: <dataset_builder.feature_extractor.cooperation_topic_feature_generator.CooperationTopicFeatureGenerator object at 0x000000002E0649B0>
2019-01-30 00:23:12 - run.py - <module> - INFO - checking module definition
2019-01-30 00:23:12 - run.py - <module> - INFO - module <DB.schema_definition.DB instance at 0x000000002E06F508> is well defined
2019-01-30 00:23:12 - run.py - <module> - INFO - module <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x00000000287B2080> is well defined
2019-01-30 00:23:12 - run.py - <module> - INFO - module <dataset_builder.feature_extractor.cooperation_topic_feature_generator.CooperationTopicFeatureGenerator object at 0x000000002E0649B0> is well defined
2019-01-30 00:23:12 - run.py - <module> - INFO - execute module: <DB.schema_definition.DB instance at 0x000000002E06F508>
2019-01-30 00:23:12 - run.py - <module> - INFO - *********Started executing DB
2019-01-30 00:23:12 - run.py - <module> - INFO - *********Finished executing DB
2019-01-30 00:23:12 - run.py - <module> - INFO - execute module: <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x00000000287B2080>
2019-01-30 00:23:12 - run.py - <module> - INFO - *********Started executing AddAuthorConnectionClaimId
2019-01-30 14:47:54 - run.py - <module> - INFO - *********Finished executing AddAuthorConnectionClaimId
2019-01-30 14:47:54 - run.py - <module> - INFO - execute module: <dataset_builder.feature_extractor.cooperation_topic_feature_generator.CooperationTopicFeatureGenerator object at 0x000000002E0649B0>
2019-01-30 14:47:54 - run.py - <module> - INFO - *********Started executing CooperationTopicFeatureGenerator
2019-01-30 14:47:54 - cooperation_topic_feature_generator.py - execute - INFO - execute started for Cooperation topic feature generator started at 1548852474.42
2019-01-30 14:47:54 - cooperation_topic_feature_generator.py - execute - INFO - Cooperation execute window_start 2000-06-07 00:00:00
2019-01-30 14:49:08 - cooperation_topic_feature_generator.py - execute - INFO - Started 1 claim from 398 claims
2019-01-30 14:49:12 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:49:15 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:49:17 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:49:19 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:49:22 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:49:24 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:49:26 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:49:28 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:49:31 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:49:33 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:49:35 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:49:38 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:49:40 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:49:42 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:49:45 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:49:47 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:49:49 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:49:51 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:49:54 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:49:56 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:49:58 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:50:01 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:50:03 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:50:05 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:50:07 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:50:10 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:50:12 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:50:14 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:50:17 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:50:19 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:50:21 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:50:23 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:50:26 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:50:28 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:50:30 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:50:33 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:50:35 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:50:37 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:50:39 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:50:42 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:50:44 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:50:46 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:50:49 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:50:51 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:50:53 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:50:56 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:50:58 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:51:00 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:51:02 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:51:05 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:51:07 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:51:09 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:51:12 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:51:14 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:51:16 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:51:18 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:51:21 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:51:23 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:51:25 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:51:28 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:51:30 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:51:32 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:51:34 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:51:37 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:51:39 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:51:41 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:51:44 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:51:46 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:51:48 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:51:51 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:51:53 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:51:55 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:51:57 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:52:00 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:52:02 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:52:04 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:52:07 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:52:09 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:52:11 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:52:13 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:52:16 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:52:18 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:52:20 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:52:23 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:52:25 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:52:27 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:52:29 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:52:32 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:52:34 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:52:36 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:52:39 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:52:41 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:52:43 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:52:46 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:52:48 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:52:50 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:52:52 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:52:55 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:52:57 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:52:59 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:53:02 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:53:04 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:53:06 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:53:08 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:53:11 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:53:13 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:53:15 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:53:18 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:53:20 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:53:22 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:53:24 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:53:27 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:53:29 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:53:31 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:53:34 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:53:36 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:53:38 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:53:41 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:53:43 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:53:45 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:53:47 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:53:50 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:53:52 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:53:54 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:53:57 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:53:59 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:54:01 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:54:03 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:54:06 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:54:08 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:54:10 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:54:13 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:54:15 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:54:17 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:54:19 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:54:22 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:54:24 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:54:26 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:54:29 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:54:31 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:54:33 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:54:35 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:54:38 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:54:40 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:54:42 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:54:45 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:54:47 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:54:49 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:54:52 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:54:54 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:54:56 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:54:58 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:55:01 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:55:03 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:55:05 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:55:08 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:55:10 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:55:12 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:55:14 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:55:17 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:55:19 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:55:21 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:55:24 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:55:26 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:55:28 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:55:31 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:55:33 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:55:35 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:55:37 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:55:40 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:55:42 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:55:44 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:55:47 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:55:49 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:55:51 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:55:54 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:55:56 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:55:58 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:56:00 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:56:03 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:56:05 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:56:07 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:56:10 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:56:12 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:56:14 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:56:16 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:56:19 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:56:21 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:56:23 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:56:26 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:56:28 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:56:30 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:56:32 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:56:35 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:56:37 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:56:39 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:56:42 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:56:44 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:56:46 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:56:49 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:56:51 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:56:53 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:56:55 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:56:58 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:57:00 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:57:02 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:57:05 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:57:07 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:57:09 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:57:11 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:57:14 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:57:16 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:57:18 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:57:21 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:57:23 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:57:25 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:57:27 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:57:30 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:57:32 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:57:34 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:57:37 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:57:39 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:57:41 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:57:44 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:57:46 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:57:48 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:57:50 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:57:53 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:57:55 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:57:57 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:58:00 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:58:02 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:58:04 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:58:07 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:58:09 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:58:11 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:58:13 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:58:16 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:58:18 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:58:20 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:58:23 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:58:25 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:58:27 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:58:29 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:58:32 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:58:34 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:58:36 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:58:39 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:58:41 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:58:43 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:58:45 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:58:48 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:58:50 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:58:52 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:58:55 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:58:57 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:58:59 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:59:01 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:59:04 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:59:06 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:59:08 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:59:11 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:59:13 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:59:15 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:59:17 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:59:20 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:59:22 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:59:24 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:59:27 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:59:29 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:59:31 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:59:33 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:59:36 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:59:38 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:59:40 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:59:43 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:59:45 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:59:47 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:59:49 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:59:52 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:59:54 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:59:56 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 14:59:59 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:00:01 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:00:03 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:00:05 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:00:08 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:00:10 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:00:12 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:00:15 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:00:17 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:00:19 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:00:22 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:00:24 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:00:26 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:00:29 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:00:31 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:00:33 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:00:35 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:00:38 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:00:40 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:00:42 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:00:45 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:00:47 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:00:49 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:00:52 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:00:54 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:00:56 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:00:59 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:01:01 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:01:03 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:01:06 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:01:08 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:01:10 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:01:13 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:01:15 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:01:17 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:01:20 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:01:22 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:01:25 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:01:27 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:01:29 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:01:31 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:01:34 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:01:36 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:01:38 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:01:41 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:01:43 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:01:45 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:01:48 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:01:50 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:01:52 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:01:55 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:01:57 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:01:59 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:02:02 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:02:04 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:02:06 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:02:09 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:02:11 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:02:13 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:02:16 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:02:18 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:02:20 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:02:23 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:02:25 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:02:27 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:02:29 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:02:32 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:02:34 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:02:36 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:02:39 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:02:41 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:02:43 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:02:45 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:02:48 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:02:50 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:02:52 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:02:55 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:02:57 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:02:59 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:03:02 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:03:04 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:03:06 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:03:08 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:03:11 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:03:13 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:03:15 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:03:18 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:03:20 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:03:22 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:03:25 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:03:27 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:03:29 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:03:31 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:03:34 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:03:36 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:03:38 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:03:41 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:03:43 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:03:45 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:03:48 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:03:50 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:03:52 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:03:55 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:03:57 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:03:59 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:04:02 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:04:04 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:04:06 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:04:08 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:04:11 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:04:13 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:04:15 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:04:18 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:04:20 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:04:22 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:04:24 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:04:27 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:04:29 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:04:31 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:04:33 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:04:36 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:04:38 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:04:40 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:04:43 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:04:45 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:04:47 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:04:49 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:04:52 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:04:54 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:04:56 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:04:59 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:05:01 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:05:03 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:05:05 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:05:08 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:05:10 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:05:12 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:05:15 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:05:17 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:05:19 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:05:22 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:05:24 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:05:26 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:05:28 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:05:31 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:05:33 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:05:35 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:05:38 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:05:40 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:05:42 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:05:44 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:05:47 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:05:49 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:05:51 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:05:54 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:05:56 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:05:58 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:06:01 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:06:03 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:06:05 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:06:07 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:06:10 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:06:12 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:06:14 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:06:17 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:06:19 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:06:21 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:06:23 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:06:26 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:06:28 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:06:30 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:06:33 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:06:35 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:06:37 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:06:39 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:06:42 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:06:44 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:06:46 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:06:49 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:06:51 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:06:53 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:06:55 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:06:58 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:07:00 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:07:02 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:07:05 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:07:07 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:07:09 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:07:11 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:07:14 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:07:16 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:07:18 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:07:21 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:07:23 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:07:25 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:07:27 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:07:30 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:07:32 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:07:34 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:07:37 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:07:39 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:07:41 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:07:44 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:07:46 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:07:48 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:07:51 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:07:53 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:07:55 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:07:57 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:08:00 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:08:02 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:08:04 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:08:07 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:08:09 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:08:11 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:08:13 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:08:16 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:08:18 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:08:20 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:08:23 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:08:25 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:08:27 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:08:30 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:08:32 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:08:34 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:08:36 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:08:39 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:08:41 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:08:43 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:08:46 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:08:48 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:08:50 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:08:52 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:08:55 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:08:57 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:08:59 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:09:01 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:09:04 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:09:06 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:09:08 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:09:11 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:09:13 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:09:15 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:09:17 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:09:20 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:09:22 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:09:24 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:09:27 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:09:29 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:09:31 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:09:34 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:09:36 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:09:38 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:09:40 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:09:43 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:09:45 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:09:47 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:09:49 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:09:52 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:09:54 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:09:56 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:09:59 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:10:01 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:10:03 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:10:06 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:10:08 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:10:10 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:10:12 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:10:15 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:10:17 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:10:19 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:10:22 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:10:24 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:10:26 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:10:28 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:10:31 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:10:33 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:10:35 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:10:38 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:10:40 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:10:42 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:10:44 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:10:47 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:10:49 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:10:51 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:10:54 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:10:56 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:10:58 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:11:01 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:11:03 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:11:05 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:11:07 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:11:10 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:11:12 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:11:14 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:11:17 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:11:19 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:11:21 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:11:23 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:11:26 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:11:28 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:11:30 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:11:33 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:11:35 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:11:37 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:11:40 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:11:42 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:11:44 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:11:46 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:11:49 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:11:51 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:11:53 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:11:56 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:11:58 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:12:00 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:12:02 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:12:05 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:12:07 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:12:09 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:12:12 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:12:14 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:12:16 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:12:19 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:12:21 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:12:23 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:12:25 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:12:28 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:12:30 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:12:32 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:12:35 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:12:37 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:12:39 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:12:41 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:12:44 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:12:46 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:12:48 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:12:51 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:12:53 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:12:55 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:12:58 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:13:00 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:13:02 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:13:04 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:13:07 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:13:09 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:13:11 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:13:14 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:13:16 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:13:18 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:13:21 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:13:23 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:13:25 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:13:27 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:13:30 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:13:32 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:13:34 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:13:37 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:13:39 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:13:41 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:13:44 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:13:46 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:13:48 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:13:50 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:13:53 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:13:55 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:13:57 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:14:00 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:14:02 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:14:04 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:14:06 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:14:09 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:14:11 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:14:13 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:14:16 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:14:18 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:14:20 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:14:23 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:14:25 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:14:27 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:14:30 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:14:32 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:14:34 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:14:36 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:14:39 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:14:41 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:14:43 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:14:46 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:14:48 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:14:50 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:14:52 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:14:55 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:14:57 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:14:59 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:15:02 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:15:04 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:15:06 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:15:09 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:15:11 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:15:13 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:15:15 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:15:18 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:15:20 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:15:22 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:15:25 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:15:27 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:15:29 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:15:32 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:15:34 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:15:36 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:15:38 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:15:41 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:15:43 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:15:45 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:15:48 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:15:50 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:15:52 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:15:54 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:15:57 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:15:59 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:16:01 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:16:04 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:16:06 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:16:08 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:16:10 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:16:13 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:16:15 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:16:17 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:16:20 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:16:22 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:16:24 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:16:27 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:16:29 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:16:31 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:16:33 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:16:36 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:16:38 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:16:40 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:16:43 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:16:45 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:16:47 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:16:49 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:16:52 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:16:54 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:16:56 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:16:59 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:17:01 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:17:03 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:17:05 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:17:08 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:17:10 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:17:12 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:17:15 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:17:17 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:17:19 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:17:21 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:17:24 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:17:26 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:17:28 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:17:31 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:17:33 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:17:35 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:17:37 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:17:40 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:17:42 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:17:44 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:17:47 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:17:49 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:17:51 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:17:53 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:17:56 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:17:58 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:18:00 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:18:03 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:18:05 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:18:07 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:18:09 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:18:12 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:18:14 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:18:16 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:18:18 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:18:21 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:18:23 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:18:25 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:18:28 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:18:30 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:18:32 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:18:34 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:18:37 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:18:39 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:18:41 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:18:44 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:18:46 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:18:48 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:18:51 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:18:53 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:18:55 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:18:58 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:19:00 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:19:02 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:19:04 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:19:07 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:19:09 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:19:11 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:19:14 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:19:16 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:19:18 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:19:21 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:19:23 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:19:25 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:19:28 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:19:30 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:19:32 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:19:35 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:19:37 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:19:39 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:19:41 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:19:44 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:19:46 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:19:48 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:19:51 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:19:53 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:19:55 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:19:58 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:20:00 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:20:02 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:20:04 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:20:07 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:20:09 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:20:11 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:20:14 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:20:16 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:20:18 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:20:20 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:20:23 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:20:25 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:20:27 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:20:29 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:20:32 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:20:34 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:20:36 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:20:39 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:20:41 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:20:43 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:20:46 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:20:48 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:20:50 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:20:52 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:20:55 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:20:57 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:20:59 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:21:02 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:21:04 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:21:06 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:21:08 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:21:11 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:21:13 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:21:15 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:21:18 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:21:20 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:21:22 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:21:24 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:21:27 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:21:29 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:21:31 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:21:34 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:21:36 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:21:38 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:21:40 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:21:43 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:21:45 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:21:47 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:21:50 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:21:52 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:21:54 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:21:56 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:21:59 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:22:01 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:22:03 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:22:06 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:22:08 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:22:10 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:22:12 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:22:15 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:22:17 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:22:19 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:22:22 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:22:24 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:22:26 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:22:29 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:22:31 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:22:33 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:22:35 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:22:38 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:22:40 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:22:42 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:22:45 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:22:47 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:22:49 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:22:52 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:22:54 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:22:56 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:22:59 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:23:01 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:23:03 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:23:06 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:23:08 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:23:10 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:23:13 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:23:15 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:23:17 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:23:20 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:23:22 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:23:25 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:23:27 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:23:29 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:23:32 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:23:34 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:23:36 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:23:38 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:23:41 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:23:43 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:23:45 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:23:48 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:23:50 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:23:52 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:23:55 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:23:57 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:23:59 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:24:02 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:24:04 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:24:06 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:24:09 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:24:11 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:24:13 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:24:16 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:24:18 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:24:20 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:24:22 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:24:25 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:24:27 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:24:29 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:24:32 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:24:34 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:24:36 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:24:39 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:24:41 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:24:43 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:24:46 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:24:48 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:24:50 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:24:52 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:24:55 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:24:57 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:24:59 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:25:02 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:25:04 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:25:06 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:25:08 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:25:11 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:25:13 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:25:15 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:25:18 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:25:20 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:25:22 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:25:24 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:25:27 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:25:29 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:25:31 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:25:34 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:25:36 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:25:38 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:25:40 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:25:43 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:25:45 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:25:47 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:25:49 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:25:52 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:25:54 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:25:56 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:25:59 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:26:01 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:26:03 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:26:06 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:26:08 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:26:10 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:26:13 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:26:15 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:26:17 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:26:20 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:26:22 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:26:24 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:26:26 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:26:29 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:26:31 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:26:34 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:26:36 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:26:38 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:26:41 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:26:43 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:26:45 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:26:47 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:26:50 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:26:52 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:26:54 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:26:57 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:26:59 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:27:01 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:27:04 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:27:06 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:27:08 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:27:10 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:27:13 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:27:15 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:27:17 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:27:20 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:27:22 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:27:24 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:27:27 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:27:29 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:27:31 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:27:33 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:27:36 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:27:38 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:27:40 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:27:43 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:27:45 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:27:47 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:27:50 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:27:52 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:27:54 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:27:57 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:27:59 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:28:01 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:28:03 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:28:06 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:28:08 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:28:10 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:28:13 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:28:15 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:28:17 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:28:19 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:28:22 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:28:24 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:28:26 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:28:29 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:28:31 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:28:33 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:28:36 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:28:38 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:28:40 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:28:42 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:28:45 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:28:47 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:28:49 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:28:52 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:28:54 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:28:56 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:28:58 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:29:01 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:29:03 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:29:05 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:29:08 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:29:10 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:29:12 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:29:14 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:29:17 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:29:19 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:29:21 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:29:24 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:29:26 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:29:28 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:29:31 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:29:33 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:29:35 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:29:37 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:29:40 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:29:42 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:29:44 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:29:47 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:29:49 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:29:51 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:29:53 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:29:56 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:29:58 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:30:00 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:30:02 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:30:05 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:30:07 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:30:09 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:30:12 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:30:14 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:30:16 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:30:18 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:30:21 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:30:23 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:30:25 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:30:28 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:30:30 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:30:32 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:30:35 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:30:37 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:30:39 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:30:42 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:30:44 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:30:46 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:30:49 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:30:51 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:30:53 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:30:56 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:30:58 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:31:00 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:31:03 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:31:05 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:31:07 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:31:09 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:31:12 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:31:14 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:31:16 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:31:19 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:31:21 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:31:23 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:31:26 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:31:28 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:31:30 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:31:33 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:31:35 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:31:37 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:31:39 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:31:42 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:31:44 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:31:46 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:31:49 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:31:51 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:31:53 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:31:56 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:31:58 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:32:00 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:32:02 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:32:05 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:32:07 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:32:09 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:32:12 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:32:14 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:32:16 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:32:18 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:32:21 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:32:23 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:32:25 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:32:28 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:32:30 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:32:32 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:32:35 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:32:37 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:32:39 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:32:41 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:32:44 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:32:46 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:32:48 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:32:51 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:32:53 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:32:55 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:32:57 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:33:00 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:33:02 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:33:04 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:33:07 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:33:09 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:33:11 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:33:13 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:33:16 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:33:18 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:33:20 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:33:23 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:33:25 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:33:27 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:33:29 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:33:32 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:33:34 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:33:36 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:33:39 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:33:41 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:33:43 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:33:45 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:33:48 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:33:50 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:33:52 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:33:55 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:33:57 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:33:59 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:34:01 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:34:04 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:34:06 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:34:08 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:34:11 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:34:13 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:34:15 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:34:18 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:34:20 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:34:22 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:34:24 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:34:27 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:34:29 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:34:31 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:34:34 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:34:36 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:34:38 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:34:40 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:34:43 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:34:45 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:34:47 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:34:50 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:34:52 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:34:54 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:34:57 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:34:59 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:35:01 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:35:03 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:35:06 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:35:08 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:35:10 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:35:13 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:35:15 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:35:17 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:35:19 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:35:22 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:35:24 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:35:26 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:35:29 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:35:31 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:35:33 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:35:35 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:35:38 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:35:40 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:35:42 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:35:44 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:35:47 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:35:49 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:35:51 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:35:54 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:35:56 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:35:58 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:36:00 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:36:03 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:36:05 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:36:07 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:36:10 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:36:12 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:36:14 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:36:16 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:36:19 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:36:21 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:36:23 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:36:26 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:36:28 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:36:30 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:36:32 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:36:35 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:36:37 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:36:39 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:36:42 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:36:44 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:36:46 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:36:48 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:36:51 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:36:53 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:36:55 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:36:58 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:37:00 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:37:02 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:37:04 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:37:07 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:37:09 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:37:11 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:37:14 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:37:16 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:37:18 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:37:20 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:37:23 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:37:25 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:37:27 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:37:30 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:37:32 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:37:34 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:37:36 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:37:39 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:37:41 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:37:43 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:37:46 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:37:48 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:37:50 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:37:52 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:37:55 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:37:57 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:37:59 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:38:02 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:38:04 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:38:06 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:38:08 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:38:11 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:38:13 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:38:15 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:38:18 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:38:20 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:38:22 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:38:25 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:38:27 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:38:29 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:38:31 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:38:34 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:38:36 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:38:38 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:38:41 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:38:43 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:38:45 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:38:48 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:38:50 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:38:52 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:38:55 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:38:57 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:38:59 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:39:02 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:39:04 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:39:06 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:39:08 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:39:11 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:39:13 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:39:15 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:39:18 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:39:20 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:39:22 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:39:24 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:39:27 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:39:29 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:39:31 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:39:34 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:39:36 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:39:38 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:39:41 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:39:43 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:39:45 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:39:48 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:39:50 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:39:53 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:39:55 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:39:58 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:40:00 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:40:03 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:40:05 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:40:07 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:40:10 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:40:12 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:40:14 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:40:17 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:40:19 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:40:21 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:40:24 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:40:26 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:40:28 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:40:30 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:40:33 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:40:35 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:40:37 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:40:40 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:40:42 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:40:44 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:40:47 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:40:49 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:40:51 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:40:53 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:40:56 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:40:58 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:41:00 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:41:03 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:41:05 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:41:07 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:41:10 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:41:12 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:41:14 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:41:16 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:41:19 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:41:21 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:41:23 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:41:26 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:41:28 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:41:30 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:41:33 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:41:35 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:41:37 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:41:39 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:41:42 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:41:44 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:41:46 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:41:49 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:41:51 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:41:53 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:41:55 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:41:58 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:42:00 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:42:02 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:42:05 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:42:07 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:42:09 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:42:11 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:42:14 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:42:16 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:42:18 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:42:21 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:42:23 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:42:25 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:42:28 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:42:30 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:42:32 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:42:35 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:42:37 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:42:39 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:42:41 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:42:44 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:42:46 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:42:48 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:42:51 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:42:53 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:42:55 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:42:58 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:43:00 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:43:02 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:43:04 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:43:07 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:43:09 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:43:11 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:43:14 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:43:16 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:43:18 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:43:21 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:43:23 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:43:25 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:43:27 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:43:30 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:43:32 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:43:34 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:43:37 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:43:39 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:43:41 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:43:44 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:43:46 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:43:48 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:43:50 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:43:53 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:43:55 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:43:57 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:44:00 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:44:02 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:44:04 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:44:07 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:44:09 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:44:11 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:44:13 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:44:16 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:44:18 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:44:20 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:44:23 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:44:25 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:44:27 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:44:29 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:44:32 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:44:34 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:44:36 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:44:39 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:44:41 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:44:43 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:44:45 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:44:48 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:44:50 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:44:52 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:44:55 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:44:57 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:44:59 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:45:02 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:45:04 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:45:06 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:45:08 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:45:11 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:45:13 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:45:15 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:45:17 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:45:20 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:45:22 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:45:24 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:45:27 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:45:29 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:45:31 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:45:34 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:45:36 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:45:38 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:45:41 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:45:43 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:45:45 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:45:48 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:45:50 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:45:52 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:45:55 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:45:57 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:45:59 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:46:02 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:46:04 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:46:06 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:46:09 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:46:11 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:46:13 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:46:16 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:46:18 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:46:21 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:46:23 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:46:25 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:46:28 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:46:30 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:46:32 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:46:35 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:46:37 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:46:39 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:46:42 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:46:44 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:46:46 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:46:49 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:46:51 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:46:53 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:46:56 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:46:58 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:47:00 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:47:03 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:47:05 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:47:07 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:47:10 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:47:12 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:47:14 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:47:17 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:47:19 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:47:21 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:47:24 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:47:26 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:47:28 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:47:31 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:47:33 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:47:36 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:47:38 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:47:40 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:47:43 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:47:45 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:47:47 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:47:50 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:47:52 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:47:54 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:47:57 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:47:59 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:48:01 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:48:04 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:48:06 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:48:08 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:48:11 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:48:13 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:48:15 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:48:18 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:48:20 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:48:22 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:48:25 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:48:27 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:48:29 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:48:32 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:48:34 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:48:36 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:48:39 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:48:41 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:48:43 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:48:46 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:48:48 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:48:50 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:48:53 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:48:55 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:48:57 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:48:59 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:49:02 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:49:04 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:49:06 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:49:09 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:49:11 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:49:13 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:49:16 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:49:18 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:49:20 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:49:23 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:49:25 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:49:27 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:49:30 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:49:32 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:49:34 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:49:37 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:49:39 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:49:41 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:49:44 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:49:46 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:49:48 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:49:51 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:49:53 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:49:55 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:49:58 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:50:00 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:50:02 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:50:05 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:50:07 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:50:09 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:50:12 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:50:14 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:50:16 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:50:18 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:50:21 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:50:23 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:50:25 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:50:28 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:50:30 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:50:32 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:50:35 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:50:37 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:50:39 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:50:42 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:50:44 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:50:46 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:50:49 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:50:51 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:50:53 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:50:56 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:50:58 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:51:00 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:51:03 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:51:05 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:51:08 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:51:10 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:51:12 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:51:15 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:51:17 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:51:19 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:51:22 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:51:24 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:51:26 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:51:29 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:51:31 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:51:33 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:51:36 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:51:38 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:51:40 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:51:43 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:51:45 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:51:47 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:51:50 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:51:52 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:51:54 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:51:57 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:51:59 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:52:01 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:52:04 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:52:06 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:52:08 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:52:11 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:52:13 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:52:15 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:52:18 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:52:20 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:52:22 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:52:25 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:52:27 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:52:29 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:52:32 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:52:34 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:52:36 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:52:39 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:52:41 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:52:43 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:52:45 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:52:48 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:52:50 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:52:52 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:52:55 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:52:57 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:52:59 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:53:02 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:53:04 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:53:06 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:53:08 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:53:11 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:53:13 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:53:15 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:53:18 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:53:20 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:53:22 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:53:25 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:53:27 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:53:29 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:53:32 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:53:34 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:53:36 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:53:38 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:53:41 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:53:43 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:53:45 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:53:48 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:53:50 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:53:52 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:53:54 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:53:57 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:53:59 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:54:01 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:54:04 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:54:06 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:54:08 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:54:11 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:54:13 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:54:15 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:54:17 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:54:20 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:54:22 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:54:24 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:54:27 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:54:29 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:54:31 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:54:34 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:54:36 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:54:38 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:54:40 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:54:43 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:54:45 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:54:47 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:54:50 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:54:52 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:54:54 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:54:57 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:54:59 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:55:01 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:55:04 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:55:06 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:55:08 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:55:10 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:55:13 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:55:15 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:55:17 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:55:20 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:55:22 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:55:24 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:55:27 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:55:29 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:55:31 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:55:34 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:55:36 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:55:38 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:55:41 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:55:43 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:55:45 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:55:48 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:55:50 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:55:52 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:55:55 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:55:57 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:55:59 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:56:01 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:56:04 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:56:06 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:56:08 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:56:11 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:56:13 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:56:15 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:56:18 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:56:20 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:56:22 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:56:25 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:56:27 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:56:29 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:56:32 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:56:34 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:56:36 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:56:38 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:56:41 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:56:43 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:56:45 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:56:48 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:56:50 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:56:52 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:56:55 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:56:57 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:56:59 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:57:02 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:57:04 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:57:06 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:57:09 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:57:11 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:57:13 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:57:16 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:57:18 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:57:20 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:57:23 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:57:25 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:57:27 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:57:30 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:57:32 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:57:34 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:57:37 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:57:39 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:57:41 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:57:44 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:57:46 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:57:48 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:57:51 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:57:53 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:57:55 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:57:58 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:58:00 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:58:02 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:58:05 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:58:07 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:58:09 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:58:12 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:58:14 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:58:16 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:58:19 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:58:21 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:58:23 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:58:26 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:58:28 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:58:30 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:58:32 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:58:35 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:58:37 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:58:39 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:58:42 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:58:44 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:58:46 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:58:49 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:58:51 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:58:53 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:58:56 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:58:58 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:59:00 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:59:03 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:59:05 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:59:07 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:59:09 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:59:12 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:59:14 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:59:16 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:59:19 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:59:21 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:59:23 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:59:26 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:59:28 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:59:30 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:59:33 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:59:35 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:59:37 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:59:40 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:59:42 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:59:44 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:59:46 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:59:49 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:59:51 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:59:53 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:59:56 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 15:59:58 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:00:00 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:00:03 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:00:05 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:00:07 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:00:10 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:00:12 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:00:14 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:00:17 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:00:19 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:00:21 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:00:24 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:00:26 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:00:28 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:00:31 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:00:33 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:00:35 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:00:38 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:00:40 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:00:42 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:00:45 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:00:47 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:00:49 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:00:52 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:00:54 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:00:56 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:00:59 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:01:01 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:01:03 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:01:06 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:01:08 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:01:10 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:01:13 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:01:15 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:01:17 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:01:20 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:01:22 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:01:24 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:01:27 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:01:29 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:01:31 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:01:33 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:01:36 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:01:38 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:01:40 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:01:43 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:01:45 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:01:47 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:01:50 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:01:52 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:01:54 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:01:57 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:01:59 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:02:01 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:02:03 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:02:06 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:02:08 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:02:10 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:02:13 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:02:15 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:02:17 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:02:19 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:02:22 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:02:24 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:02:26 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:02:29 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:02:31 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:02:33 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:02:36 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:02:38 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:02:40 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:02:42 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:02:45 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:02:47 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:02:49 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:02:52 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:02:54 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:02:56 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:02:59 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:03:01 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:03:03 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:03:05 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:03:08 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:03:10 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:03:12 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:03:15 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:03:17 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:03:19 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:03:21 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:03:24 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:03:26 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:03:28 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:03:31 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:03:33 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:03:35 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:03:38 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:03:40 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:03:42 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:03:44 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:03:47 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:03:49 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:03:51 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:03:54 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:03:56 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:03:58 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:04:00 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:04:03 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:04:05 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:04:07 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:04:10 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:04:12 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:04:14 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:04:17 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:04:19 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:04:21 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:04:24 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:04:26 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:04:28 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:04:31 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:04:33 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:04:35 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:04:37 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:04:40 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:04:42 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:04:44 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:04:47 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:04:49 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:04:51 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:04:54 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:04:56 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:04:58 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:05:01 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:05:03 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:05:05 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:05:08 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:05:10 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:05:12 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:05:15 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:05:17 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:05:19 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:05:21 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:05:24 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:05:26 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:05:28 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:05:31 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:05:33 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:05:35 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:05:38 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:05:40 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:05:42 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:05:45 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:05:47 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:05:49 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:05:52 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:05:54 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:05:56 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:05:59 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:06:01 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:06:03 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:06:06 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:06:08 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:06:10 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:06:12 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:06:15 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:06:17 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:06:19 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:06:22 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:06:24 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:06:26 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:06:29 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:06:31 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:06:33 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:06:36 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:06:38 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:06:40 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:06:43 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:06:45 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:06:47 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:06:49 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:06:52 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:06:54 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:06:56 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:06:59 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:07:01 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:07:03 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:07:06 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:07:08 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:07:10 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:07:12 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:07:15 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:07:17 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:07:19 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:07:22 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:07:24 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:07:26 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:07:29 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:07:31 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:07:33 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:07:36 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:07:38 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:07:40 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:07:42 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:07:45 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:07:47 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:07:49 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:07:52 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:07:54 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:07:56 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:07:59 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:08:01 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:08:03 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:08:06 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:08:08 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:08:10 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:08:13 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:08:15 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:08:17 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:08:19 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:08:22 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:08:24 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:08:26 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:08:29 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:08:31 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:08:33 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:08:36 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:08:38 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:08:40 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:08:42 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:08:45 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:08:47 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:08:49 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:08:52 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:08:54 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:08:56 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:08:59 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:09:01 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:09:03 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:09:05 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:09:08 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:09:10 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:09:12 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:09:15 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:09:17 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:09:19 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:09:22 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:09:24 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:09:26 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:09:29 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:09:31 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:09:33 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:09:35 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:09:38 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:09:40 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:09:42 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:09:45 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:09:47 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:09:49 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:09:51 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:09:54 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:09:56 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:09:58 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:10:01 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:10:03 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:10:05 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:10:08 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:10:10 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:10:12 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:10:14 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:10:17 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:10:19 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:10:21 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:10:24 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:10:26 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:10:28 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:10:31 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:10:33 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:10:35 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:10:38 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:10:40 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:10:42 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:10:45 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:10:47 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:10:49 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:10:52 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:10:54 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:10:56 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:10:59 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:11:01 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:11:03 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:11:06 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:11:08 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:11:10 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:11:13 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:11:15 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:11:17 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:11:20 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:11:22 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:11:24 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:11:27 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:11:29 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:11:31 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:11:34 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:11:36 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:11:38 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:11:41 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:11:43 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:11:45 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:11:48 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:11:50 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:11:52 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:11:55 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:11:57 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:11:59 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:12:02 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:12:04 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:12:06 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:12:09 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:12:11 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:12:13 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:12:16 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:12:18 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:12:20 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:12:23 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:12:25 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:12:27 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:12:30 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:12:32 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:12:34 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:12:37 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:12:39 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:12:41 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:12:44 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:12:46 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:12:48 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:12:51 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:12:53 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:12:55 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:12:58 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:13:00 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:13:03 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:13:05 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:13:07 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:13:10 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:13:12 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:13:14 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:13:17 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:13:19 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:13:21 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:13:24 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:13:26 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:13:28 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:13:31 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:13:33 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:13:35 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:13:38 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:13:40 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:13:42 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:13:45 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:13:47 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:13:49 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:13:52 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:13:54 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:13:56 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:13:59 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:14:01 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:14:03 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:14:06 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:14:08 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:14:10 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:14:13 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:14:15 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:14:17 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:14:20 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:14:22 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:14:24 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:14:27 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:14:29 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:14:31 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:14:34 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:14:36 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:14:38 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:14:41 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:14:43 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:14:45 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:14:48 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:14:50 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:14:53 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:14:55 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:14:57 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:15:00 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:15:02 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:15:04 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:15:07 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:15:09 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:15:11 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:15:14 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:15:16 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:15:18 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:15:21 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:15:23 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:15:25 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:15:28 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:15:30 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:15:32 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:15:35 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:15:37 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:15:39 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:15:42 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:15:44 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:15:46 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:15:49 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:15:51 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:15:53 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:15:56 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:15:58 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:16:00 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:16:03 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:16:05 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:16:07 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:16:09 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:16:12 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:16:14 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:16:17 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:16:19 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:16:21 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:16:23 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:16:26 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:16:28 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:16:30 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:16:33 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:16:35 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:16:38 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:16:40 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:16:42 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:16:44 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:16:47 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:16:49 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:16:52 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:16:54 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:16:56 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:16:59 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:17:01 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:17:03 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:17:06 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:17:08 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:17:10 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:17:13 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:17:15 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:17:17 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:17:20 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:17:22 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:17:24 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:17:27 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:17:29 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:17:31 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:17:34 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:17:36 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:17:38 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:17:41 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:17:43 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:17:45 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:17:48 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:17:50 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:17:52 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:17:55 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:17:57 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:17:59 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:18:02 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:18:04 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:18:06 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:18:09 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:18:11 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:18:13 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:18:15 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:18:18 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:18:20 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:18:23 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:18:25 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:18:27 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:18:30 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:18:32 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:18:34 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:18:37 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:18:39 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:18:41 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:18:44 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:18:46 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:18:48 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:18:51 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:18:53 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:18:55 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:18:58 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:19:00 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:19:02 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:19:05 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:19:07 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:19:09 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:19:12 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:19:14 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:19:16 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:19:18 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:19:21 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:19:23 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:19:25 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:19:28 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:19:30 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:19:32 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:19:35 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:19:37 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:19:39 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:19:42 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:19:44 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:19:46 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:19:49 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:19:51 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:19:53 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:19:56 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:19:58 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:20:00 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:20:03 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:20:05 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:20:07 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:20:10 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:20:12 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:20:14 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:20:17 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:20:19 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:20:21 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:20:24 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:20:26 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:20:28 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:20:31 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:20:33 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:20:35 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:20:38 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:20:40 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:20:42 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:20:45 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:20:47 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:20:49 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:20:52 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:20:54 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:20:56 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:20:59 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:21:01 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:21:03 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:21:06 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:21:08 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:21:10 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:21:13 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:21:15 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:21:17 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:21:20 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:21:22 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:21:24 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:21:27 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:21:29 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:21:31 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:21:34 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:21:36 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:21:38 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:21:41 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:21:43 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:21:46 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:21:48 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:21:50 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:21:53 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:21:55 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:21:57 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:22:00 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:22:02 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:22:04 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:22:07 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:22:09 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:22:11 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:22:14 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:22:16 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:22:18 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:22:21 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:22:23 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:22:25 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:22:28 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:22:30 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:22:32 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:22:35 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:22:37 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:22:39 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:22:42 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:22:44 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:22:46 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:22:49 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:22:51 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:22:53 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:22:56 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:22:58 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:23:00 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:23:03 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:23:05 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:23:07 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:23:10 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:23:12 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:23:14 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:23:17 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:23:19 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:23:21 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:23:24 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:23:26 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:23:28 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:23:31 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:23:33 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:23:35 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:23:38 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:23:40 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:23:42 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:23:45 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:23:47 - cooperation_topic_feature_generator.py - calculate_topics - INFO - cur claim author count: defaultdict(<type 'int'>, {})
2019-01-30 16:59:22 - run.py - <module> - INFO - Start Execution ... 
2019-01-30 16:59:22 - run.py - <module> - INFO - SETUP global variables
2019-01-30 16:59:22 - run.py - <module> - INFO - CREATE pipeline
2019-01-30 16:59:22 - run.py - <module> - INFO - SETUP pipeline
2019-01-30 16:59:22 - run.py - <module> - INFO - setup module: <DB.schema_definition.DB instance at 0x000000002E5547C8>
2019-01-30 16:59:22 - run.py - <module> - INFO - setup module: <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x00000000294DF1D0>
2019-01-30 16:59:22 - run.py - <module> - INFO - setup module: <dataset_builder.feature_extractor.cooperation_topic_feature_generator.CooperationTopicFeatureGenerator object at 0x000000002E555CF8>
2019-01-30 16:59:22 - run.py - <module> - INFO - checking module definition
2019-01-30 16:59:22 - run.py - <module> - INFO - module <DB.schema_definition.DB instance at 0x000000002E5547C8> is well defined
2019-01-30 16:59:22 - run.py - <module> - INFO - module <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x00000000294DF1D0> is well defined
2019-01-30 16:59:22 - run.py - <module> - INFO - module <dataset_builder.feature_extractor.cooperation_topic_feature_generator.CooperationTopicFeatureGenerator object at 0x000000002E555CF8> is well defined
2019-01-30 16:59:22 - run.py - <module> - INFO - execute module: <DB.schema_definition.DB instance at 0x000000002E5547C8>
2019-01-30 16:59:22 - run.py - <module> - INFO - *********Started executing DB
2019-01-30 16:59:22 - run.py - <module> - INFO - *********Finished executing DB
2019-01-30 16:59:22 - run.py - <module> - INFO - execute module: <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x00000000294DF1D0>
2019-01-30 16:59:22 - run.py - <module> - INFO - *********Started executing AddAuthorConnectionClaimId
2019-01-30 17:00:05 - run.py - <module> - INFO - *********Finished executing AddAuthorConnectionClaimId
2019-01-30 17:00:05 - run.py - <module> - INFO - execute module: <dataset_builder.feature_extractor.cooperation_topic_feature_generator.CooperationTopicFeatureGenerator object at 0x000000002E555CF8>
2019-01-30 17:00:05 - run.py - <module> - INFO - *********Started executing CooperationTopicFeatureGenerator
2019-01-30 17:00:05 - cooperation_topic_feature_generator.py - execute - INFO - execute started for Cooperation topic feature generator started at 1548860405.26
2019-01-30 17:00:05 - cooperation_topic_feature_generator.py - execute - INFO - Cooperation execute window_start 2000-06-07 00:00:00
2019-01-30 17:02:47 - cooperation_topic_feature_generator.py - execute - INFO - Started 1 claim from 398 claims
2019-01-30 17:25:27 - run.py - <module> - INFO - Start Execution ... 
2019-01-30 17:25:27 - run.py - <module> - INFO - SETUP global variables
2019-01-30 17:25:27 - run.py - <module> - INFO - CREATE pipeline
2019-01-30 17:25:27 - run.py - <module> - INFO - SETUP pipeline
2019-01-30 17:25:27 - run.py - <module> - INFO - setup module: <DB.schema_definition.DB instance at 0x000000002E6CC7C8>
2019-01-30 17:25:27 - run.py - <module> - INFO - setup module: <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x00000000294EC1D0>
2019-01-30 17:25:27 - run.py - <module> - INFO - setup module: <dataset_builder.feature_extractor.cooperation_topic_feature_generator.CooperationTopicFeatureGenerator object at 0x000000002E6CDD30>
2019-01-30 17:25:27 - run.py - <module> - INFO - checking module definition
2019-01-30 17:25:27 - run.py - <module> - INFO - module <DB.schema_definition.DB instance at 0x000000002E6CC7C8> is well defined
2019-01-30 17:25:27 - run.py - <module> - INFO - module <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x00000000294EC1D0> is well defined
2019-01-30 17:25:27 - run.py - <module> - INFO - module <dataset_builder.feature_extractor.cooperation_topic_feature_generator.CooperationTopicFeatureGenerator object at 0x000000002E6CDD30> is well defined
2019-01-30 17:25:27 - run.py - <module> - INFO - execute module: <DB.schema_definition.DB instance at 0x000000002E6CC7C8>
2019-01-30 17:25:27 - run.py - <module> - INFO - *********Started executing DB
2019-01-30 17:25:27 - run.py - <module> - INFO - *********Finished executing DB
2019-01-30 17:25:27 - run.py - <module> - INFO - execute module: <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x00000000294EC1D0>
2019-01-30 17:25:27 - run.py - <module> - INFO - *********Started executing AddAuthorConnectionClaimId
2019-01-30 17:26:08 - run.py - <module> - INFO - *********Finished executing AddAuthorConnectionClaimId
2019-01-30 17:26:08 - run.py - <module> - INFO - execute module: <dataset_builder.feature_extractor.cooperation_topic_feature_generator.CooperationTopicFeatureGenerator object at 0x000000002E6CDD30>
2019-01-30 17:26:08 - run.py - <module> - INFO - *********Started executing CooperationTopicFeatureGenerator
2019-01-30 17:26:08 - cooperation_topic_feature_generator.py - execute - INFO - execute started for Cooperation topic feature generator started at 1548861968.92
2019-01-30 17:26:08 - cooperation_topic_feature_generator.py - execute - INFO - Cooperation execute window_start 2000-06-07 00:00:00
2019-01-30 17:27:05 - run.py - <module> - INFO - Start Execution ... 
2019-01-30 17:27:05 - run.py - <module> - INFO - SETUP global variables
2019-01-30 17:27:05 - run.py - <module> - INFO - CREATE pipeline
2019-01-30 17:27:05 - run.py - <module> - INFO - SETUP pipeline
2019-01-30 17:27:05 - run.py - <module> - INFO - setup module: <DB.schema_definition.DB instance at 0x000000002DB6EC48>
2019-01-30 17:27:05 - run.py - <module> - INFO - setup module: <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x00000000281D1128>
2019-01-30 17:27:05 - run.py - <module> - INFO - setup module: <dataset_builder.feature_extractor.cooperation_topic_feature_generator.CooperationTopicFeatureGenerator object at 0x000000002DB64CC0>
2019-01-30 17:27:05 - run.py - <module> - INFO - checking module definition
2019-01-30 17:27:05 - run.py - <module> - INFO - module <DB.schema_definition.DB instance at 0x000000002DB6EC48> is well defined
2019-01-30 17:27:05 - run.py - <module> - INFO - module <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x00000000281D1128> is well defined
2019-01-30 17:27:05 - run.py - <module> - INFO - module <dataset_builder.feature_extractor.cooperation_topic_feature_generator.CooperationTopicFeatureGenerator object at 0x000000002DB64CC0> is well defined
2019-01-30 17:27:05 - run.py - <module> - INFO - execute module: <DB.schema_definition.DB instance at 0x000000002DB6EC48>
2019-01-30 17:27:05 - run.py - <module> - INFO - *********Started executing DB
2019-01-30 17:27:05 - run.py - <module> - INFO - *********Finished executing DB
2019-01-30 17:27:05 - run.py - <module> - INFO - execute module: <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x00000000281D1128>
2019-01-30 17:27:05 - run.py - <module> - INFO - *********Started executing AddAuthorConnectionClaimId
2019-01-30 17:27:44 - run.py - <module> - INFO - *********Finished executing AddAuthorConnectionClaimId
2019-01-30 17:27:44 - run.py - <module> - INFO - execute module: <dataset_builder.feature_extractor.cooperation_topic_feature_generator.CooperationTopicFeatureGenerator object at 0x000000002DB64CC0>
2019-01-30 17:27:44 - run.py - <module> - INFO - *********Started executing CooperationTopicFeatureGenerator
2019-01-30 17:27:44 - cooperation_topic_feature_generator.py - execute - INFO - execute started for Cooperation topic feature generator started at 1548862064.69
2019-01-30 17:27:44 - cooperation_topic_feature_generator.py - execute - INFO - Cooperation execute window_start 2000-06-07 00:00:00
2019-01-30 17:28:56 - cooperation_topic_feature_generator.py - execute - INFO - Started 1 claim from 398 claims
2019-02-06 09:36:16 - run.py - <module> - INFO - Start Execution ... 
2019-02-06 09:36:16 - run.py - <module> - INFO - SETUP global variables
2019-02-06 09:36:16 - run.py - <module> - INFO - CREATE pipeline
2019-02-06 09:36:16 - run.py - <module> - INFO - SETUP pipeline
2019-02-06 09:36:16 - run.py - <module> - INFO - setup module: <DB.schema_definition.DB instance at 0x000000002DB15A08>
2019-02-06 09:36:16 - run.py - <module> - INFO - setup module: <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x0000000027FCCB70>
2019-02-06 09:36:16 - run.py - <module> - INFO - checking module definition
2019-02-06 09:36:16 - run.py - <module> - INFO - module <DB.schema_definition.DB instance at 0x000000002DB15A08> is well defined
2019-02-06 09:36:16 - run.py - <module> - INFO - module <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x0000000027FCCB70> is well defined
2019-02-06 09:36:16 - run.py - <module> - INFO - execute module: <DB.schema_definition.DB instance at 0x000000002DB15A08>
2019-02-06 09:36:16 - run.py - <module> - INFO - *********Started executing DB
2019-02-06 09:36:16 - run.py - <module> - INFO - *********Finished executing DB
2019-02-06 09:36:16 - run.py - <module> - INFO - execute module: <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x0000000027FCCB70>
2019-02-06 09:36:16 - run.py - <module> - INFO - *********Started executing AddAuthorConnectionClaimId
2019-02-06 09:36:16 - run.py - <module> - INFO - *********Finished executing AddAuthorConnectionClaimId
2019-02-06 09:38:15 - run.py - <module> - INFO - Start Execution ... 
2019-02-06 09:38:15 - run.py - <module> - INFO - SETUP global variables
2019-02-06 09:38:15 - run.py - <module> - INFO - CREATE pipeline
2019-02-06 09:38:15 - run.py - <module> - INFO - SETUP pipeline
2019-02-06 09:38:15 - run.py - <module> - INFO - setup module: <DB.schema_definition.DB instance at 0x000000002ED04F48>
2019-02-06 09:38:15 - run.py - <module> - INFO - setup module: <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x0000000029900588>
2019-02-06 09:38:15 - run.py - <module> - INFO - checking module definition
2019-02-06 09:38:15 - run.py - <module> - INFO - module <DB.schema_definition.DB instance at 0x000000002ED04F48> is well defined
2019-02-06 09:38:15 - run.py - <module> - INFO - module <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x0000000029900588> is well defined
2019-02-06 09:38:15 - run.py - <module> - INFO - execute module: <DB.schema_definition.DB instance at 0x000000002ED04F48>
2019-02-06 09:38:15 - run.py - <module> - INFO - *********Started executing DB
2019-02-06 09:38:15 - run.py - <module> - INFO - *********Finished executing DB
2019-02-06 09:38:15 - run.py - <module> - INFO - execute module: <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x0000000029900588>
2019-02-06 09:38:15 - run.py - <module> - INFO - *********Started executing AddAuthorConnectionClaimId
2019-02-06 09:38:15 - run.py - <module> - INFO - *********Finished executing AddAuthorConnectionClaimId
2019-02-06 09:40:23 - run.py - <module> - INFO - Start Execution ... 
2019-02-06 09:40:23 - run.py - <module> - INFO - SETUP global variables
2019-02-06 09:40:23 - run.py - <module> - INFO - CREATE pipeline
2019-02-06 09:40:23 - run.py - <module> - INFO - SETUP pipeline
2019-02-06 09:40:23 - run.py - <module> - INFO - setup module: <DB.schema_definition.DB instance at 0x000000002E47DCC8>
2019-02-06 09:40:23 - run.py - <module> - INFO - setup module: <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x00000000289FE438>
2019-02-06 09:40:23 - run.py - <module> - INFO - checking module definition
2019-02-06 09:40:23 - run.py - <module> - INFO - module <DB.schema_definition.DB instance at 0x000000002E47DCC8> is well defined
2019-02-06 09:40:23 - run.py - <module> - INFO - module <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x00000000289FE438> is well defined
2019-02-06 09:40:23 - run.py - <module> - INFO - execute module: <DB.schema_definition.DB instance at 0x000000002E47DCC8>
2019-02-06 09:40:23 - run.py - <module> - INFO - *********Started executing DB
2019-02-06 09:40:23 - run.py - <module> - INFO - *********Finished executing DB
2019-02-06 09:40:23 - run.py - <module> - INFO - execute module: <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x00000000289FE438>
2019-02-06 09:40:23 - run.py - <module> - INFO - *********Started executing AddAuthorConnectionClaimId
2019-02-06 09:40:23 - run.py - <module> - INFO - *********Finished executing AddAuthorConnectionClaimId
2019-02-06 09:43:24 - run.py - <module> - INFO - Start Execution ... 
2019-02-06 09:43:24 - run.py - <module> - INFO - SETUP global variables
2019-02-06 09:43:24 - run.py - <module> - INFO - CREATE pipeline
2019-02-06 09:43:24 - run.py - <module> - INFO - SETUP pipeline
2019-02-06 09:43:24 - run.py - <module> - INFO - setup module: <DB.schema_definition.DB instance at 0x000000002E72BF88>
2019-02-06 09:43:24 - run.py - <module> - INFO - setup module: <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x00000000294D7588>
2019-02-06 09:43:24 - run.py - <module> - INFO - checking module definition
2019-02-06 09:43:24 - run.py - <module> - INFO - module <DB.schema_definition.DB instance at 0x000000002E72BF88> is well defined
2019-02-06 09:43:24 - run.py - <module> - INFO - module <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x00000000294D7588> is well defined
2019-02-06 09:43:24 - run.py - <module> - INFO - execute module: <DB.schema_definition.DB instance at 0x000000002E72BF88>
2019-02-06 09:43:24 - run.py - <module> - INFO - *********Started executing DB
2019-02-06 09:43:24 - run.py - <module> - INFO - *********Finished executing DB
2019-02-06 09:43:24 - run.py - <module> - INFO - execute module: <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x00000000294D7588>
2019-02-06 09:43:24 - run.py - <module> - INFO - *********Started executing AddAuthorConnectionClaimId
2019-02-06 09:43:24 - run.py - <module> - INFO - *********Finished executing AddAuthorConnectionClaimId
2019-02-06 09:43:36 - run.py - <module> - INFO - Start Execution ... 
2019-02-06 09:43:36 - run.py - <module> - INFO - SETUP global variables
2019-02-06 09:43:36 - run.py - <module> - INFO - CREATE pipeline
2019-02-06 09:43:36 - run.py - <module> - INFO - SETUP pipeline
2019-02-06 09:43:36 - run.py - <module> - INFO - setup module: <DB.schema_definition.DB instance at 0x000000002DD99CC8>
2019-02-06 09:43:36 - run.py - <module> - INFO - setup module: <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x0000000028391438>
2019-02-06 09:43:36 - run.py - <module> - INFO - checking module definition
2019-02-06 09:43:36 - run.py - <module> - INFO - module <DB.schema_definition.DB instance at 0x000000002DD99CC8> is well defined
2019-02-06 09:43:36 - run.py - <module> - INFO - module <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x0000000028391438> is well defined
2019-02-06 09:43:36 - run.py - <module> - INFO - execute module: <DB.schema_definition.DB instance at 0x000000002DD99CC8>
2019-02-06 09:43:36 - run.py - <module> - INFO - *********Started executing DB
2019-02-06 09:43:36 - run.py - <module> - INFO - *********Finished executing DB
2019-02-06 09:43:36 - run.py - <module> - INFO - execute module: <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x0000000028391438>
2019-02-06 09:43:36 - run.py - <module> - INFO - *********Started executing AddAuthorConnectionClaimId
2019-02-06 09:43:36 - run.py - <module> - INFO - *********Finished executing AddAuthorConnectionClaimId
2019-02-06 09:44:03 - run.py - <module> - INFO - Start Execution ... 
2019-02-06 09:44:03 - run.py - <module> - INFO - SETUP global variables
2019-02-06 09:44:03 - run.py - <module> - INFO - CREATE pipeline
2019-02-06 09:44:03 - run.py - <module> - INFO - SETUP pipeline
2019-02-06 09:44:03 - run.py - <module> - INFO - setup module: <DB.schema_definition.DB instance at 0x000000002E557CC8>
2019-02-06 09:44:03 - run.py - <module> - INFO - setup module: <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x0000000028AE1438>
2019-02-06 09:44:03 - run.py - <module> - INFO - checking module definition
2019-02-06 09:44:03 - run.py - <module> - INFO - module <DB.schema_definition.DB instance at 0x000000002E557CC8> is well defined
2019-02-06 09:44:03 - run.py - <module> - INFO - module <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x0000000028AE1438> is well defined
2019-02-06 09:44:03 - run.py - <module> - INFO - execute module: <DB.schema_definition.DB instance at 0x000000002E557CC8>
2019-02-06 09:44:03 - run.py - <module> - INFO - *********Started executing DB
2019-02-06 09:44:03 - run.py - <module> - INFO - *********Finished executing DB
2019-02-06 09:44:03 - run.py - <module> - INFO - execute module: <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x0000000028AE1438>
2019-02-06 09:44:03 - run.py - <module> - INFO - *********Started executing AddAuthorConnectionClaimId
2019-02-06 09:44:03 - run.py - <module> - INFO - *********Finished executing AddAuthorConnectionClaimId
2019-02-06 09:45:05 - run.py - <module> - INFO - Start Execution ... 
2019-02-06 09:45:05 - run.py - <module> - INFO - SETUP global variables
2019-02-06 09:45:05 - run.py - <module> - INFO - CREATE pipeline
2019-02-06 09:45:05 - run.py - <module> - INFO - SETUP pipeline
2019-02-06 09:45:05 - run.py - <module> - INFO - setup module: <DB.schema_definition.DB instance at 0x000000002D85BCC8>
2019-02-06 09:45:05 - run.py - <module> - INFO - setup module: <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x0000000027FAE438>
2019-02-06 09:45:05 - run.py - <module> - INFO - checking module definition
2019-02-06 09:45:05 - run.py - <module> - INFO - module <DB.schema_definition.DB instance at 0x000000002D85BCC8> is well defined
2019-02-06 09:45:05 - run.py - <module> - INFO - module <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x0000000027FAE438> is well defined
2019-02-06 09:45:05 - run.py - <module> - INFO - execute module: <DB.schema_definition.DB instance at 0x000000002D85BCC8>
2019-02-06 09:45:05 - run.py - <module> - INFO - *********Started executing DB
2019-02-06 09:45:05 - run.py - <module> - INFO - *********Finished executing DB
2019-02-06 09:45:05 - run.py - <module> - INFO - execute module: <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x0000000027FAE438>
2019-02-06 09:45:05 - run.py - <module> - INFO - *********Started executing AddAuthorConnectionClaimId
2019-02-06 09:45:05 - run.py - <module> - INFO - *********Finished executing AddAuthorConnectionClaimId
2019-02-06 09:45:54 - run.py - <module> - INFO - Start Execution ... 
2019-02-06 09:45:54 - run.py - <module> - INFO - SETUP global variables
2019-02-06 09:45:54 - run.py - <module> - INFO - CREATE pipeline
2019-02-06 09:45:54 - run.py - <module> - INFO - SETUP pipeline
2019-02-06 09:45:54 - run.py - <module> - INFO - setup module: <DB.schema_definition.DB instance at 0x000000002DA7DCC8>
2019-02-06 09:45:54 - run.py - <module> - INFO - setup module: <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x0000000027FEE438>
2019-02-06 09:45:54 - run.py - <module> - INFO - checking module definition
2019-02-06 09:45:54 - run.py - <module> - INFO - module <DB.schema_definition.DB instance at 0x000000002DA7DCC8> is well defined
2019-02-06 09:45:54 - run.py - <module> - INFO - module <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x0000000027FEE438> is well defined
2019-02-06 09:45:54 - run.py - <module> - INFO - execute module: <DB.schema_definition.DB instance at 0x000000002DA7DCC8>
2019-02-06 09:45:54 - run.py - <module> - INFO - *********Started executing DB
2019-02-06 09:45:54 - run.py - <module> - INFO - *********Finished executing DB
2019-02-06 09:45:54 - run.py - <module> - INFO - execute module: <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x0000000027FEE438>
2019-02-06 09:45:54 - run.py - <module> - INFO - *********Started executing AddAuthorConnectionClaimId
2019-02-06 09:45:54 - run.py - <module> - INFO - *********Finished executing AddAuthorConnectionClaimId
2019-02-06 09:48:28 - run.py - <module> - INFO - Start Execution ... 
2019-02-06 09:48:28 - run.py - <module> - INFO - SETUP global variables
2019-02-06 09:48:28 - run.py - <module> - INFO - CREATE pipeline
2019-02-06 09:48:28 - run.py - <module> - INFO - SETUP pipeline
2019-02-06 09:48:28 - run.py - <module> - INFO - setup module: <DB.schema_definition.DB instance at 0x000000002E18DD08>
2019-02-06 09:48:28 - run.py - <module> - INFO - setup module: <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x00000000286DE438>
2019-02-06 09:48:28 - run.py - <module> - INFO - checking module definition
2019-02-06 09:48:28 - run.py - <module> - INFO - module <DB.schema_definition.DB instance at 0x000000002E18DD08> is well defined
2019-02-06 09:48:28 - run.py - <module> - INFO - module <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x00000000286DE438> is well defined
2019-02-06 09:48:28 - run.py - <module> - INFO - execute module: <DB.schema_definition.DB instance at 0x000000002E18DD08>
2019-02-06 09:48:28 - run.py - <module> - INFO - *********Started executing DB
2019-02-06 09:48:28 - run.py - <module> - INFO - *********Finished executing DB
2019-02-06 09:48:28 - run.py - <module> - INFO - execute module: <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x00000000286DE438>
2019-02-06 09:48:28 - run.py - <module> - INFO - *********Started executing AddAuthorConnectionClaimId
2019-02-06 09:48:28 - run.py - <module> - INFO - *********Finished executing AddAuthorConnectionClaimId
2019-02-06 09:48:52 - run.py - <module> - INFO - Start Execution ... 
2019-02-06 09:48:52 - run.py - <module> - INFO - SETUP global variables
2019-02-06 09:48:52 - run.py - <module> - INFO - CREATE pipeline
2019-02-06 09:48:52 - run.py - <module> - INFO - SETUP pipeline
2019-02-06 09:48:52 - run.py - <module> - INFO - setup module: <DB.schema_definition.DB instance at 0x000000002D6ADD08>
2019-02-06 09:48:52 - run.py - <module> - INFO - setup module: <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x0000000027CAE438>
2019-02-06 09:48:52 - run.py - <module> - INFO - checking module definition
2019-02-06 09:48:52 - run.py - <module> - INFO - module <DB.schema_definition.DB instance at 0x000000002D6ADD08> is well defined
2019-02-06 09:48:52 - run.py - <module> - INFO - module <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x0000000027CAE438> is well defined
2019-02-06 09:48:52 - run.py - <module> - INFO - execute module: <DB.schema_definition.DB instance at 0x000000002D6ADD08>
2019-02-06 09:48:52 - run.py - <module> - INFO - *********Started executing DB
2019-02-06 09:48:52 - run.py - <module> - INFO - *********Finished executing DB
2019-02-06 09:48:52 - run.py - <module> - INFO - execute module: <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x0000000027CAE438>
2019-02-06 09:48:52 - run.py - <module> - INFO - *********Started executing AddAuthorConnectionClaimId
2019-02-06 09:48:52 - run.py - <module> - INFO - *********Finished executing AddAuthorConnectionClaimId
2019-02-06 09:49:34 - run.py - <module> - INFO - Start Execution ... 
2019-02-06 09:49:34 - run.py - <module> - INFO - SETUP global variables
2019-02-06 09:49:34 - run.py - <module> - INFO - CREATE pipeline
2019-02-06 09:49:34 - run.py - <module> - INFO - SETUP pipeline
2019-02-06 09:49:34 - run.py - <module> - INFO - setup module: <DB.schema_definition.DB instance at 0x000000002D6ADCC8>
2019-02-06 09:49:34 - run.py - <module> - INFO - setup module: <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x0000000027BFE438>
2019-02-06 09:49:34 - run.py - <module> - INFO - checking module definition
2019-02-06 09:49:34 - run.py - <module> - INFO - module <DB.schema_definition.DB instance at 0x000000002D6ADCC8> is well defined
2019-02-06 09:49:34 - run.py - <module> - INFO - module <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x0000000027BFE438> is well defined
2019-02-06 09:49:34 - run.py - <module> - INFO - execute module: <DB.schema_definition.DB instance at 0x000000002D6ADCC8>
2019-02-06 09:49:34 - run.py - <module> - INFO - *********Started executing DB
2019-02-06 09:49:34 - run.py - <module> - INFO - *********Finished executing DB
2019-02-06 09:49:34 - run.py - <module> - INFO - execute module: <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x0000000027BFE438>
2019-02-06 09:49:34 - run.py - <module> - INFO - *********Started executing AddAuthorConnectionClaimId
2019-02-06 09:49:34 - run.py - <module> - INFO - *********Finished executing AddAuthorConnectionClaimId
2019-02-06 09:49:57 - run.py - <module> - INFO - Start Execution ... 
2019-02-06 09:49:57 - run.py - <module> - INFO - SETUP global variables
2019-02-06 09:49:57 - run.py - <module> - INFO - CREATE pipeline
2019-02-06 09:49:57 - run.py - <module> - INFO - SETUP pipeline
2019-02-06 09:49:57 - run.py - <module> - INFO - setup module: <DB.schema_definition.DB instance at 0x000000002DAACCC8>
2019-02-06 09:49:57 - run.py - <module> - INFO - setup module: <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x0000000028001438>
2019-02-06 09:49:57 - run.py - <module> - INFO - checking module definition
2019-02-06 09:49:57 - run.py - <module> - INFO - module <DB.schema_definition.DB instance at 0x000000002DAACCC8> is well defined
2019-02-06 09:49:57 - run.py - <module> - INFO - module <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x0000000028001438> is well defined
2019-02-06 09:49:57 - run.py - <module> - INFO - execute module: <DB.schema_definition.DB instance at 0x000000002DAACCC8>
2019-02-06 09:49:57 - run.py - <module> - INFO - *********Started executing DB
2019-02-06 09:49:57 - run.py - <module> - INFO - *********Finished executing DB
2019-02-06 09:49:57 - run.py - <module> - INFO - execute module: <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x0000000028001438>
2019-02-06 09:49:57 - run.py - <module> - INFO - *********Started executing AddAuthorConnectionClaimId
2019-02-06 09:49:57 - run.py - <module> - INFO - *********Finished executing AddAuthorConnectionClaimId
2019-02-06 09:50:16 - run.py - <module> - INFO - Start Execution ... 
2019-02-06 09:50:16 - run.py - <module> - INFO - SETUP global variables
2019-02-06 09:50:16 - run.py - <module> - INFO - CREATE pipeline
2019-02-06 09:50:16 - run.py - <module> - INFO - SETUP pipeline
2019-02-06 09:50:16 - run.py - <module> - INFO - setup module: <DB.schema_definition.DB instance at 0x000000002DD5BC88>
2019-02-06 09:50:16 - run.py - <module> - INFO - setup module: <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x00000000283EE438>
2019-02-06 09:50:16 - run.py - <module> - INFO - checking module definition
2019-02-06 09:50:16 - run.py - <module> - INFO - module <DB.schema_definition.DB instance at 0x000000002DD5BC88> is well defined
2019-02-06 09:50:16 - run.py - <module> - INFO - module <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x00000000283EE438> is well defined
2019-02-06 09:50:16 - run.py - <module> - INFO - execute module: <DB.schema_definition.DB instance at 0x000000002DD5BC88>
2019-02-06 09:50:16 - run.py - <module> - INFO - *********Started executing DB
2019-02-06 09:50:16 - run.py - <module> - INFO - *********Finished executing DB
2019-02-06 09:50:16 - run.py - <module> - INFO - execute module: <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x00000000283EE438>
2019-02-06 09:50:16 - run.py - <module> - INFO - *********Started executing AddAuthorConnectionClaimId
2019-02-06 09:50:16 - run.py - <module> - INFO - *********Finished executing AddAuthorConnectionClaimId
2019-02-06 09:57:19 - run.py - <module> - INFO - Start Execution ... 
2019-02-06 09:57:19 - run.py - <module> - INFO - SETUP global variables
2019-02-06 09:57:19 - run.py - <module> - INFO - CREATE pipeline
2019-02-06 09:57:19 - run.py - <module> - INFO - SETUP pipeline
2019-02-06 09:57:19 - run.py - <module> - INFO - setup module: <DB.schema_definition.DB instance at 0x000000002DA6BCC8>
2019-02-06 09:57:19 - run.py - <module> - INFO - setup module: <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x000000002800E438>
2019-02-06 09:57:19 - run.py - <module> - INFO - checking module definition
2019-02-06 09:57:19 - run.py - <module> - INFO - module <DB.schema_definition.DB instance at 0x000000002DA6BCC8> is well defined
2019-02-06 09:57:19 - run.py - <module> - INFO - module <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x000000002800E438> is well defined
2019-02-06 09:57:19 - run.py - <module> - INFO - execute module: <DB.schema_definition.DB instance at 0x000000002DA6BCC8>
2019-02-06 09:57:19 - run.py - <module> - INFO - *********Started executing DB
2019-02-06 09:57:19 - run.py - <module> - INFO - *********Finished executing DB
2019-02-06 09:57:19 - run.py - <module> - INFO - execute module: <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x000000002800E438>
2019-02-06 09:57:19 - run.py - <module> - INFO - *********Started executing AddAuthorConnectionClaimId
2019-02-06 09:57:19 - run.py - <module> - INFO - *********Finished executing AddAuthorConnectionClaimId
2019-02-06 10:33:05 - run.py - <module> - INFO - Start Execution ... 
2019-02-06 10:33:05 - run.py - <module> - INFO - SETUP global variables
2019-02-06 10:33:05 - run.py - <module> - INFO - CREATE pipeline
2019-02-06 10:33:05 - run.py - <module> - INFO - SETUP pipeline
2019-02-06 10:33:05 - run.py - <module> - INFO - setup module: <DB.schema_definition.DB instance at 0x000000002E53FD88>
2019-02-06 10:33:05 - run.py - <module> - INFO - setup module: <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x0000000028BB3470>
2019-02-06 10:33:05 - run.py - <module> - INFO - setup module: <newsapi_crawler.newsapi_crawler.NewsAPI_Crawler object at 0x000000002E53D940>
2019-02-06 10:33:05 - run.py - <module> - INFO - checking module definition
2019-02-06 10:33:05 - run.py - <module> - INFO - module <DB.schema_definition.DB instance at 0x000000002E53FD88> is well defined
2019-02-06 10:33:05 - run.py - <module> - INFO - module <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x0000000028BB3470> is well defined
2019-02-06 10:33:05 - run.py - <module> - INFO - module <newsapi_crawler.newsapi_crawler.NewsAPI_Crawler object at 0x000000002E53D940> is well defined
2019-02-06 10:33:05 - run.py - <module> - INFO - execute module: <DB.schema_definition.DB instance at 0x000000002E53FD88>
2019-02-06 10:33:05 - run.py - <module> - INFO - *********Started executing DB
2019-02-06 10:33:05 - run.py - <module> - INFO - *********Finished executing DB
2019-02-06 10:33:05 - run.py - <module> - INFO - execute module: <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x0000000028BB3470>
2019-02-06 10:33:05 - run.py - <module> - INFO - *********Started executing AddAuthorConnectionClaimId
2019-02-06 10:33:05 - run.py - <module> - INFO - *********Finished executing AddAuthorConnectionClaimId
2019-02-06 10:33:05 - run.py - <module> - INFO - execute module: <newsapi_crawler.newsapi_crawler.NewsAPI_Crawler object at 0x000000002E53D940>
2019-02-06 10:33:05 - run.py - <module> - INFO - *********Started executing NewsAPI_Crawler
2019-02-06 10:33:05 - method_executor.py - execute - INFO - execute started for get_most_popular_posts_by_google_trends started at 1549441986.0
2019-02-06 10:33:05 - method_executor.py - execute - INFO - get_most_popular_posts_by_google_trends execute window_start 2000-06-07 00:00:00
2019-02-06 10:33:07 - method_executor.py - execute - ERROR - Failed in the new crawling process!
2019-02-06 10:33:07 - method_executor.py - execute - INFO - execute ended at 1549441987.29
2019-02-06 10:33:07 - run.py - <module> - INFO - *********Finished executing NewsAPI_Crawler
2019-02-06 10:33:26 - run.py - <module> - INFO - Start Execution ... 
2019-02-06 10:33:26 - run.py - <module> - INFO - SETUP global variables
2019-02-06 10:33:26 - run.py - <module> - INFO - CREATE pipeline
2019-02-06 10:33:26 - run.py - <module> - INFO - SETUP pipeline
2019-02-06 10:33:26 - run.py - <module> - INFO - setup module: <DB.schema_definition.DB instance at 0x000000002E5605C8>
2019-02-06 10:33:26 - run.py - <module> - INFO - setup module: <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x0000000029143588>
2019-02-06 10:33:26 - run.py - <module> - INFO - setup module: <newsapi_crawler.newsapi_crawler.NewsAPI_Crawler object at 0x000000002E561C88>
2019-02-06 10:33:26 - run.py - <module> - INFO - checking module definition
2019-02-06 10:33:26 - run.py - <module> - INFO - module <DB.schema_definition.DB instance at 0x000000002E5605C8> is well defined
2019-02-06 10:33:26 - run.py - <module> - INFO - module <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x0000000029143588> is well defined
2019-02-06 10:33:26 - run.py - <module> - INFO - module <newsapi_crawler.newsapi_crawler.NewsAPI_Crawler object at 0x000000002E561C88> is well defined
2019-02-06 10:33:26 - run.py - <module> - INFO - execute module: <DB.schema_definition.DB instance at 0x000000002E5605C8>
2019-02-06 10:33:26 - run.py - <module> - INFO - *********Started executing DB
2019-02-06 10:33:26 - run.py - <module> - INFO - *********Finished executing DB
2019-02-06 10:33:26 - run.py - <module> - INFO - execute module: <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x0000000029143588>
2019-02-06 10:33:26 - run.py - <module> - INFO - *********Started executing AddAuthorConnectionClaimId
2019-02-06 10:33:26 - run.py - <module> - INFO - *********Finished executing AddAuthorConnectionClaimId
2019-02-06 10:33:26 - run.py - <module> - INFO - execute module: <newsapi_crawler.newsapi_crawler.NewsAPI_Crawler object at 0x000000002E561C88>
2019-02-06 10:33:26 - run.py - <module> - INFO - *********Started executing NewsAPI_Crawler
2019-02-06 10:33:26 - method_executor.py - execute - INFO - execute started for get_most_popular_posts_by_google_trends started at 1549442006.41
2019-02-06 10:33:26 - method_executor.py - execute - INFO - get_most_popular_posts_by_google_trends execute window_start 2000-06-07 00:00:00
2019-02-06 10:33:27 - method_executor.py - execute - ERROR - Failed in the new crawling process!
2019-02-06 10:33:27 - method_executor.py - execute - INFO - execute ended at 1549442007.8
2019-02-06 10:33:27 - run.py - <module> - INFO - *********Finished executing NewsAPI_Crawler
2019-02-06 10:35:25 - run.py - <module> - INFO - Start Execution ... 
2019-02-06 10:35:25 - run.py - <module> - INFO - SETUP global variables
2019-02-06 10:35:25 - run.py - <module> - INFO - CREATE pipeline
2019-02-06 10:35:25 - run.py - <module> - INFO - SETUP pipeline
2019-02-06 10:35:25 - run.py - <module> - INFO - setup module: <DB.schema_definition.DB instance at 0x000000002DF6D648>
2019-02-06 10:35:25 - run.py - <module> - INFO - setup module: <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x0000000028521470>
2019-02-06 10:35:25 - run.py - <module> - INFO - setup module: <newsapi_crawler.newsapi_crawler.NewsAPI_Crawler object at 0x000000002DF6AD30>
2019-02-06 10:35:25 - run.py - <module> - INFO - checking module definition
2019-02-06 10:35:25 - run.py - <module> - INFO - module <DB.schema_definition.DB instance at 0x000000002DF6D648> is well defined
2019-02-06 10:35:25 - run.py - <module> - INFO - module <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x0000000028521470> is well defined
2019-02-06 10:35:25 - run.py - <module> - INFO - module <newsapi_crawler.newsapi_crawler.NewsAPI_Crawler object at 0x000000002DF6AD30> is well defined
2019-02-06 10:35:25 - run.py - <module> - INFO - execute module: <DB.schema_definition.DB instance at 0x000000002DF6D648>
2019-02-06 10:35:25 - run.py - <module> - INFO - *********Started executing DB
2019-02-06 10:35:25 - run.py - <module> - INFO - *********Finished executing DB
2019-02-06 10:35:25 - run.py - <module> - INFO - execute module: <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x0000000028521470>
2019-02-06 10:35:25 - run.py - <module> - INFO - *********Started executing AddAuthorConnectionClaimId
2019-02-06 10:35:25 - run.py - <module> - INFO - *********Finished executing AddAuthorConnectionClaimId
2019-02-06 10:35:25 - run.py - <module> - INFO - execute module: <newsapi_crawler.newsapi_crawler.NewsAPI_Crawler object at 0x000000002DF6AD30>
2019-02-06 10:35:25 - run.py - <module> - INFO - *********Started executing NewsAPI_Crawler
2019-02-06 10:35:25 - method_executor.py - execute - INFO - execute started for get_most_popular_posts_by_google_trends started at 1549442125.58
2019-02-06 10:35:25 - method_executor.py - execute - INFO - get_most_popular_posts_by_google_trends execute window_start 2000-06-07 00:00:00
2019-02-06 10:35:26 - method_executor.py - execute - ERROR - Failed in the new crawling process!
2019-02-06 10:35:26 - method_executor.py - execute - INFO - execute ended at 1549442126.9
2019-02-06 10:35:26 - run.py - <module> - INFO - *********Finished executing NewsAPI_Crawler
2019-02-06 10:36:28 - run.py - <module> - INFO - Start Execution ... 
2019-02-06 10:36:28 - run.py - <module> - INFO - SETUP global variables
2019-02-06 10:36:28 - run.py - <module> - INFO - CREATE pipeline
2019-02-06 10:36:28 - run.py - <module> - INFO - SETUP pipeline
2019-02-06 10:36:28 - run.py - <module> - INFO - setup module: <DB.schema_definition.DB instance at 0x000000002DF94508>
2019-02-06 10:36:28 - run.py - <module> - INFO - setup module: <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x0000000028583470>
2019-02-06 10:36:28 - run.py - <module> - INFO - setup module: <newsapi_crawler.newsapi_crawler.NewsAPI_Crawler object at 0x000000002DF91D30>
2019-02-06 10:36:28 - run.py - <module> - INFO - checking module definition
2019-02-06 10:36:28 - run.py - <module> - INFO - module <DB.schema_definition.DB instance at 0x000000002DF94508> is well defined
2019-02-06 10:36:28 - run.py - <module> - INFO - module <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x0000000028583470> is well defined
2019-02-06 10:36:28 - run.py - <module> - INFO - module <newsapi_crawler.newsapi_crawler.NewsAPI_Crawler object at 0x000000002DF91D30> is well defined
2019-02-06 10:36:28 - run.py - <module> - INFO - execute module: <DB.schema_definition.DB instance at 0x000000002DF94508>
2019-02-06 10:36:28 - run.py - <module> - INFO - *********Started executing DB
2019-02-06 10:36:28 - run.py - <module> - INFO - *********Finished executing DB
2019-02-06 10:36:28 - run.py - <module> - INFO - execute module: <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x0000000028583470>
2019-02-06 10:36:28 - run.py - <module> - INFO - *********Started executing AddAuthorConnectionClaimId
2019-02-06 10:36:28 - run.py - <module> - INFO - *********Finished executing AddAuthorConnectionClaimId
2019-02-06 10:36:28 - run.py - <module> - INFO - execute module: <newsapi_crawler.newsapi_crawler.NewsAPI_Crawler object at 0x000000002DF91D30>
2019-02-06 10:36:28 - run.py - <module> - INFO - *********Started executing NewsAPI_Crawler
2019-02-06 10:36:28 - method_executor.py - execute - INFO - execute started for get_most_popular_posts_by_google_trends started at 1549442188.04
2019-02-06 10:36:28 - method_executor.py - execute - INFO - get_most_popular_posts_by_google_trends execute window_start 2000-06-07 00:00:00
2019-02-06 10:36:29 - method_executor.py - execute - ERROR - Failed in the new crawling process!
2019-02-06 10:36:29 - method_executor.py - execute - INFO - execute ended at 1549442189.42
2019-02-06 10:36:29 - run.py - <module> - INFO - *********Finished executing NewsAPI_Crawler
2019-02-06 10:48:47 - run.py - <module> - INFO - Start Execution ... 
2019-02-06 10:48:47 - run.py - <module> - INFO - SETUP global variables
2019-02-06 10:48:47 - run.py - <module> - INFO - CREATE pipeline
2019-02-06 10:48:47 - run.py - <module> - INFO - SETUP pipeline
2019-02-06 10:48:47 - run.py - <module> - INFO - setup module: <DB.schema_definition.DB instance at 0x000000002D92F5C8>
2019-02-06 10:48:47 - run.py - <module> - INFO - setup module: <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x0000000027FC1470>
2019-02-06 10:48:47 - run.py - <module> - INFO - setup module: <newsapi_crawler.newsapi_crawler.NewsAPI_Crawler object at 0x000000002D92CD30>
2019-02-06 10:48:47 - run.py - <module> - INFO - checking module definition
2019-02-06 10:48:47 - run.py - <module> - INFO - module <DB.schema_definition.DB instance at 0x000000002D92F5C8> is well defined
2019-02-06 10:48:47 - run.py - <module> - INFO - module <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x0000000027FC1470> is well defined
2019-02-06 10:48:47 - run.py - <module> - INFO - module <newsapi_crawler.newsapi_crawler.NewsAPI_Crawler object at 0x000000002D92CD30> is well defined
2019-02-06 10:48:47 - run.py - <module> - INFO - execute module: <DB.schema_definition.DB instance at 0x000000002D92F5C8>
2019-02-06 10:48:47 - run.py - <module> - INFO - *********Started executing DB
2019-02-06 10:48:47 - run.py - <module> - INFO - *********Finished executing DB
2019-02-06 10:48:47 - run.py - <module> - INFO - execute module: <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x0000000027FC1470>
2019-02-06 10:48:47 - run.py - <module> - INFO - *********Started executing AddAuthorConnectionClaimId
2019-02-06 10:48:47 - run.py - <module> - INFO - *********Finished executing AddAuthorConnectionClaimId
2019-02-06 10:48:47 - run.py - <module> - INFO - execute module: <newsapi_crawler.newsapi_crawler.NewsAPI_Crawler object at 0x000000002D92CD30>
2019-02-06 10:48:47 - run.py - <module> - INFO - *********Started executing NewsAPI_Crawler
2019-02-06 10:48:47 - method_executor.py - execute - INFO - execute started for get_most_popular_posts_by_google_trends started at 1549442927.46
2019-02-06 10:48:47 - method_executor.py - execute - INFO - get_most_popular_posts_by_google_trends execute window_start 2000-06-07 00:00:00
2019-02-06 10:49:46 - method_executor.py - execute - ERROR - Failed in the new crawling process!
2019-02-06 10:49:46 - method_executor.py - execute - INFO - execute ended at 1549442986.44
2019-02-06 10:49:46 - run.py - <module> - INFO - *********Finished executing NewsAPI_Crawler
2019-02-06 10:53:09 - run.py - <module> - INFO - Start Execution ... 
2019-02-06 10:53:09 - run.py - <module> - INFO - SETUP global variables
2019-02-06 10:53:09 - run.py - <module> - INFO - CREATE pipeline
2019-02-06 10:53:09 - run.py - <module> - INFO - SETUP pipeline
2019-02-06 10:53:09 - run.py - <module> - INFO - setup module: <DB.schema_definition.DB instance at 0x000000002D856B08>
2019-02-06 10:53:09 - run.py - <module> - INFO - setup module: <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x0000000027E33390>
2019-02-06 10:53:09 - run.py - <module> - INFO - setup module: <newsapi_crawler.newsapi_crawler.NewsAPI_Crawler object at 0x000000002D84E9E8>
2019-02-06 10:53:09 - run.py - <module> - INFO - checking module definition
2019-02-06 10:53:09 - run.py - <module> - INFO - module <DB.schema_definition.DB instance at 0x000000002D856B08> is well defined
2019-02-06 10:53:09 - run.py - <module> - INFO - module <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x0000000027E33390> is well defined
2019-02-06 10:53:09 - run.py - <module> - INFO - module <newsapi_crawler.newsapi_crawler.NewsAPI_Crawler object at 0x000000002D84E9E8> is well defined
2019-02-06 10:53:09 - run.py - <module> - INFO - execute module: <DB.schema_definition.DB instance at 0x000000002D856B08>
2019-02-06 10:53:09 - run.py - <module> - INFO - *********Started executing DB
2019-02-06 10:53:09 - run.py - <module> - INFO - *********Finished executing DB
2019-02-06 10:53:09 - run.py - <module> - INFO - execute module: <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x0000000027E33390>
2019-02-06 10:53:09 - run.py - <module> - INFO - *********Started executing AddAuthorConnectionClaimId
2019-02-06 10:53:09 - run.py - <module> - INFO - *********Finished executing AddAuthorConnectionClaimId
2019-02-06 10:53:09 - run.py - <module> - INFO - execute module: <newsapi_crawler.newsapi_crawler.NewsAPI_Crawler object at 0x000000002D84E9E8>
2019-02-06 10:53:09 - run.py - <module> - INFO - *********Started executing NewsAPI_Crawler
2019-02-06 10:53:09 - method_executor.py - execute - INFO - execute started for get_most_popular_posts_by_google_trends started at 1549443189.72
2019-02-06 10:53:09 - method_executor.py - execute - INFO - get_most_popular_posts_by_google_trends execute window_start 2000-06-07 00:00:00
2019-02-06 10:53:54 - run.py - <module> - INFO - Start Execution ... 
2019-02-06 10:53:54 - run.py - <module> - INFO - SETUP global variables
2019-02-06 10:53:54 - run.py - <module> - INFO - CREATE pipeline
2019-02-06 10:53:54 - run.py - <module> - INFO - SETUP pipeline
2019-02-06 10:53:54 - run.py - <module> - INFO - setup module: <DB.schema_definition.DB instance at 0x000000002DE72288>
2019-02-06 10:53:54 - run.py - <module> - INFO - setup module: <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x00000000285E3470>
2019-02-06 10:53:54 - run.py - <module> - INFO - setup module: <newsapi_crawler.newsapi_crawler.NewsAPI_Crawler object at 0x000000002DFF1D30>
2019-02-06 10:53:54 - run.py - <module> - INFO - checking module definition
2019-02-06 10:53:54 - run.py - <module> - INFO - module <DB.schema_definition.DB instance at 0x000000002DE72288> is well defined
2019-02-06 10:53:54 - run.py - <module> - INFO - module <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x00000000285E3470> is well defined
2019-02-06 10:53:54 - run.py - <module> - INFO - module <newsapi_crawler.newsapi_crawler.NewsAPI_Crawler object at 0x000000002DFF1D30> is well defined
2019-02-06 10:53:54 - run.py - <module> - INFO - execute module: <DB.schema_definition.DB instance at 0x000000002DE72288>
2019-02-06 10:53:54 - run.py - <module> - INFO - *********Started executing DB
2019-02-06 10:53:54 - run.py - <module> - INFO - *********Finished executing DB
2019-02-06 10:53:54 - run.py - <module> - INFO - execute module: <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x00000000285E3470>
2019-02-06 10:53:54 - run.py - <module> - INFO - *********Started executing AddAuthorConnectionClaimId
2019-02-06 10:53:54 - run.py - <module> - INFO - *********Finished executing AddAuthorConnectionClaimId
2019-02-06 10:53:54 - run.py - <module> - INFO - execute module: <newsapi_crawler.newsapi_crawler.NewsAPI_Crawler object at 0x000000002DFF1D30>
2019-02-06 10:53:54 - run.py - <module> - INFO - *********Started executing NewsAPI_Crawler
2019-02-06 10:53:54 - method_executor.py - execute - INFO - execute started for get_most_popular_posts_by_google_trends started at 1549443235.0
2019-02-06 10:53:54 - method_executor.py - execute - INFO - get_most_popular_posts_by_google_trends execute window_start 2000-06-07 00:00:00
2019-02-06 10:57:23 - run.py - <module> - INFO - Start Execution ... 
2019-02-06 10:57:23 - run.py - <module> - INFO - SETUP global variables
2019-02-06 10:57:23 - run.py - <module> - INFO - CREATE pipeline
2019-02-06 10:57:23 - run.py - <module> - INFO - SETUP pipeline
2019-02-06 10:57:23 - run.py - <module> - INFO - setup module: <DB.schema_definition.DB instance at 0x000000002DFE4548>
2019-02-06 10:57:23 - run.py - <module> - INFO - setup module: <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x00000000285D3470>
2019-02-06 10:57:23 - run.py - <module> - INFO - setup module: <newsapi_crawler.newsapi_crawler.NewsAPI_Crawler object at 0x000000002DFE1D30>
2019-02-06 10:57:23 - run.py - <module> - INFO - checking module definition
2019-02-06 10:57:23 - run.py - <module> - INFO - module <DB.schema_definition.DB instance at 0x000000002DFE4548> is well defined
2019-02-06 10:57:23 - run.py - <module> - INFO - module <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x00000000285D3470> is well defined
2019-02-06 10:57:23 - run.py - <module> - INFO - module <newsapi_crawler.newsapi_crawler.NewsAPI_Crawler object at 0x000000002DFE1D30> is well defined
2019-02-06 10:57:23 - run.py - <module> - INFO - execute module: <DB.schema_definition.DB instance at 0x000000002DFE4548>
2019-02-06 10:57:23 - run.py - <module> - INFO - *********Started executing DB
2019-02-06 10:57:23 - run.py - <module> - INFO - *********Finished executing DB
2019-02-06 10:57:23 - run.py - <module> - INFO - execute module: <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x00000000285D3470>
2019-02-06 10:57:23 - run.py - <module> - INFO - *********Started executing AddAuthorConnectionClaimId
2019-02-06 10:57:23 - run.py - <module> - INFO - *********Finished executing AddAuthorConnectionClaimId
2019-02-06 10:57:23 - run.py - <module> - INFO - execute module: <newsapi_crawler.newsapi_crawler.NewsAPI_Crawler object at 0x000000002DFE1D30>
2019-02-06 10:57:23 - run.py - <module> - INFO - *********Started executing NewsAPI_Crawler
2019-02-06 10:57:23 - method_executor.py - execute - INFO - execute started for get_most_popular_posts_by_google_trends started at 1549443443.16
2019-02-06 10:57:23 - method_executor.py - execute - INFO - get_most_popular_posts_by_google_trends execute window_start 2000-06-07 00:00:00
2019-02-06 10:59:40 - run.py - <module> - INFO - Start Execution ... 
2019-02-06 10:59:40 - run.py - <module> - INFO - SETUP global variables
2019-02-06 10:59:40 - run.py - <module> - INFO - CREATE pipeline
2019-02-06 10:59:40 - run.py - <module> - INFO - SETUP pipeline
2019-02-06 10:59:40 - run.py - <module> - INFO - setup module: <DB.schema_definition.DB instance at 0x000000002E2E8548>
2019-02-06 10:59:40 - run.py - <module> - INFO - setup module: <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x00000000288A1470>
2019-02-06 10:59:40 - run.py - <module> - INFO - setup module: <newsapi_crawler.newsapi_crawler.NewsAPI_Crawler object at 0x000000002E2F1908>
2019-02-06 10:59:40 - run.py - <module> - INFO - checking module definition
2019-02-06 10:59:40 - run.py - <module> - INFO - module <DB.schema_definition.DB instance at 0x000000002E2E8548> is well defined
2019-02-06 10:59:40 - run.py - <module> - INFO - module <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x00000000288A1470> is well defined
2019-02-06 10:59:40 - run.py - <module> - INFO - module <newsapi_crawler.newsapi_crawler.NewsAPI_Crawler object at 0x000000002E2F1908> is well defined
2019-02-06 10:59:40 - run.py - <module> - INFO - execute module: <DB.schema_definition.DB instance at 0x000000002E2E8548>
2019-02-06 10:59:40 - run.py - <module> - INFO - *********Started executing DB
2019-02-06 10:59:40 - run.py - <module> - INFO - *********Finished executing DB
2019-02-06 10:59:40 - run.py - <module> - INFO - execute module: <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x00000000288A1470>
2019-02-06 10:59:40 - run.py - <module> - INFO - *********Started executing AddAuthorConnectionClaimId
2019-02-06 10:59:40 - run.py - <module> - INFO - *********Finished executing AddAuthorConnectionClaimId
2019-02-06 10:59:40 - run.py - <module> - INFO - execute module: <newsapi_crawler.newsapi_crawler.NewsAPI_Crawler object at 0x000000002E2F1908>
2019-02-06 10:59:40 - run.py - <module> - INFO - *********Started executing NewsAPI_Crawler
2019-02-06 10:59:40 - method_executor.py - execute - INFO - execute started for get_most_popular_posts_by_google_trends started at 1549443580.37
2019-02-06 10:59:40 - method_executor.py - execute - INFO - get_most_popular_posts_by_google_trends execute window_start 2000-06-07 00:00:00
2019-02-06 10:59:43 - schema_definition.py - addPosts - INFO - total Posts inserted to DB: 0
2019-02-06 10:59:43 - method_executor.py - execute - ERROR - Failed in the new crawling process!
2019-02-06 10:59:43 - method_executor.py - execute - INFO - execute ended at 1549443583.11
2019-02-06 10:59:43 - run.py - <module> - INFO - *********Finished executing NewsAPI_Crawler
2019-02-06 11:02:15 - run.py - <module> - INFO - Start Execution ... 
2019-02-06 11:02:15 - run.py - <module> - INFO - SETUP global variables
2019-02-06 11:02:15 - run.py - <module> - INFO - CREATE pipeline
2019-02-06 11:02:15 - run.py - <module> - INFO - SETUP pipeline
2019-02-06 11:02:15 - run.py - <module> - INFO - setup module: <DB.schema_definition.DB instance at 0x000000002E0C4048>
2019-02-06 11:02:15 - run.py - <module> - INFO - setup module: <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x00000000286B3470>
2019-02-06 11:02:15 - run.py - <module> - INFO - setup module: <newsapi_crawler.newsapi_crawler.NewsAPI_Crawler object at 0x000000002E0C1D30>
2019-02-06 11:02:15 - run.py - <module> - INFO - checking module definition
2019-02-06 11:02:15 - run.py - <module> - INFO - module <DB.schema_definition.DB instance at 0x000000002E0C4048> is well defined
2019-02-06 11:02:15 - run.py - <module> - INFO - module <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x00000000286B3470> is well defined
2019-02-06 11:02:15 - run.py - <module> - INFO - module <newsapi_crawler.newsapi_crawler.NewsAPI_Crawler object at 0x000000002E0C1D30> is well defined
2019-02-06 11:02:15 - run.py - <module> - INFO - execute module: <DB.schema_definition.DB instance at 0x000000002E0C4048>
2019-02-06 11:02:15 - run.py - <module> - INFO - *********Started executing DB
2019-02-06 11:02:15 - run.py - <module> - INFO - *********Finished executing DB
2019-02-06 11:02:15 - run.py - <module> - INFO - execute module: <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x00000000286B3470>
2019-02-06 11:02:15 - run.py - <module> - INFO - *********Started executing AddAuthorConnectionClaimId
2019-02-06 11:02:15 - run.py - <module> - INFO - *********Finished executing AddAuthorConnectionClaimId
2019-02-06 11:02:15 - run.py - <module> - INFO - execute module: <newsapi_crawler.newsapi_crawler.NewsAPI_Crawler object at 0x000000002E0C1D30>
2019-02-06 11:02:15 - run.py - <module> - INFO - *********Started executing NewsAPI_Crawler
2019-02-06 11:02:15 - method_executor.py - execute - INFO - execute started for get_most_popular_posts_by_google_trends started at 1549443735.74
2019-02-06 11:02:15 - method_executor.py - execute - INFO - get_most_popular_posts_by_google_trends execute window_start 2000-06-07 00:00:00
2019-02-06 11:02:17 - schema_definition.py - addPosts - INFO - total Posts inserted to DB: 0
2019-02-06 11:02:17 - method_executor.py - execute - ERROR - Failed in the new crawling process!
2019-02-06 11:02:17 - method_executor.py - execute - INFO - execute ended at 1549443737.23
2019-02-06 11:02:17 - run.py - <module> - INFO - *********Finished executing NewsAPI_Crawler
2019-02-06 11:06:29 - run.py - <module> - INFO - Start Execution ... 
2019-02-06 11:06:29 - run.py - <module> - INFO - SETUP global variables
2019-02-06 11:06:29 - run.py - <module> - INFO - CREATE pipeline
2019-02-06 11:06:29 - run.py - <module> - INFO - SETUP pipeline
2019-02-06 11:06:29 - run.py - <module> - INFO - setup module: <DB.schema_definition.DB instance at 0x000000002E478B08>
2019-02-06 11:06:29 - run.py - <module> - INFO - setup module: <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x0000000028B43390>
2019-02-06 11:06:29 - run.py - <module> - INFO - setup module: <newsapi_crawler.newsapi_crawler.NewsAPI_Crawler object at 0x000000002E46E9E8>
2019-02-06 11:06:29 - run.py - <module> - INFO - checking module definition
2019-02-06 11:06:29 - run.py - <module> - INFO - module <DB.schema_definition.DB instance at 0x000000002E478B08> is well defined
2019-02-06 11:06:29 - run.py - <module> - INFO - module <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x0000000028B43390> is well defined
2019-02-06 11:06:29 - run.py - <module> - INFO - module <newsapi_crawler.newsapi_crawler.NewsAPI_Crawler object at 0x000000002E46E9E8> is well defined
2019-02-06 11:06:29 - run.py - <module> - INFO - execute module: <DB.schema_definition.DB instance at 0x000000002E478B08>
2019-02-06 11:06:29 - run.py - <module> - INFO - *********Started executing DB
2019-02-06 11:06:29 - run.py - <module> - INFO - *********Finished executing DB
2019-02-06 11:06:29 - run.py - <module> - INFO - execute module: <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x0000000028B43390>
2019-02-06 11:06:29 - run.py - <module> - INFO - *********Started executing AddAuthorConnectionClaimId
2019-02-06 11:06:29 - run.py - <module> - INFO - *********Finished executing AddAuthorConnectionClaimId
2019-02-06 11:06:29 - run.py - <module> - INFO - execute module: <newsapi_crawler.newsapi_crawler.NewsAPI_Crawler object at 0x000000002E46E9E8>
2019-02-06 11:06:29 - run.py - <module> - INFO - *********Started executing NewsAPI_Crawler
2019-02-06 11:06:29 - method_executor.py - execute - INFO - execute started for get_most_popular_posts_by_google_trends started at 1549443989.98
2019-02-06 11:06:29 - method_executor.py - execute - INFO - get_most_popular_posts_by_google_trends execute window_start 2000-06-07 00:00:00
2019-02-06 11:06:31 - schema_definition.py - addPosts - INFO - total Posts inserted to DB: 0
2019-02-06 11:06:31 - method_executor.py - execute - ERROR - Failed in the new crawling process!
2019-02-06 11:06:31 - method_executor.py - execute - INFO - execute ended at 1549443991.37
2019-02-06 11:06:31 - run.py - <module> - INFO - *********Finished executing NewsAPI_Crawler
2019-02-06 11:12:33 - run.py - <module> - INFO - Start Execution ... 
2019-02-06 11:12:33 - run.py - <module> - INFO - SETUP global variables
2019-02-06 11:12:33 - run.py - <module> - INFO - CREATE pipeline
2019-02-06 11:12:33 - run.py - <module> - INFO - SETUP pipeline
2019-02-06 11:12:33 - run.py - <module> - INFO - setup module: <DB.schema_definition.DB instance at 0x000000002DA0C2C8>
2019-02-06 11:12:33 - run.py - <module> - INFO - setup module: <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x0000000027FBD390>
2019-02-06 11:12:33 - run.py - <module> - INFO - setup module: <newsapi_crawler.newsapi_crawler.NewsAPI_Crawler object at 0x000000002DA03C18>
2019-02-06 11:12:33 - run.py - <module> - INFO - checking module definition
2019-02-06 11:12:33 - run.py - <module> - INFO - module <DB.schema_definition.DB instance at 0x000000002DA0C2C8> is well defined
2019-02-06 11:12:33 - run.py - <module> - INFO - module <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x0000000027FBD390> is well defined
2019-02-06 11:12:33 - run.py - <module> - INFO - module <newsapi_crawler.newsapi_crawler.NewsAPI_Crawler object at 0x000000002DA03C18> is well defined
2019-02-06 11:12:33 - run.py - <module> - INFO - execute module: <DB.schema_definition.DB instance at 0x000000002DA0C2C8>
2019-02-06 11:12:33 - run.py - <module> - INFO - *********Started executing DB
2019-02-06 11:12:33 - run.py - <module> - INFO - *********Finished executing DB
2019-02-06 11:12:33 - run.py - <module> - INFO - execute module: <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x0000000027FBD390>
2019-02-06 11:12:33 - run.py - <module> - INFO - *********Started executing AddAuthorConnectionClaimId
2019-02-06 11:12:33 - run.py - <module> - INFO - *********Finished executing AddAuthorConnectionClaimId
2019-02-06 11:12:33 - run.py - <module> - INFO - execute module: <newsapi_crawler.newsapi_crawler.NewsAPI_Crawler object at 0x000000002DA03C18>
2019-02-06 11:12:33 - run.py - <module> - INFO - *********Started executing NewsAPI_Crawler
2019-02-06 11:12:33 - method_executor.py - execute - INFO - execute started for get_most_popular_posts_by_google_trends started at 1549444353.42
2019-02-06 11:12:33 - method_executor.py - execute - INFO - get_most_popular_posts_by_google_trends execute window_start 2000-06-07 00:00:00
2019-02-06 11:12:35 - schema_definition.py - addPosts - INFO - total Posts inserted to DB: 0
2019-02-06 11:12:35 - method_executor.py - execute - ERROR - Failed in the new crawling process!
2019-02-06 11:12:35 - method_executor.py - execute - INFO - execute ended at 1549444355.04
2019-02-06 11:12:35 - run.py - <module> - INFO - *********Finished executing NewsAPI_Crawler
2019-02-06 11:14:48 - run.py - <module> - INFO - Start Execution ... 
2019-02-06 11:14:48 - run.py - <module> - INFO - SETUP global variables
2019-02-06 11:14:48 - run.py - <module> - INFO - CREATE pipeline
2019-02-06 11:14:48 - run.py - <module> - INFO - SETUP pipeline
2019-02-06 11:14:48 - run.py - <module> - INFO - setup module: <DB.schema_definition.DB instance at 0x000000002E265308>
2019-02-06 11:14:48 - run.py - <module> - INFO - setup module: <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x00000000288C3390>
2019-02-06 11:14:48 - run.py - <module> - INFO - setup module: <newsapi_crawler.newsapi_crawler.NewsAPI_Crawler object at 0x000000002E25CC18>
2019-02-06 11:14:48 - run.py - <module> - INFO - checking module definition
2019-02-06 11:14:48 - run.py - <module> - INFO - module <DB.schema_definition.DB instance at 0x000000002E265308> is well defined
2019-02-06 11:14:48 - run.py - <module> - INFO - module <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x00000000288C3390> is well defined
2019-02-06 11:14:48 - run.py - <module> - INFO - module <newsapi_crawler.newsapi_crawler.NewsAPI_Crawler object at 0x000000002E25CC18> is well defined
2019-02-06 11:14:48 - run.py - <module> - INFO - execute module: <DB.schema_definition.DB instance at 0x000000002E265308>
2019-02-06 11:14:48 - run.py - <module> - INFO - *********Started executing DB
2019-02-06 11:14:48 - run.py - <module> - INFO - *********Finished executing DB
2019-02-06 11:14:48 - run.py - <module> - INFO - execute module: <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x00000000288C3390>
2019-02-06 11:14:48 - run.py - <module> - INFO - *********Started executing AddAuthorConnectionClaimId
2019-02-06 11:14:48 - run.py - <module> - INFO - *********Finished executing AddAuthorConnectionClaimId
2019-02-06 11:14:48 - run.py - <module> - INFO - execute module: <newsapi_crawler.newsapi_crawler.NewsAPI_Crawler object at 0x000000002E25CC18>
2019-02-06 11:14:48 - run.py - <module> - INFO - *********Started executing NewsAPI_Crawler
2019-02-06 11:14:48 - method_executor.py - execute - INFO - execute started for get_most_popular_posts_by_google_trends started at 1549444488.35
2019-02-06 11:14:48 - method_executor.py - execute - INFO - get_most_popular_posts_by_google_trends execute window_start 2000-06-07 00:00:00
2019-02-06 11:14:49 - schema_definition.py - addPosts - INFO - total Posts inserted to DB: 0
2019-02-06 11:14:49 - method_executor.py - execute - ERROR - Failed in the new crawling process!
2019-02-06 11:14:49 - method_executor.py - execute - INFO - execute ended at 1549444489.84
2019-02-06 11:14:49 - run.py - <module> - INFO - *********Finished executing NewsAPI_Crawler
2019-02-06 11:15:49 - run.py - <module> - INFO - Start Execution ... 
2019-02-06 11:15:49 - run.py - <module> - INFO - SETUP global variables
2019-02-06 11:15:49 - run.py - <module> - INFO - CREATE pipeline
2019-02-06 11:15:49 - run.py - <module> - INFO - SETUP pipeline
2019-02-06 11:15:49 - run.py - <module> - INFO - setup module: <DB.schema_definition.DB instance at 0x000000002D775308>
2019-02-06 11:15:49 - run.py - <module> - INFO - setup module: <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x0000000027D93390>
2019-02-06 11:15:49 - run.py - <module> - INFO - setup module: <newsapi_crawler.newsapi_crawler.NewsAPI_Crawler object at 0x000000002D76CC18>
2019-02-06 11:15:49 - run.py - <module> - INFO - checking module definition
2019-02-06 11:15:49 - run.py - <module> - INFO - module <DB.schema_definition.DB instance at 0x000000002D775308> is well defined
2019-02-06 11:15:49 - run.py - <module> - INFO - module <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x0000000027D93390> is well defined
2019-02-06 11:15:49 - run.py - <module> - INFO - module <newsapi_crawler.newsapi_crawler.NewsAPI_Crawler object at 0x000000002D76CC18> is well defined
2019-02-06 11:15:49 - run.py - <module> - INFO - execute module: <DB.schema_definition.DB instance at 0x000000002D775308>
2019-02-06 11:15:49 - run.py - <module> - INFO - *********Started executing DB
2019-02-06 11:15:49 - run.py - <module> - INFO - *********Finished executing DB
2019-02-06 11:15:49 - run.py - <module> - INFO - execute module: <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x0000000027D93390>
2019-02-06 11:15:49 - run.py - <module> - INFO - *********Started executing AddAuthorConnectionClaimId
2019-02-06 11:15:49 - run.py - <module> - INFO - *********Finished executing AddAuthorConnectionClaimId
2019-02-06 11:15:49 - run.py - <module> - INFO - execute module: <newsapi_crawler.newsapi_crawler.NewsAPI_Crawler object at 0x000000002D76CC18>
2019-02-06 11:15:49 - run.py - <module> - INFO - *********Started executing NewsAPI_Crawler
2019-02-06 11:15:49 - method_executor.py - execute - INFO - execute started for get_most_popular_posts_by_google_trends started at 1549444549.85
2019-02-06 11:15:49 - method_executor.py - execute - INFO - get_most_popular_posts_by_google_trends execute window_start 2000-06-07 00:00:00
2019-02-06 11:15:51 - schema_definition.py - addPosts - INFO - total Posts inserted to DB: 0
2019-02-06 11:15:51 - method_executor.py - execute - ERROR - Failed in the new crawling process!
2019-02-06 11:15:51 - method_executor.py - execute - INFO - execute ended at 1549444551.35
2019-02-06 11:15:51 - run.py - <module> - INFO - *********Finished executing NewsAPI_Crawler
2019-02-06 11:17:12 - run.py - <module> - INFO - Start Execution ... 
2019-02-06 11:17:12 - run.py - <module> - INFO - SETUP global variables
2019-02-06 11:17:12 - run.py - <module> - INFO - CREATE pipeline
2019-02-06 11:17:12 - run.py - <module> - INFO - SETUP pipeline
2019-02-06 11:17:12 - run.py - <module> - INFO - setup module: <DB.schema_definition.DB instance at 0x000000002E43E308>
2019-02-06 11:17:12 - run.py - <module> - INFO - setup module: <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x00000000289A1390>
2019-02-06 11:17:12 - run.py - <module> - INFO - setup module: <newsapi_crawler.newsapi_crawler.NewsAPI_Crawler object at 0x000000002E435C18>
2019-02-06 11:17:12 - run.py - <module> - INFO - checking module definition
2019-02-06 11:17:12 - run.py - <module> - INFO - module <DB.schema_definition.DB instance at 0x000000002E43E308> is well defined
2019-02-06 11:17:12 - run.py - <module> - INFO - module <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x00000000289A1390> is well defined
2019-02-06 11:17:12 - run.py - <module> - INFO - module <newsapi_crawler.newsapi_crawler.NewsAPI_Crawler object at 0x000000002E435C18> is well defined
2019-02-06 11:17:12 - run.py - <module> - INFO - execute module: <DB.schema_definition.DB instance at 0x000000002E43E308>
2019-02-06 11:17:12 - run.py - <module> - INFO - *********Started executing DB
2019-02-06 11:17:12 - run.py - <module> - INFO - *********Finished executing DB
2019-02-06 11:17:12 - run.py - <module> - INFO - execute module: <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x00000000289A1390>
2019-02-06 11:17:12 - run.py - <module> - INFO - *********Started executing AddAuthorConnectionClaimId
2019-02-06 11:17:12 - run.py - <module> - INFO - *********Finished executing AddAuthorConnectionClaimId
2019-02-06 11:17:12 - run.py - <module> - INFO - execute module: <newsapi_crawler.newsapi_crawler.NewsAPI_Crawler object at 0x000000002E435C18>
2019-02-06 11:17:12 - run.py - <module> - INFO - *********Started executing NewsAPI_Crawler
2019-02-06 11:17:12 - method_executor.py - execute - INFO - execute started for get_most_popular_posts_by_google_trends started at 1549444632.92
2019-02-06 11:17:12 - method_executor.py - execute - INFO - get_most_popular_posts_by_google_trends execute window_start 2000-06-07 00:00:00
2019-02-06 11:17:14 - schema_definition.py - addPosts - INFO - total Posts inserted to DB: 0
2019-02-06 11:17:14 - method_executor.py - execute - ERROR - Failed in the new crawling process!
2019-02-06 11:17:14 - method_executor.py - execute - INFO - execute ended at 1549444634.41
2019-02-06 11:17:14 - run.py - <module> - INFO - *********Finished executing NewsAPI_Crawler
2019-02-06 11:18:28 - run.py - <module> - INFO - Start Execution ... 
2019-02-06 11:18:28 - run.py - <module> - INFO - SETUP global variables
2019-02-06 11:18:28 - run.py - <module> - INFO - CREATE pipeline
2019-02-06 11:18:28 - run.py - <module> - INFO - SETUP pipeline
2019-02-06 11:18:28 - run.py - <module> - INFO - setup module: <DB.schema_definition.DB instance at 0x000000002DB34488>
2019-02-06 11:18:28 - run.py - <module> - INFO - setup module: <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x0000000028123470>
2019-02-06 11:18:28 - run.py - <module> - INFO - setup module: <newsapi_crawler.newsapi_crawler.NewsAPI_Crawler object at 0x000000002DB31D30>
2019-02-06 11:18:28 - run.py - <module> - INFO - checking module definition
2019-02-06 11:18:28 - run.py - <module> - INFO - module <DB.schema_definition.DB instance at 0x000000002DB34488> is well defined
2019-02-06 11:18:28 - run.py - <module> - INFO - module <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x0000000028123470> is well defined
2019-02-06 11:18:28 - run.py - <module> - INFO - module <newsapi_crawler.newsapi_crawler.NewsAPI_Crawler object at 0x000000002DB31D30> is well defined
2019-02-06 11:18:28 - run.py - <module> - INFO - execute module: <DB.schema_definition.DB instance at 0x000000002DB34488>
2019-02-06 11:18:28 - run.py - <module> - INFO - *********Started executing DB
2019-02-06 11:18:28 - run.py - <module> - INFO - *********Finished executing DB
2019-02-06 11:18:28 - run.py - <module> - INFO - execute module: <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x0000000028123470>
2019-02-06 11:18:28 - run.py - <module> - INFO - *********Started executing AddAuthorConnectionClaimId
2019-02-06 11:18:28 - run.py - <module> - INFO - *********Finished executing AddAuthorConnectionClaimId
2019-02-06 11:18:28 - run.py - <module> - INFO - execute module: <newsapi_crawler.newsapi_crawler.NewsAPI_Crawler object at 0x000000002DB31D30>
2019-02-06 11:18:28 - run.py - <module> - INFO - *********Started executing NewsAPI_Crawler
2019-02-06 11:18:28 - method_executor.py - execute - INFO - execute started for get_most_popular_posts_by_google_trends started at 1549444708.68
2019-02-06 11:18:28 - method_executor.py - execute - INFO - get_most_popular_posts_by_google_trends execute window_start 2000-06-07 00:00:00
2019-02-06 11:18:32 - schema_definition.py - addPosts - INFO - total Posts inserted to DB: 0
2019-02-06 11:18:32 - method_executor.py - execute - ERROR - Failed in the new crawling process!
2019-02-06 11:18:32 - method_executor.py - execute - INFO - execute ended at 1549444712.37
2019-02-06 11:18:32 - run.py - <module> - INFO - *********Finished executing NewsAPI_Crawler
2019-02-06 11:20:03 - run.py - <module> - INFO - Start Execution ... 
2019-02-06 11:20:03 - run.py - <module> - INFO - SETUP global variables
2019-02-06 11:20:03 - run.py - <module> - INFO - CREATE pipeline
2019-02-06 11:20:03 - run.py - <module> - INFO - SETUP pipeline
2019-02-06 11:20:03 - run.py - <module> - INFO - setup module: <DB.schema_definition.DB instance at 0x000000002E38D048>
2019-02-06 11:20:03 - run.py - <module> - INFO - setup module: <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x0000000028991470>
2019-02-06 11:20:03 - run.py - <module> - INFO - setup module: <newsapi_crawler.newsapi_crawler.NewsAPI_Crawler object at 0x000000002E38AD30>
2019-02-06 11:20:03 - run.py - <module> - INFO - checking module definition
2019-02-06 11:20:03 - run.py - <module> - INFO - module <DB.schema_definition.DB instance at 0x000000002E38D048> is well defined
2019-02-06 11:20:03 - run.py - <module> - INFO - module <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x0000000028991470> is well defined
2019-02-06 11:20:03 - run.py - <module> - INFO - module <newsapi_crawler.newsapi_crawler.NewsAPI_Crawler object at 0x000000002E38AD30> is well defined
2019-02-06 11:20:03 - run.py - <module> - INFO - execute module: <DB.schema_definition.DB instance at 0x000000002E38D048>
2019-02-06 11:20:03 - run.py - <module> - INFO - *********Started executing DB
2019-02-06 11:20:03 - run.py - <module> - INFO - *********Finished executing DB
2019-02-06 11:20:03 - run.py - <module> - INFO - execute module: <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x0000000028991470>
2019-02-06 11:20:03 - run.py - <module> - INFO - *********Started executing AddAuthorConnectionClaimId
2019-02-06 11:20:03 - run.py - <module> - INFO - *********Finished executing AddAuthorConnectionClaimId
2019-02-06 11:20:03 - run.py - <module> - INFO - execute module: <newsapi_crawler.newsapi_crawler.NewsAPI_Crawler object at 0x000000002E38AD30>
2019-02-06 11:20:03 - run.py - <module> - INFO - *********Started executing NewsAPI_Crawler
2019-02-06 11:20:03 - method_executor.py - execute - INFO - execute started for get_most_popular_posts_by_google_trends started at 1549444803.38
2019-02-06 11:20:03 - method_executor.py - execute - INFO - get_most_popular_posts_by_google_trends execute window_start 2000-06-07 00:00:00
2019-02-06 11:20:07 - schema_definition.py - addPosts - INFO - total Posts inserted to DB: 0
2019-02-06 11:20:07 - method_executor.py - execute - ERROR - Failed in the new crawling process!
2019-02-06 11:20:07 - method_executor.py - execute - INFO - execute ended at 1549444807.32
2019-02-06 11:20:07 - run.py - <module> - INFO - *********Finished executing NewsAPI_Crawler
2019-02-06 11:23:00 - run.py - <module> - INFO - Start Execution ... 
2019-02-06 11:23:00 - run.py - <module> - INFO - SETUP global variables
2019-02-06 11:23:00 - run.py - <module> - INFO - CREATE pipeline
2019-02-06 11:23:00 - run.py - <module> - INFO - SETUP pipeline
2019-02-06 11:23:00 - run.py - <module> - INFO - setup module: <DB.schema_definition.DB instance at 0x000000002D993308>
2019-02-06 11:23:00 - run.py - <module> - INFO - setup module: <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x0000000027F01470>
2019-02-06 11:23:00 - run.py - <module> - INFO - setup module: <newsapi_crawler.newsapi_crawler.NewsAPI_Crawler object at 0x000000002D980D30>
2019-02-06 11:23:00 - run.py - <module> - INFO - checking module definition
2019-02-06 11:23:00 - run.py - <module> - INFO - module <DB.schema_definition.DB instance at 0x000000002D993308> is well defined
2019-02-06 11:23:00 - run.py - <module> - INFO - module <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x0000000027F01470> is well defined
2019-02-06 11:23:00 - run.py - <module> - INFO - module <newsapi_crawler.newsapi_crawler.NewsAPI_Crawler object at 0x000000002D980D30> is well defined
2019-02-06 11:23:00 - run.py - <module> - INFO - execute module: <DB.schema_definition.DB instance at 0x000000002D993308>
2019-02-06 11:23:00 - run.py - <module> - INFO - *********Started executing DB
2019-02-06 11:23:00 - run.py - <module> - INFO - *********Finished executing DB
2019-02-06 11:23:00 - run.py - <module> - INFO - execute module: <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x0000000027F01470>
2019-02-06 11:23:00 - run.py - <module> - INFO - *********Started executing AddAuthorConnectionClaimId
2019-02-06 11:23:00 - run.py - <module> - INFO - *********Finished executing AddAuthorConnectionClaimId
2019-02-06 11:23:00 - run.py - <module> - INFO - execute module: <newsapi_crawler.newsapi_crawler.NewsAPI_Crawler object at 0x000000002D980D30>
2019-02-06 11:23:00 - run.py - <module> - INFO - *********Started executing NewsAPI_Crawler
2019-02-06 11:23:00 - method_executor.py - execute - INFO - execute started for get_most_popular_posts_by_google_trends started at 1549444980.7
2019-02-06 11:23:00 - method_executor.py - execute - INFO - get_most_popular_posts_by_google_trends execute window_start 2000-06-07 00:00:00
2019-02-06 11:23:08 - method_executor.py - execute - ERROR - Failed in the new crawling process!
2019-02-06 11:23:08 - method_executor.py - execute - INFO - execute ended at 1549444988.73
2019-02-06 11:23:08 - run.py - <module> - INFO - *********Finished executing NewsAPI_Crawler
2019-02-06 11:31:04 - run.py - <module> - INFO - Start Execution ... 
2019-02-06 11:31:04 - run.py - <module> - INFO - SETUP global variables
2019-02-06 11:31:04 - run.py - <module> - INFO - CREATE pipeline
2019-02-06 11:31:04 - run.py - <module> - INFO - SETUP pipeline
2019-02-06 11:31:04 - run.py - <module> - INFO - setup module: <DB.schema_definition.DB instance at 0x000000002D6C3348>
2019-02-06 11:31:04 - run.py - <module> - INFO - setup module: <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x0000000027C91390>
2019-02-06 11:31:04 - run.py - <module> - INFO - setup module: <newsapi_crawler.newsapi_crawler.NewsAPI_Crawler object at 0x000000002D6BBC18>
2019-02-06 11:31:04 - run.py - <module> - INFO - checking module definition
2019-02-06 11:31:04 - run.py - <module> - INFO - module <DB.schema_definition.DB instance at 0x000000002D6C3348> is well defined
2019-02-06 11:31:04 - run.py - <module> - INFO - module <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x0000000027C91390> is well defined
2019-02-06 11:31:04 - run.py - <module> - INFO - module <newsapi_crawler.newsapi_crawler.NewsAPI_Crawler object at 0x000000002D6BBC18> is well defined
2019-02-06 11:31:04 - run.py - <module> - INFO - execute module: <DB.schema_definition.DB instance at 0x000000002D6C3348>
2019-02-06 11:31:04 - run.py - <module> - INFO - *********Started executing DB
2019-02-06 11:31:04 - run.py - <module> - INFO - *********Finished executing DB
2019-02-06 11:31:04 - run.py - <module> - INFO - execute module: <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x0000000027C91390>
2019-02-06 11:31:04 - run.py - <module> - INFO - *********Started executing AddAuthorConnectionClaimId
2019-02-06 11:31:04 - run.py - <module> - INFO - *********Finished executing AddAuthorConnectionClaimId
2019-02-06 11:31:04 - run.py - <module> - INFO - execute module: <newsapi_crawler.newsapi_crawler.NewsAPI_Crawler object at 0x000000002D6BBC18>
2019-02-06 11:31:04 - run.py - <module> - INFO - *********Started executing NewsAPI_Crawler
2019-02-06 11:31:04 - method_executor.py - execute - INFO - execute started for get_most_popular_posts_by_google_trends started at 1549445464.76
2019-02-06 11:31:04 - method_executor.py - execute - INFO - get_most_popular_posts_by_google_trends execute window_start 2000-06-07 00:00:00
2019-02-06 11:31:12 - method_executor.py - execute - ERROR - Failed in the new crawling process!
2019-02-06 11:31:12 - method_executor.py - execute - INFO - execute ended at 1549445472.59
2019-02-06 11:31:12 - run.py - <module> - INFO - *********Finished executing NewsAPI_Crawler
2019-02-06 11:38:37 - run.py - <module> - INFO - Start Execution ... 
2019-02-06 11:38:37 - run.py - <module> - INFO - SETUP global variables
2019-02-06 11:38:37 - run.py - <module> - INFO - CREATE pipeline
2019-02-06 11:38:37 - run.py - <module> - INFO - SETUP pipeline
2019-02-06 11:38:37 - run.py - <module> - INFO - setup module: <DB.schema_definition.DB instance at 0x000000002E26E488>
2019-02-06 11:38:37 - run.py - <module> - INFO - setup module: <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x00000000287E1390>
2019-02-06 11:38:37 - run.py - <module> - INFO - setup module: <newsapi_crawler.newsapi_crawler.NewsAPI_Crawler object at 0x000000002E26BC50>
2019-02-06 11:38:37 - run.py - <module> - INFO - checking module definition
2019-02-06 11:38:37 - run.py - <module> - INFO - module <DB.schema_definition.DB instance at 0x000000002E26E488> is well defined
2019-02-06 11:38:37 - run.py - <module> - INFO - module <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x00000000287E1390> is well defined
2019-02-06 11:38:37 - run.py - <module> - INFO - module <newsapi_crawler.newsapi_crawler.NewsAPI_Crawler object at 0x000000002E26BC50> is well defined
2019-02-06 11:38:37 - run.py - <module> - INFO - execute module: <DB.schema_definition.DB instance at 0x000000002E26E488>
2019-02-06 11:38:37 - run.py - <module> - INFO - *********Started executing DB
2019-02-06 11:38:37 - run.py - <module> - INFO - *********Finished executing DB
2019-02-06 11:38:37 - run.py - <module> - INFO - execute module: <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x00000000287E1390>
2019-02-06 11:38:37 - run.py - <module> - INFO - *********Started executing AddAuthorConnectionClaimId
2019-02-06 11:38:37 - run.py - <module> - INFO - *********Finished executing AddAuthorConnectionClaimId
2019-02-06 11:38:37 - run.py - <module> - INFO - execute module: <newsapi_crawler.newsapi_crawler.NewsAPI_Crawler object at 0x000000002E26BC50>
2019-02-06 11:38:37 - run.py - <module> - INFO - *********Started executing NewsAPI_Crawler
2019-02-06 11:38:37 - method_executor.py - execute - INFO - execute started for get_most_popular_posts_by_google_trends started at 1549445917.69
2019-02-06 11:38:37 - method_executor.py - execute - INFO - get_most_popular_posts_by_google_trends execute window_start 2000-06-07 00:00:00
2019-02-06 11:38:44 - method_executor.py - execute - ERROR - Failed in the new crawling process!
2019-02-06 11:38:44 - method_executor.py - execute - INFO - execute ended at 1549445924.15
2019-02-06 11:38:44 - run.py - <module> - INFO - *********Finished executing NewsAPI_Crawler
2019-02-06 11:43:39 - run.py - <module> - INFO - Start Execution ... 
2019-02-06 11:43:39 - run.py - <module> - INFO - SETUP global variables
2019-02-06 11:43:39 - run.py - <module> - INFO - CREATE pipeline
2019-02-06 11:43:39 - run.py - <module> - INFO - SETUP pipeline
2019-02-06 11:43:39 - run.py - <module> - INFO - setup module: <DB.schema_definition.DB instance at 0x000000002E2FF488>
2019-02-06 11:43:39 - run.py - <module> - INFO - setup module: <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x0000000028A21390>
2019-02-06 11:43:39 - run.py - <module> - INFO - setup module: <newsapi_crawler.newsapi_crawler.NewsAPI_Crawler object at 0x000000002E2FCC50>
2019-02-06 11:43:39 - run.py - <module> - INFO - checking module definition
2019-02-06 11:43:39 - run.py - <module> - INFO - module <DB.schema_definition.DB instance at 0x000000002E2FF488> is well defined
2019-02-06 11:43:39 - run.py - <module> - INFO - module <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x0000000028A21390> is well defined
2019-02-06 11:43:39 - run.py - <module> - INFO - module <newsapi_crawler.newsapi_crawler.NewsAPI_Crawler object at 0x000000002E2FCC50> is well defined
2019-02-06 11:43:39 - run.py - <module> - INFO - execute module: <DB.schema_definition.DB instance at 0x000000002E2FF488>
2019-02-06 11:43:39 - run.py - <module> - INFO - *********Started executing DB
2019-02-06 11:43:39 - run.py - <module> - INFO - *********Finished executing DB
2019-02-06 11:43:39 - run.py - <module> - INFO - execute module: <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x0000000028A21390>
2019-02-06 11:43:39 - run.py - <module> - INFO - *********Started executing AddAuthorConnectionClaimId
2019-02-06 11:43:39 - run.py - <module> - INFO - *********Finished executing AddAuthorConnectionClaimId
2019-02-06 11:43:39 - run.py - <module> - INFO - execute module: <newsapi_crawler.newsapi_crawler.NewsAPI_Crawler object at 0x000000002E2FCC50>
2019-02-06 11:43:39 - run.py - <module> - INFO - *********Started executing NewsAPI_Crawler
2019-02-06 11:43:39 - method_executor.py - execute - INFO - execute started for get_most_popular_posts_by_google_trends started at 1549446219.06
2019-02-06 11:43:39 - method_executor.py - execute - INFO - get_most_popular_posts_by_google_trends execute window_start 2000-06-07 00:00:00
2019-02-06 11:43:47 - schema_definition.py - addPosts - INFO - total Posts inserted to DB: 662
2019-02-06 11:43:47 - method_executor.py - execute - ERROR - Failed in the new crawling process!
2019-02-06 11:43:47 - method_executor.py - execute - INFO - execute ended at 1549446227.6
2019-02-06 11:43:47 - run.py - <module> - INFO - *********Finished executing NewsAPI_Crawler
2019-02-06 11:49:52 - run.py - <module> - INFO - Start Execution ... 
2019-02-06 11:49:52 - run.py - <module> - INFO - SETUP global variables
2019-02-06 11:49:52 - run.py - <module> - INFO - CREATE pipeline
2019-02-06 11:49:52 - run.py - <module> - INFO - SETUP pipeline
2019-02-06 11:49:52 - run.py - <module> - INFO - setup module: <DB.schema_definition.DB instance at 0x000000002DE47488>
2019-02-06 11:49:52 - run.py - <module> - INFO - setup module: <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x000000002842D390>
2019-02-06 11:49:52 - run.py - <module> - INFO - setup module: <newsapi_crawler.newsapi_crawler.NewsAPI_Crawler object at 0x000000002DE44C50>
2019-02-06 11:49:52 - run.py - <module> - INFO - checking module definition
2019-02-06 11:49:52 - run.py - <module> - INFO - module <DB.schema_definition.DB instance at 0x000000002DE47488> is well defined
2019-02-06 11:49:52 - run.py - <module> - INFO - module <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x000000002842D390> is well defined
2019-02-06 11:49:52 - run.py - <module> - INFO - module <newsapi_crawler.newsapi_crawler.NewsAPI_Crawler object at 0x000000002DE44C50> is well defined
2019-02-06 11:49:52 - run.py - <module> - INFO - execute module: <DB.schema_definition.DB instance at 0x000000002DE47488>
2019-02-06 11:49:52 - run.py - <module> - INFO - *********Started executing DB
2019-02-06 11:49:52 - run.py - <module> - INFO - *********Finished executing DB
2019-02-06 11:49:52 - run.py - <module> - INFO - execute module: <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x000000002842D390>
2019-02-06 11:49:52 - run.py - <module> - INFO - *********Started executing AddAuthorConnectionClaimId
2019-02-06 11:49:52 - run.py - <module> - INFO - *********Finished executing AddAuthorConnectionClaimId
2019-02-06 11:49:52 - run.py - <module> - INFO - execute module: <newsapi_crawler.newsapi_crawler.NewsAPI_Crawler object at 0x000000002DE44C50>
2019-02-06 11:49:52 - run.py - <module> - INFO - *********Started executing NewsAPI_Crawler
2019-02-06 11:49:52 - method_executor.py - execute - INFO - execute started for get_most_popular_posts_by_google_trends started at 1549446592.28
2019-02-06 11:49:52 - method_executor.py - execute - INFO - get_most_popular_posts_by_google_trends execute window_start 2000-06-07 00:00:00
2019-02-06 11:49:58 - method_executor.py - execute - ERROR - Failed in the new crawling process!
2019-02-06 11:49:58 - method_executor.py - execute - INFO - execute ended at 1549446598.54
2019-02-06 11:49:58 - run.py - <module> - INFO - *********Finished executing NewsAPI_Crawler
2019-02-06 11:55:30 - run.py - <module> - INFO - Start Execution ... 
2019-02-06 11:55:30 - run.py - <module> - INFO - SETUP global variables
2019-02-06 11:55:30 - run.py - <module> - INFO - CREATE pipeline
2019-02-06 11:55:30 - run.py - <module> - INFO - SETUP pipeline
2019-02-06 11:55:30 - run.py - <module> - INFO - setup module: <DB.schema_definition.DB instance at 0x000000002DD22488>
2019-02-06 11:55:30 - run.py - <module> - INFO - setup module: <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x0000000028393390>
2019-02-06 11:55:30 - run.py - <module> - INFO - setup module: <newsapi_crawler.newsapi_crawler.NewsAPI_Crawler object at 0x000000002DD1FC50>
2019-02-06 11:55:30 - run.py - <module> - INFO - checking module definition
2019-02-06 11:55:30 - run.py - <module> - INFO - module <DB.schema_definition.DB instance at 0x000000002DD22488> is well defined
2019-02-06 11:55:30 - run.py - <module> - INFO - module <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x0000000028393390> is well defined
2019-02-06 11:55:30 - run.py - <module> - INFO - module <newsapi_crawler.newsapi_crawler.NewsAPI_Crawler object at 0x000000002DD1FC50> is well defined
2019-02-06 11:55:30 - run.py - <module> - INFO - execute module: <DB.schema_definition.DB instance at 0x000000002DD22488>
2019-02-06 11:55:30 - run.py - <module> - INFO - *********Started executing DB
2019-02-06 11:55:30 - run.py - <module> - INFO - *********Finished executing DB
2019-02-06 11:55:30 - run.py - <module> - INFO - execute module: <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x0000000028393390>
2019-02-06 11:55:30 - run.py - <module> - INFO - *********Started executing AddAuthorConnectionClaimId
2019-02-06 11:55:30 - run.py - <module> - INFO - *********Finished executing AddAuthorConnectionClaimId
2019-02-06 11:55:30 - run.py - <module> - INFO - execute module: <newsapi_crawler.newsapi_crawler.NewsAPI_Crawler object at 0x000000002DD1FC50>
2019-02-06 11:55:30 - run.py - <module> - INFO - *********Started executing NewsAPI_Crawler
2019-02-06 11:55:30 - method_executor.py - execute - INFO - execute started for get_most_popular_posts_by_google_trends started at 1549446930.26
2019-02-06 11:55:30 - method_executor.py - execute - INFO - get_most_popular_posts_by_google_trends execute window_start 2000-06-07 00:00:00
2019-02-06 11:55:38 - schema_definition.py - addPosts - INFO - total Posts inserted to DB: 662
2019-02-06 11:55:40 - method_executor.py - execute - ERROR - Failed in the new crawling process!
2019-02-06 11:55:40 - method_executor.py - execute - INFO - execute ended at 1549446940.6
2019-02-06 11:55:40 - run.py - <module> - INFO - *********Finished executing NewsAPI_Crawler
2019-02-06 12:03:25 - run.py - <module> - INFO - Start Execution ... 
2019-02-06 12:03:25 - run.py - <module> - INFO - SETUP global variables
2019-02-06 12:03:25 - run.py - <module> - INFO - CREATE pipeline
2019-02-06 12:03:25 - run.py - <module> - INFO - SETUP pipeline
2019-02-06 12:03:25 - run.py - <module> - INFO - setup module: <DB.schema_definition.DB instance at 0x000000002DEF6508>
2019-02-06 12:03:25 - run.py - <module> - INFO - setup module: <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x0000000028523390>
2019-02-06 12:03:25 - run.py - <module> - INFO - setup module: <newsapi_crawler.newsapi_crawler.NewsAPI_Crawler object at 0x000000002DEF4A58>
2019-02-06 12:03:25 - run.py - <module> - INFO - checking module definition
2019-02-06 12:03:25 - run.py - <module> - INFO - module <DB.schema_definition.DB instance at 0x000000002DEF6508> is well defined
2019-02-06 12:03:25 - run.py - <module> - INFO - module <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x0000000028523390> is well defined
2019-02-06 12:03:25 - run.py - <module> - INFO - module <newsapi_crawler.newsapi_crawler.NewsAPI_Crawler object at 0x000000002DEF4A58> is well defined
2019-02-06 12:03:25 - run.py - <module> - INFO - execute module: <DB.schema_definition.DB instance at 0x000000002DEF6508>
2019-02-06 12:03:25 - run.py - <module> - INFO - *********Started executing DB
2019-02-06 12:03:25 - run.py - <module> - INFO - *********Finished executing DB
2019-02-06 12:03:25 - run.py - <module> - INFO - execute module: <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x0000000028523390>
2019-02-06 12:03:25 - run.py - <module> - INFO - *********Started executing AddAuthorConnectionClaimId
2019-02-06 12:03:25 - run.py - <module> - INFO - *********Finished executing AddAuthorConnectionClaimId
2019-02-06 12:03:25 - run.py - <module> - INFO - execute module: <newsapi_crawler.newsapi_crawler.NewsAPI_Crawler object at 0x000000002DEF4A58>
2019-02-06 12:03:25 - run.py - <module> - INFO - *********Started executing NewsAPI_Crawler
2019-02-06 12:03:25 - method_executor.py - execute - INFO - execute started for get_most_popular_posts_by_google_trends started at 1549447405.35
2019-02-06 12:03:25 - method_executor.py - execute - INFO - get_most_popular_posts_by_google_trends execute window_start 2000-06-07 00:00:00
2019-02-06 12:03:33 - schema_definition.py - addPosts - INFO - total Posts inserted to DB: 662
2019-02-06 12:03:36 - method_executor.py - execute - ERROR - Failed in the new crawling process!
2019-02-06 12:03:36 - method_executor.py - execute - INFO - execute ended at 1549447416.05
2019-02-06 12:03:36 - run.py - <module> - INFO - *********Finished executing NewsAPI_Crawler
2019-02-06 12:05:44 - run.py - <module> - INFO - Start Execution ... 
2019-02-06 12:05:44 - run.py - <module> - INFO - SETUP global variables
2019-02-06 12:05:44 - run.py - <module> - INFO - CREATE pipeline
2019-02-06 12:05:44 - run.py - <module> - INFO - SETUP pipeline
2019-02-06 12:05:44 - run.py - <module> - INFO - setup module: <DB.schema_definition.DB instance at 0x000000002DC9FE48>
2019-02-06 12:05:44 - run.py - <module> - INFO - setup module: <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x00000000281B6BA8>
2019-02-06 12:05:44 - run.py - <module> - INFO - setup module: <newsapi_crawler.newsapi_crawler.NewsAPI_Crawler object at 0x000000002DC96E80>
2019-02-06 12:05:44 - run.py - <module> - INFO - checking module definition
2019-02-06 12:05:44 - run.py - <module> - INFO - module <DB.schema_definition.DB instance at 0x000000002DC9FE48> is well defined
2019-02-06 12:05:44 - run.py - <module> - INFO - module <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x00000000281B6BA8> is well defined
2019-02-06 12:05:44 - run.py - <module> - INFO - module <newsapi_crawler.newsapi_crawler.NewsAPI_Crawler object at 0x000000002DC96E80> is well defined
2019-02-06 12:05:44 - run.py - <module> - INFO - execute module: <DB.schema_definition.DB instance at 0x000000002DC9FE48>
2019-02-06 12:05:44 - run.py - <module> - INFO - *********Started executing DB
2019-02-06 12:05:44 - run.py - <module> - INFO - *********Finished executing DB
2019-02-06 12:05:44 - run.py - <module> - INFO - execute module: <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x00000000281B6BA8>
2019-02-06 12:05:44 - run.py - <module> - INFO - *********Started executing AddAuthorConnectionClaimId
2019-02-06 12:05:44 - run.py - <module> - INFO - *********Finished executing AddAuthorConnectionClaimId
2019-02-06 12:05:44 - run.py - <module> - INFO - execute module: <newsapi_crawler.newsapi_crawler.NewsAPI_Crawler object at 0x000000002DC96E80>
2019-02-06 12:05:44 - run.py - <module> - INFO - *********Started executing NewsAPI_Crawler
2019-02-06 12:05:44 - method_executor.py - execute - INFO - execute started for get_most_popular_posts_by_google_trends started at 1549447544.81
2019-02-06 12:05:44 - method_executor.py - execute - INFO - get_most_popular_posts_by_google_trends execute window_start 2000-06-07 00:00:00
2019-02-06 12:05:52 - schema_definition.py - addPosts - INFO - total Posts inserted to DB: 662
2019-02-06 12:05:54 - schema_definition.py - addArticles - INFO - total Articles inserted to DB: 662
2019-02-06 12:05:54 - method_executor.py - execute - ERROR - Failed in the new crawling process!
2019-02-06 12:05:54 - method_executor.py - execute - INFO - execute ended at 1549447554.77
2019-02-06 12:05:54 - run.py - <module> - INFO - *********Finished executing NewsAPI_Crawler
2019-02-06 12:12:52 - run.py - <module> - INFO - Start Execution ... 
2019-02-06 12:12:52 - run.py - <module> - INFO - SETUP global variables
2019-02-06 12:12:52 - run.py - <module> - INFO - CREATE pipeline
2019-02-06 12:12:52 - run.py - <module> - INFO - SETUP pipeline
2019-02-06 12:12:52 - run.py - <module> - INFO - setup module: <DB.schema_definition.DB instance at 0x000000002DF69E48>
2019-02-06 12:12:52 - run.py - <module> - INFO - setup module: <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x0000000028458BA8>
2019-02-06 12:12:52 - run.py - <module> - INFO - setup module: <newsapi_crawler.newsapi_crawler.NewsAPI_Crawler object at 0x000000002DF60E80>
2019-02-06 12:12:52 - run.py - <module> - INFO - checking module definition
2019-02-06 12:12:52 - run.py - <module> - INFO - module <DB.schema_definition.DB instance at 0x000000002DF69E48> is well defined
2019-02-06 12:12:52 - run.py - <module> - INFO - module <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x0000000028458BA8> is well defined
2019-02-06 12:12:52 - run.py - <module> - INFO - module <newsapi_crawler.newsapi_crawler.NewsAPI_Crawler object at 0x000000002DF60E80> is well defined
2019-02-06 12:12:52 - run.py - <module> - INFO - execute module: <DB.schema_definition.DB instance at 0x000000002DF69E48>
2019-02-06 12:12:52 - run.py - <module> - INFO - *********Started executing DB
2019-02-06 12:12:52 - run.py - <module> - INFO - *********Finished executing DB
2019-02-06 12:12:52 - run.py - <module> - INFO - execute module: <missing_data_complementor.add_author_connection_claim_id.AddAuthorConnectionClaimId object at 0x0000000028458BA8>
2019-02-06 12:12:52 - run.py - <module> - INFO - *********Started executing AddAuthorConnectionClaimId
2019-02-06 12:12:52 - run.py - <module> - INFO - *********Finished executing AddAuthorConnectionClaimId
2019-02-06 12:12:52 - run.py - <module> - INFO - execute module: <newsapi_crawler.newsapi_crawler.NewsAPI_Crawler object at 0x000000002DF60E80>
2019-02-06 12:12:52 - run.py - <module> - INFO - *********Started executing NewsAPI_Crawler
2019-02-06 12:12:52 - method_executor.py - execute - INFO - execute started for get_most_popular_posts_by_google_trends started at 1549447972.64
2019-02-06 12:12:52 - method_executor.py - execute - INFO - get_most_popular_posts_by_google_trends execute window_start 2000-06-07 00:00:00
2019-02-06 12:13:01 - schema_definition.py - addPosts - INFO - total Posts inserted to DB: 662
2019-02-06 12:13:03 - schema_definition.py - addArticles - INFO - total Articles inserted to DB: 662
2019-02-06 12:13:04 - schema_definition.py - addArticleItems - INFO - total Article Items inserted to DB: 662
2019-02-06 12:13:11 - schema_definition.py - addPosts - INFO - total Posts inserted to DB: 662
2019-02-06 12:13:13 - schema_definition.py - addArticles - INFO - total Articles inserted to DB: 662
2019-02-06 12:13:14 - schema_definition.py - addArticleItems - INFO - total Article Items inserted to DB: 662
2019-02-06 12:13:21 - schema_definition.py - addPosts - INFO - total Posts inserted to DB: 662
2019-02-06 12:13:23 - schema_definition.py - addArticles - INFO - total Articles inserted to DB: 662
2019-02-06 12:13:24 - schema_definition.py - addArticleItems - INFO - total Article Items inserted to DB: 662
2019-02-06 12:13:31 - schema_definition.py - addPosts - INFO - total Posts inserted to DB: 662
2019-02-06 12:13:33 - schema_definition.py - addArticles - INFO - total Articles inserted to DB: 662
2019-02-06 12:13:34 - schema_definition.py - addArticleItems - INFO - total Article Items inserted to DB: 662
2019-02-06 12:13:41 - schema_definition.py - addPosts - INFO - total Posts inserted to DB: 662
2019-02-06 12:13:43 - schema_definition.py - addArticles - INFO - total Articles inserted to DB: 662
2019-02-06 12:13:44 - schema_definition.py - addArticleItems - INFO - total Article Items inserted to DB: 662
2019-02-06 12:13:51 - schema_definition.py - addPosts - INFO - total Posts inserted to DB: 662
2019-02-06 12:13:53 - schema_definition.py - addArticles - INFO - total Articles inserted to DB: 662
2019-02-06 12:13:54 - schema_definition.py - addArticleItems - INFO - total Article Items inserted to DB: 662
2019-02-06 12:14:01 - schema_definition.py - addPosts - INFO - total Posts inserted to DB: 662
2019-02-06 12:14:03 - schema_definition.py - addArticles - INFO - total Articles inserted to DB: 662
2019-02-06 12:14:04 - schema_definition.py - addArticleItems - INFO - total Article Items inserted to DB: 662
2019-02-06 12:14:11 - schema_definition.py - addPosts - INFO - total Posts inserted to DB: 662
2019-02-06 12:14:13 - schema_definition.py - addArticles - INFO - total Articles inserted to DB: 662
2019-02-06 12:14:14 - schema_definition.py - addArticleItems - INFO - total Article Items inserted to DB: 662
2019-02-06 12:14:21 - schema_definition.py - addPosts - INFO - total Posts inserted to DB: 662
2019-02-06 12:14:23 - schema_definition.py - addArticles - INFO - total Articles inserted to DB: 662
2019-02-06 12:14:24 - schema_definition.py - addArticleItems - INFO - total Article Items inserted to DB: 662
2019-02-06 12:14:31 - schema_definition.py - addPosts - INFO - total Posts inserted to DB: 662
2019-02-06 12:14:34 - schema_definition.py - addArticles - INFO - total Articles inserted to DB: 662
2019-02-06 12:14:34 - schema_definition.py - addArticleItems - INFO - total Article Items inserted to DB: 662
2019-02-06 12:14:41 - schema_definition.py - addPosts - INFO - total Posts inserted to DB: 662
2019-02-06 12:14:43 - schema_definition.py - addArticles - INFO - total Articles inserted to DB: 662
2019-02-06 12:14:44 - schema_definition.py - addArticleItems - INFO - total Article Items inserted to DB: 662
2019-02-06 12:14:51 - schema_definition.py - addPosts - INFO - total Posts inserted to DB: 662
2019-02-06 12:14:53 - schema_definition.py - addArticles - INFO - total Articles inserted to DB: 662
2019-02-06 12:14:54 - schema_definition.py - addArticleItems - INFO - total Article Items inserted to DB: 662
2019-02-06 12:15:01 - schema_definition.py - addPosts - INFO - total Posts inserted to DB: 662
2019-02-06 12:15:03 - schema_definition.py - addArticles - INFO - total Articles inserted to DB: 662
2019-02-06 12:15:04 - schema_definition.py - addArticleItems - INFO - total Article Items inserted to DB: 662
2019-02-06 12:15:11 - schema_definition.py - addPosts - INFO - total Posts inserted to DB: 662
2019-02-06 12:15:13 - schema_definition.py - addArticles - INFO - total Articles inserted to DB: 662
2019-02-06 12:15:14 - schema_definition.py - addArticleItems - INFO - total Article Items inserted to DB: 662
2019-02-06 12:15:21 - schema_definition.py - addPosts - INFO - total Posts inserted to DB: 662
2019-02-06 12:15:23 - schema_definition.py - addArticles - INFO - total Articles inserted to DB: 662
2019-02-06 12:15:24 - schema_definition.py - addArticleItems - INFO - total Article Items inserted to DB: 662
2019-02-06 12:15:31 - schema_definition.py - addPosts - INFO - total Posts inserted to DB: 662
2019-02-06 12:15:33 - schema_definition.py - addArticles - INFO - total Articles inserted to DB: 662
2019-02-06 12:15:34 - schema_definition.py - addArticleItems - INFO - total Article Items inserted to DB: 662
2019-02-06 12:15:41 - schema_definition.py - addPosts - INFO - total Posts inserted to DB: 662
2019-02-06 12:15:43 - schema_definition.py - addArticles - INFO - total Articles inserted to DB: 662
2019-02-06 12:15:44 - schema_definition.py - addArticleItems - INFO - total Article Items inserted to DB: 662
2019-02-06 12:15:51 - schema_definition.py - addPosts - INFO - total Posts inserted to DB: 662
2019-02-06 12:15:53 - schema_definition.py - addArticles - INFO - total Articles inserted to DB: 662
2019-02-06 12:15:54 - schema_definition.py - addArticleItems - INFO - total Article Items inserted to DB: 662
2019-02-06 12:16:01 - schema_definition.py - addPosts - INFO - total Posts inserted to DB: 662
2019-02-06 12:16:03 - schema_definition.py - addArticles - INFO - total Articles inserted to DB: 662
2019-02-06 12:16:04 - schema_definition.py - addArticleItems - INFO - total Article Items inserted to DB: 662
2019-02-06 12:16:11 - schema_definition.py - addPosts - INFO - total Posts inserted to DB: 662
2019-02-06 12:16:13 - schema_definition.py - addArticles - INFO - total Articles inserted to DB: 662
2019-02-06 12:16:14 - schema_definition.py - addArticleItems - INFO - total Article Items inserted to DB: 662
2019-02-06 12:16:21 - schema_definition.py - addPosts - INFO - total Posts inserted to DB: 662
2019-02-06 12:16:23 - schema_definition.py - addArticles - INFO - total Articles inserted to DB: 662
2019-02-06 12:16:24 - schema_definition.py - addArticleItems - INFO - total Article Items inserted to DB: 662
2019-02-06 12:16:31 - schema_definition.py - addPosts - INFO - total Posts inserted to DB: 662
2019-02-06 12:16:33 - schema_definition.py - addArticles - INFO - total Articles inserted to DB: 662
2019-02-06 12:16:34 - schema_definition.py - addArticleItems - INFO - total Article Items inserted to DB: 662
2019-02-06 12:16:41 - schema_definition.py - addPosts - INFO - total Posts inserted to DB: 662
2019-02-06 12:16:43 - schema_definition.py - addArticles - INFO - total Articles inserted to DB: 662
2019-02-06 12:16:43 - schema_definition.py - addArticleItems - INFO - total Article Items inserted to DB: 662
2019-02-06 12:16:50 - schema_definition.py - addPosts - INFO - total Posts inserted to DB: 662
2019-02-06 12:16:52 - schema_definition.py - addArticles - INFO - total Articles inserted to DB: 662
2019-02-06 12:16:53 - schema_definition.py - addArticleItems - INFO - total Article Items inserted to DB: 662
2019-02-06 12:17:00 - schema_definition.py - addPosts - INFO - total Posts inserted to DB: 662
2019-02-06 12:17:02 - schema_definition.py - addArticles - INFO - total Articles inserted to DB: 662
2019-02-06 12:17:03 - schema_definition.py - addArticleItems - INFO - total Article Items inserted to DB: 662
2019-02-06 12:17:10 - schema_definition.py - addPosts - INFO - total Posts inserted to DB: 662
2019-02-06 12:17:12 - schema_definition.py - addArticles - INFO - total Articles inserted to DB: 662
2019-02-06 12:17:13 - schema_definition.py - addArticleItems - INFO - total Article Items inserted to DB: 662
2019-02-06 12:17:20 - schema_definition.py - addPosts - INFO - total Posts inserted to DB: 662
2019-02-06 12:17:22 - schema_definition.py - addArticles - INFO - total Articles inserted to DB: 662
2019-02-06 12:17:23 - schema_definition.py - addArticleItems - INFO - total Article Items inserted to DB: 662
2019-02-06 12:17:30 - schema_definition.py - addPosts - INFO - total Posts inserted to DB: 662
2019-02-06 12:17:32 - schema_definition.py - addArticles - INFO - total Articles inserted to DB: 662
2019-02-06 12:17:32 - schema_definition.py - addArticleItems - INFO - total Article Items inserted to DB: 662
2019-02-06 12:17:39 - schema_definition.py - addPosts - INFO - total Posts inserted to DB: 662
2019-02-06 12:17:42 - schema_definition.py - addArticles - INFO - total Articles inserted to DB: 662
2019-02-06 12:17:42 - schema_definition.py - addArticleItems - INFO - total Article Items inserted to DB: 662
2019-02-06 12:17:49 - schema_definition.py - addPosts - INFO - total Posts inserted to DB: 662
2019-02-06 12:17:52 - schema_definition.py - addArticles - INFO - total Articles inserted to DB: 662
2019-02-06 12:17:52 - schema_definition.py - addArticleItems - INFO - total Article Items inserted to DB: 662
2019-02-06 12:17:59 - schema_definition.py - addPosts - INFO - total Posts inserted to DB: 662
2019-02-06 12:18:01 - schema_definition.py - addArticles - INFO - total Articles inserted to DB: 662
2019-02-06 12:18:02 - schema_definition.py - addArticleItems - INFO - total Article Items inserted to DB: 662
2019-02-06 12:18:10 - schema_definition.py - addPosts - INFO - total Posts inserted to DB: 663
2019-02-06 12:18:12 - schema_definition.py - addArticles - INFO - total Articles inserted to DB: 663
2019-02-06 12:18:13 - schema_definition.py - addArticleItems - INFO - total Article Items inserted to DB: 663
2019-02-06 12:18:20 - schema_definition.py - addPosts - INFO - total Posts inserted to DB: 663
2019-02-06 12:18:22 - schema_definition.py - addArticles - INFO - total Articles inserted to DB: 663
2019-02-06 12:18:23 - schema_definition.py - addArticleItems - INFO - total Article Items inserted to DB: 663
2019-02-06 12:18:29 - schema_definition.py - addPosts - INFO - total Posts inserted to DB: 663
2019-02-06 12:18:32 - schema_definition.py - addArticles - INFO - total Articles inserted to DB: 663
2019-02-06 12:18:32 - schema_definition.py - addArticleItems - INFO - total Article Items inserted to DB: 663
2019-02-06 12:18:39 - schema_definition.py - addPosts - INFO - total Posts inserted to DB: 663
2019-02-06 12:18:41 - schema_definition.py - addArticles - INFO - total Articles inserted to DB: 663
2019-02-06 12:18:42 - schema_definition.py - addArticleItems - INFO - total Article Items inserted to DB: 663
2019-02-06 12:18:49 - schema_definition.py - addPosts - INFO - total Posts inserted to DB: 663
2019-02-06 12:18:51 - schema_definition.py - addArticles - INFO - total Articles inserted to DB: 663
2019-02-06 12:18:51 - schema_definition.py - addArticleItems - INFO - total Article Items inserted to DB: 663
2019-02-06 12:18:58 - schema_definition.py - addPosts - INFO - total Posts inserted to DB: 663
2019-02-06 12:19:00 - schema_definition.py - addArticles - INFO - total Articles inserted to DB: 663
2019-02-06 12:19:01 - schema_definition.py - addArticleItems - INFO - total Article Items inserted to DB: 663
2019-02-06 12:19:07 - schema_definition.py - addPosts - INFO - total Posts inserted to DB: 663
2019-02-06 12:19:10 - schema_definition.py - addArticles - INFO - total Articles inserted to DB: 663
2019-02-06 12:19:10 - schema_definition.py - addArticleItems - INFO - total Article Items inserted to DB: 663
2019-02-06 12:19:17 - schema_definition.py - addPosts - INFO - total Posts inserted to DB: 663
2019-02-06 12:19:19 - schema_definition.py - addArticles - INFO - total Articles inserted to DB: 663
2019-02-06 12:19:20 - schema_definition.py - addArticleItems - INFO - total Article Items inserted to DB: 663
2019-02-06 12:19:27 - schema_definition.py - addPosts - INFO - total Posts inserted to DB: 663
2019-02-06 12:19:29 - schema_definition.py - addArticles - INFO - total Articles inserted to DB: 663
2019-02-06 12:19:29 - schema_definition.py - addArticleItems - INFO - total Article Items inserted to DB: 663
2019-02-07 16:23:10 - run.py - <module> - INFO - Start Execution ... 
2019-02-07 16:23:10 - run.py - <module> - INFO - SETUP global variables
2019-02-07 16:23:10 - run.py - <module> - INFO - CREATE pipeline
2019-02-07 16:25:00 - run.py - <module> - INFO - Start Execution ... 
2019-02-07 16:25:00 - run.py - <module> - INFO - SETUP global variables
2019-02-07 16:25:00 - run.py - <module> - INFO - CREATE pipeline
2019-02-07 16:28:02 - run.py - <module> - INFO - Start Execution ... 
2019-02-07 16:28:02 - run.py - <module> - INFO - SETUP global variables
2019-02-07 16:28:02 - run.py - <module> - INFO - CREATE pipeline
2019-02-07 16:28:51 - run.py - <module> - INFO - Start Execution ... 
2019-02-07 16:28:51 - run.py - <module> - INFO - SETUP global variables
2019-02-07 16:28:51 - run.py - <module> - INFO - CREATE pipeline
2019-02-07 16:28:51 - run.py - <module> - INFO - SETUP pipeline
2019-02-07 16:28:51 - run.py - <module> - INFO - setup module: <DB.schema_definition.DB instance at 0x000000002FDFCF08>
2019-02-07 16:32:00 - run.py - <module> - INFO - Start Execution ... 
2019-02-07 16:32:00 - run.py - <module> - INFO - SETUP global variables
2019-02-07 16:32:00 - run.py - <module> - INFO - CREATE pipeline
2019-02-07 16:32:00 - run.py - <module> - INFO - SETUP pipeline
2019-02-07 16:32:00 - run.py - <module> - INFO - setup module: <DB.schema_definition.DB instance at 0x000000002FD11F08>
2019-02-07 16:33:11 - run.py - <module> - INFO - Start Execution ... 
2019-02-07 16:33:11 - run.py - <module> - INFO - SETUP global variables
2019-02-07 16:33:11 - run.py - <module> - INFO - CREATE pipeline
2019-02-07 16:33:11 - run.py - <module> - INFO - SETUP pipeline
2019-02-07 16:33:11 - run.py - <module> - INFO - setup module: <DB.schema_definition.DB instance at 0x0000000030344F08>
2019-02-07 16:33:11 - run.py - <module> - INFO - setup module: <missing_data_complementor.category_filler_for_claims.CategoryFillerForClaims object at 0x0000000029EB67B8>
2019-02-07 16:33:11 - run.py - <module> - INFO - setup module: <webcrawlers.webcrawlers.WebCrawlers object at 0x000000002FF1AD68>
2019-02-07 16:33:11 - run.py - <module> - INFO - checking module definition
2019-02-07 16:33:11 - run.py - <module> - INFO - module <DB.schema_definition.DB instance at 0x0000000030344F08> is well defined
2019-02-07 16:33:11 - run.py - <module> - INFO - module <missing_data_complementor.category_filler_for_claims.CategoryFillerForClaims object at 0x0000000029EB67B8> is well defined
2019-02-07 16:33:11 - run.py - <module> - INFO - module <webcrawlers.webcrawlers.WebCrawlers object at 0x000000002FF1AD68> is well defined
2019-02-07 16:33:11 - run.py - <module> - INFO - execute module: <DB.schema_definition.DB instance at 0x0000000030344F08>
2019-02-07 16:33:11 - run.py - <module> - INFO - *********Started executing DB
2019-02-07 16:33:11 - run.py - <module> - INFO - *********Finished executing DB
2019-02-07 16:33:11 - run.py - <module> - INFO - execute module: <missing_data_complementor.category_filler_for_claims.CategoryFillerForClaims object at 0x0000000029EB67B8>
2019-02-07 16:33:11 - run.py - <module> - INFO - *********Started executing CategoryFillerForClaims
2019-02-07 16:35:35 - run.py - <module> - INFO - Start Execution ... 
2019-02-07 16:35:35 - run.py - <module> - INFO - SETUP global variables
2019-02-07 16:35:35 - run.py - <module> - INFO - CREATE pipeline
2019-02-07 16:35:35 - run.py - <module> - INFO - SETUP pipeline
2019-02-07 16:35:35 - run.py - <module> - INFO - setup module: <DB.schema_definition.DB instance at 0x000000002F981E08>
2019-02-07 16:35:35 - run.py - <module> - INFO - setup module: <webcrawlers.webcrawlers.WebCrawlers object at 0x000000002F485CC0>
2019-02-07 16:35:35 - run.py - <module> - INFO - checking module definition
2019-02-07 16:35:35 - run.py - <module> - INFO - module <DB.schema_definition.DB instance at 0x000000002F981E08> is well defined
2019-02-07 16:35:35 - run.py - <module> - INFO - module <webcrawlers.webcrawlers.WebCrawlers object at 0x000000002F485CC0> is well defined
2019-02-07 16:35:35 - run.py - <module> - INFO - execute module: <DB.schema_definition.DB instance at 0x000000002F981E08>
2019-02-07 16:35:35 - run.py - <module> - INFO - *********Started executing DB
2019-02-07 16:35:35 - run.py - <module> - INFO - *********Finished executing DB
2019-02-07 16:35:35 - run.py - <module> - INFO - execute module: <webcrawlers.webcrawlers.WebCrawlers object at 0x000000002F485CC0>
2019-02-07 16:35:35 - run.py - <module> - INFO - *********Started executing WebCrawlers
2019-02-07 16:36:18 - telnet.py - __init__ - INFO - Telnet Password: 89eba59a3419b9cd
2019-02-07 16:36:18 - __init__.py - _load_handler - ERROR - Loading "scrapy.core.downloader.handlers.http.HTTPDownloadHandler" for scheme "http"
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\__init__.py", line 48, in _load_handler
    dhcls = load_object(path)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\http.py", line 3, in <module>
    from .http11 import HTTP11DownloadHandler as HTTPDownloadHandler
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 16, in <module>
    from twisted.web.client import Agent, ProxyAgent, ResponseDone, \
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:18 - __init__.py - _load_handler - ERROR - Loading "scrapy.core.downloader.handlers.s3.S3DownloadHandler" for scheme "s3"
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\__init__.py", line 48, in _load_handler
    dhcls = load_object(path)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\s3.py", line 6, in <module>
    from .http import HTTPDownloadHandler
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\http.py", line 3, in <module>
    from .http11 import HTTP11DownloadHandler as HTTPDownloadHandler
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 16, in <module>
    from twisted.web.client import Agent, ProxyAgent, ResponseDone, \
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:18 - __init__.py - _load_handler - ERROR - Loading "scrapy.core.downloader.handlers.http.HTTPDownloadHandler" for scheme "https"
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\__init__.py", line 48, in _load_handler
    dhcls = load_object(path)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\http.py", line 3, in <module>
    from .http11 import HTTP11DownloadHandler as HTTPDownloadHandler
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 16, in <module>
    from twisted.web.client import Agent, ProxyAgent, ResponseDone, \
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:18 - telnet.py - __init__ - INFO - Telnet Password: f882ed7de01587ca
2019-02-07 16:36:18 - __init__.py - _load_handler - ERROR - Loading "scrapy.core.downloader.handlers.http.HTTPDownloadHandler" for scheme "http"
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\__init__.py", line 48, in _load_handler
    dhcls = load_object(path)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\http.py", line 3, in <module>
    from .http11 import HTTP11DownloadHandler as HTTPDownloadHandler
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 16, in <module>
    from twisted.web.client import Agent, ProxyAgent, ResponseDone, \
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:18 - __init__.py - _load_handler - ERROR - Loading "scrapy.core.downloader.handlers.s3.S3DownloadHandler" for scheme "s3"
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\__init__.py", line 48, in _load_handler
    dhcls = load_object(path)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\s3.py", line 6, in <module>
    from .http import HTTPDownloadHandler
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\http.py", line 3, in <module>
    from .http11 import HTTP11DownloadHandler as HTTPDownloadHandler
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 16, in <module>
    from twisted.web.client import Agent, ProxyAgent, ResponseDone, \
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:18 - __init__.py - _load_handler - ERROR - Loading "scrapy.core.downloader.handlers.http.HTTPDownloadHandler" for scheme "https"
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\__init__.py", line 48, in _load_handler
    dhcls = load_object(path)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\http.py", line 3, in <module>
    from .http11 import HTTP11DownloadHandler as HTTPDownloadHandler
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 16, in <module>
    from twisted.web.client import Agent, ProxyAgent, ResponseDone, \
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:18 - telnet.py - __init__ - INFO - Telnet Password: 2bf03013c0b0ca8d
2019-02-07 16:36:18 - __init__.py - _load_handler - ERROR - Loading "scrapy.core.downloader.handlers.http.HTTPDownloadHandler" for scheme "http"
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\__init__.py", line 48, in _load_handler
    dhcls = load_object(path)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\http.py", line 3, in <module>
    from .http11 import HTTP11DownloadHandler as HTTPDownloadHandler
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 16, in <module>
    from twisted.web.client import Agent, ProxyAgent, ResponseDone, \
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:18 - __init__.py - _load_handler - ERROR - Loading "scrapy.core.downloader.handlers.s3.S3DownloadHandler" for scheme "s3"
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\__init__.py", line 48, in _load_handler
    dhcls = load_object(path)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\s3.py", line 6, in <module>
    from .http import HTTPDownloadHandler
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\http.py", line 3, in <module>
    from .http11 import HTTP11DownloadHandler as HTTPDownloadHandler
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 16, in <module>
    from twisted.web.client import Agent, ProxyAgent, ResponseDone, \
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:18 - __init__.py - _load_handler - ERROR - Loading "scrapy.core.downloader.handlers.http.HTTPDownloadHandler" for scheme "https"
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\__init__.py", line 48, in _load_handler
    dhcls = load_object(path)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\http.py", line 3, in <module>
    from .http11 import HTTP11DownloadHandler as HTTPDownloadHandler
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 16, in <module>
    from twisted.web.client import Agent, ProxyAgent, ResponseDone, \
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:18 - telnet.py - __init__ - INFO - Telnet Password: d552a35db8d984e2
2019-02-07 16:36:18 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:18 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:18 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:18 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:18 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:18 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:18 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:18 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:18 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:18 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:18 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:18 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:18 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:18 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:18 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:18 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:18 - __init__.py - _load_handler - ERROR - Loading "scrapy.core.downloader.handlers.http.HTTPDownloadHandler" for scheme "http"
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\__init__.py", line 48, in _load_handler
    dhcls = load_object(path)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\http.py", line 3, in <module>
    from .http11 import HTTP11DownloadHandler as HTTPDownloadHandler
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 16, in <module>
    from twisted.web.client import Agent, ProxyAgent, ResponseDone, \
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:18 - __init__.py - _load_handler - ERROR - Loading "scrapy.core.downloader.handlers.s3.S3DownloadHandler" for scheme "s3"
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\__init__.py", line 48, in _load_handler
    dhcls = load_object(path)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\s3.py", line 6, in <module>
    from .http import HTTPDownloadHandler
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\http.py", line 3, in <module>
    from .http11 import HTTP11DownloadHandler as HTTPDownloadHandler
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 16, in <module>
    from twisted.web.client import Agent, ProxyAgent, ResponseDone, \
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:18 - __init__.py - _load_handler - ERROR - Loading "scrapy.core.downloader.handlers.http.HTTPDownloadHandler" for scheme "https"
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\__init__.py", line 48, in _load_handler
    dhcls = load_object(path)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\http.py", line 3, in <module>
    from .http11 import HTTP11DownloadHandler as HTTPDownloadHandler
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 16, in <module>
    from twisted.web.client import Agent, ProxyAgent, ResponseDone, \
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:18 - telnet.py - __init__ - INFO - Telnet Password: 8804981f6f92776b
2019-02-07 16:36:18 - __init__.py - _load_handler - ERROR - Loading "scrapy.core.downloader.handlers.http.HTTPDownloadHandler" for scheme "http"
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\__init__.py", line 48, in _load_handler
    dhcls = load_object(path)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\http.py", line 3, in <module>
    from .http11 import HTTP11DownloadHandler as HTTPDownloadHandler
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 16, in <module>
    from twisted.web.client import Agent, ProxyAgent, ResponseDone, \
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:18 - __init__.py - _load_handler - ERROR - Loading "scrapy.core.downloader.handlers.s3.S3DownloadHandler" for scheme "s3"
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\__init__.py", line 48, in _load_handler
    dhcls = load_object(path)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\s3.py", line 6, in <module>
    from .http import HTTPDownloadHandler
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\http.py", line 3, in <module>
    from .http11 import HTTP11DownloadHandler as HTTPDownloadHandler
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 16, in <module>
    from twisted.web.client import Agent, ProxyAgent, ResponseDone, \
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:18 - __init__.py - _load_handler - ERROR - Loading "scrapy.core.downloader.handlers.http.HTTPDownloadHandler" for scheme "https"
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\__init__.py", line 48, in _load_handler
    dhcls = load_object(path)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\http.py", line 3, in <module>
    from .http11 import HTTP11DownloadHandler as HTTPDownloadHandler
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 16, in <module>
    from twisted.web.client import Agent, ProxyAgent, ResponseDone, \
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:18 - telnet.py - __init__ - INFO - Telnet Password: b2bedbee7b34b4da
2019-02-07 16:36:18 - __init__.py - _load_handler - ERROR - Loading "scrapy.core.downloader.handlers.http.HTTPDownloadHandler" for scheme "http"
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\__init__.py", line 48, in _load_handler
    dhcls = load_object(path)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\http.py", line 3, in <module>
    from .http11 import HTTP11DownloadHandler as HTTPDownloadHandler
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 16, in <module>
    from twisted.web.client import Agent, ProxyAgent, ResponseDone, \
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:18 - __init__.py - _load_handler - ERROR - Loading "scrapy.core.downloader.handlers.s3.S3DownloadHandler" for scheme "s3"
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\__init__.py", line 48, in _load_handler
    dhcls = load_object(path)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\s3.py", line 6, in <module>
    from .http import HTTPDownloadHandler
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\http.py", line 3, in <module>
    from .http11 import HTTP11DownloadHandler as HTTPDownloadHandler
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 16, in <module>
    from twisted.web.client import Agent, ProxyAgent, ResponseDone, \
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:18 - __init__.py - _load_handler - ERROR - Loading "scrapy.core.downloader.handlers.http.HTTPDownloadHandler" for scheme "https"
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\__init__.py", line 48, in _load_handler
    dhcls = load_object(path)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\http.py", line 3, in <module>
    from .http11 import HTTP11DownloadHandler as HTTPDownloadHandler
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 16, in <module>
    from twisted.web.client import Agent, ProxyAgent, ResponseDone, \
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:18 - telnet.py - __init__ - INFO - Telnet Password: 7c4285024a938796
2019-02-07 16:36:18 - __init__.py - _load_handler - ERROR - Loading "scrapy.core.downloader.handlers.http.HTTPDownloadHandler" for scheme "http"
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\__init__.py", line 48, in _load_handler
    dhcls = load_object(path)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\http.py", line 3, in <module>
    from .http11 import HTTP11DownloadHandler as HTTPDownloadHandler
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 16, in <module>
    from twisted.web.client import Agent, ProxyAgent, ResponseDone, \
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:18 - __init__.py - _load_handler - ERROR - Loading "scrapy.core.downloader.handlers.s3.S3DownloadHandler" for scheme "s3"
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\__init__.py", line 48, in _load_handler
    dhcls = load_object(path)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\s3.py", line 6, in <module>
    from .http import HTTPDownloadHandler
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\http.py", line 3, in <module>
    from .http11 import HTTP11DownloadHandler as HTTPDownloadHandler
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 16, in <module>
    from twisted.web.client import Agent, ProxyAgent, ResponseDone, \
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:18 - __init__.py - _load_handler - ERROR - Loading "scrapy.core.downloader.handlers.http.HTTPDownloadHandler" for scheme "https"
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\__init__.py", line 48, in _load_handler
    dhcls = load_object(path)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\http.py", line 3, in <module>
    from .http11 import HTTP11DownloadHandler as HTTPDownloadHandler
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 16, in <module>
    from twisted.web.client import Agent, ProxyAgent, ResponseDone, \
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:18 - telnet.py - __init__ - INFO - Telnet Password: 9e7ee5bc3e88d894
2019-02-07 16:36:18 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:18 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:18 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:18 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:18 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:18 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:18 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:18 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:18 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:18 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:18 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:18 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:18 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:18 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:18 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:18 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:18 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:18 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:18 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:18 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:18 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:18 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:18 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:18 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:18 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:18 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:18 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:18 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:18 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:18 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:18 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:18 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:18 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:18 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:18 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:18 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:18 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:18 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:18 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:18 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:18 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:18 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:18 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:18 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:18 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:18 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:18 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:18 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:18 - __init__.py - _load_handler - ERROR - Loading "scrapy.core.downloader.handlers.http.HTTPDownloadHandler" for scheme "http"
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\__init__.py", line 48, in _load_handler
    dhcls = load_object(path)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\http.py", line 3, in <module>
    from .http11 import HTTP11DownloadHandler as HTTPDownloadHandler
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 16, in <module>
    from twisted.web.client import Agent, ProxyAgent, ResponseDone, \
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:18 - __init__.py - _load_handler - ERROR - Loading "scrapy.core.downloader.handlers.s3.S3DownloadHandler" for scheme "s3"
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\__init__.py", line 48, in _load_handler
    dhcls = load_object(path)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\s3.py", line 6, in <module>
    from .http import HTTPDownloadHandler
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\http.py", line 3, in <module>
    from .http11 import HTTP11DownloadHandler as HTTPDownloadHandler
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 16, in <module>
    from twisted.web.client import Agent, ProxyAgent, ResponseDone, \
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:18 - __init__.py - _load_handler - ERROR - Loading "scrapy.core.downloader.handlers.http.HTTPDownloadHandler" for scheme "https"
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\__init__.py", line 48, in _load_handler
    dhcls = load_object(path)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\http.py", line 3, in <module>
    from .http11 import HTTP11DownloadHandler as HTTPDownloadHandler
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 16, in <module>
    from twisted.web.client import Agent, ProxyAgent, ResponseDone, \
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:18 - telnet.py - __init__ - INFO - Telnet Password: 5a0c29a8213e08d7
2019-02-07 16:36:18 - __init__.py - _load_handler - ERROR - Loading "scrapy.core.downloader.handlers.http.HTTPDownloadHandler" for scheme "http"
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\__init__.py", line 48, in _load_handler
    dhcls = load_object(path)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\http.py", line 3, in <module>
    from .http11 import HTTP11DownloadHandler as HTTPDownloadHandler
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 16, in <module>
    from twisted.web.client import Agent, ProxyAgent, ResponseDone, \
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:18 - __init__.py - _load_handler - ERROR - Loading "scrapy.core.downloader.handlers.s3.S3DownloadHandler" for scheme "s3"
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\__init__.py", line 48, in _load_handler
    dhcls = load_object(path)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\s3.py", line 6, in <module>
    from .http import HTTPDownloadHandler
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\http.py", line 3, in <module>
    from .http11 import HTTP11DownloadHandler as HTTPDownloadHandler
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 16, in <module>
    from twisted.web.client import Agent, ProxyAgent, ResponseDone, \
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:18 - __init__.py - _load_handler - ERROR - Loading "scrapy.core.downloader.handlers.http.HTTPDownloadHandler" for scheme "https"
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\__init__.py", line 48, in _load_handler
    dhcls = load_object(path)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\http.py", line 3, in <module>
    from .http11 import HTTP11DownloadHandler as HTTPDownloadHandler
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 16, in <module>
    from twisted.web.client import Agent, ProxyAgent, ResponseDone, \
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:18 - telnet.py - __init__ - INFO - Telnet Password: 6c19c34aa5f20e33
2019-02-07 16:36:18 - __init__.py - _load_handler - ERROR - Loading "scrapy.core.downloader.handlers.http.HTTPDownloadHandler" for scheme "http"
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\__init__.py", line 48, in _load_handler
    dhcls = load_object(path)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\http.py", line 3, in <module>
    from .http11 import HTTP11DownloadHandler as HTTPDownloadHandler
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 16, in <module>
    from twisted.web.client import Agent, ProxyAgent, ResponseDone, \
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:18 - __init__.py - _load_handler - ERROR - Loading "scrapy.core.downloader.handlers.s3.S3DownloadHandler" for scheme "s3"
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\__init__.py", line 48, in _load_handler
    dhcls = load_object(path)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\s3.py", line 6, in <module>
    from .http import HTTPDownloadHandler
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\http.py", line 3, in <module>
    from .http11 import HTTP11DownloadHandler as HTTPDownloadHandler
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 16, in <module>
    from twisted.web.client import Agent, ProxyAgent, ResponseDone, \
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:18 - __init__.py - _load_handler - ERROR - Loading "scrapy.core.downloader.handlers.http.HTTPDownloadHandler" for scheme "https"
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\__init__.py", line 48, in _load_handler
    dhcls = load_object(path)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\http.py", line 3, in <module>
    from .http11 import HTTP11DownloadHandler as HTTPDownloadHandler
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 16, in <module>
    from twisted.web.client import Agent, ProxyAgent, ResponseDone, \
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:18 - telnet.py - __init__ - INFO - Telnet Password: efeeefad2d83029c
2019-02-07 16:36:18 - __init__.py - _load_handler - ERROR - Loading "scrapy.core.downloader.handlers.http.HTTPDownloadHandler" for scheme "http"
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\__init__.py", line 48, in _load_handler
    dhcls = load_object(path)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\http.py", line 3, in <module>
    from .http11 import HTTP11DownloadHandler as HTTPDownloadHandler
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 16, in <module>
    from twisted.web.client import Agent, ProxyAgent, ResponseDone, \
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:18 - __init__.py - _load_handler - ERROR - Loading "scrapy.core.downloader.handlers.s3.S3DownloadHandler" for scheme "s3"
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\__init__.py", line 48, in _load_handler
    dhcls = load_object(path)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\s3.py", line 6, in <module>
    from .http import HTTPDownloadHandler
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\http.py", line 3, in <module>
    from .http11 import HTTP11DownloadHandler as HTTPDownloadHandler
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 16, in <module>
    from twisted.web.client import Agent, ProxyAgent, ResponseDone, \
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:18 - __init__.py - _load_handler - ERROR - Loading "scrapy.core.downloader.handlers.http.HTTPDownloadHandler" for scheme "https"
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\__init__.py", line 48, in _load_handler
    dhcls = load_object(path)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\http.py", line 3, in <module>
    from .http11 import HTTP11DownloadHandler as HTTPDownloadHandler
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 16, in <module>
    from twisted.web.client import Agent, ProxyAgent, ResponseDone, \
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:18 - telnet.py - __init__ - INFO - Telnet Password: 061380996ba54d9e
2019-02-07 16:36:18 - __init__.py - _load_handler - ERROR - Loading "scrapy.core.downloader.handlers.http.HTTPDownloadHandler" for scheme "http"
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\__init__.py", line 48, in _load_handler
    dhcls = load_object(path)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\http.py", line 3, in <module>
    from .http11 import HTTP11DownloadHandler as HTTPDownloadHandler
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 16, in <module>
    from twisted.web.client import Agent, ProxyAgent, ResponseDone, \
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:18 - __init__.py - _load_handler - ERROR - Loading "scrapy.core.downloader.handlers.s3.S3DownloadHandler" for scheme "s3"
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\__init__.py", line 48, in _load_handler
    dhcls = load_object(path)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\s3.py", line 6, in <module>
    from .http import HTTPDownloadHandler
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\http.py", line 3, in <module>
    from .http11 import HTTP11DownloadHandler as HTTPDownloadHandler
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 16, in <module>
    from twisted.web.client import Agent, ProxyAgent, ResponseDone, \
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - __init__.py - _load_handler - ERROR - Loading "scrapy.core.downloader.handlers.http.HTTPDownloadHandler" for scheme "https"
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\__init__.py", line 48, in _load_handler
    dhcls = load_object(path)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\http.py", line 3, in <module>
    from .http11 import HTTP11DownloadHandler as HTTPDownloadHandler
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 16, in <module>
    from twisted.web.client import Agent, ProxyAgent, ResponseDone, \
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - telnet.py - __init__ - INFO - Telnet Password: 3386174ceb1726dd
2019-02-07 16:36:19 - __init__.py - _load_handler - ERROR - Loading "scrapy.core.downloader.handlers.http.HTTPDownloadHandler" for scheme "http"
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\__init__.py", line 48, in _load_handler
    dhcls = load_object(path)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\http.py", line 3, in <module>
    from .http11 import HTTP11DownloadHandler as HTTPDownloadHandler
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 16, in <module>
    from twisted.web.client import Agent, ProxyAgent, ResponseDone, \
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - __init__.py - _load_handler - ERROR - Loading "scrapy.core.downloader.handlers.s3.S3DownloadHandler" for scheme "s3"
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\__init__.py", line 48, in _load_handler
    dhcls = load_object(path)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\s3.py", line 6, in <module>
    from .http import HTTPDownloadHandler
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\http.py", line 3, in <module>
    from .http11 import HTTP11DownloadHandler as HTTPDownloadHandler
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 16, in <module>
    from twisted.web.client import Agent, ProxyAgent, ResponseDone, \
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - __init__.py - _load_handler - ERROR - Loading "scrapy.core.downloader.handlers.http.HTTPDownloadHandler" for scheme "https"
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\__init__.py", line 48, in _load_handler
    dhcls = load_object(path)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\http.py", line 3, in <module>
    from .http11 import HTTP11DownloadHandler as HTTPDownloadHandler
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 16, in <module>
    from twisted.web.client import Agent, ProxyAgent, ResponseDone, \
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - telnet.py - __init__ - INFO - Telnet Password: 58fceae798ad7cd3
2019-02-07 16:36:19 - __init__.py - _load_handler - ERROR - Loading "scrapy.core.downloader.handlers.http.HTTPDownloadHandler" for scheme "http"
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\__init__.py", line 48, in _load_handler
    dhcls = load_object(path)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\http.py", line 3, in <module>
    from .http11 import HTTP11DownloadHandler as HTTPDownloadHandler
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 16, in <module>
    from twisted.web.client import Agent, ProxyAgent, ResponseDone, \
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - __init__.py - _load_handler - ERROR - Loading "scrapy.core.downloader.handlers.s3.S3DownloadHandler" for scheme "s3"
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\__init__.py", line 48, in _load_handler
    dhcls = load_object(path)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\s3.py", line 6, in <module>
    from .http import HTTPDownloadHandler
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\http.py", line 3, in <module>
    from .http11 import HTTP11DownloadHandler as HTTPDownloadHandler
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 16, in <module>
    from twisted.web.client import Agent, ProxyAgent, ResponseDone, \
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - __init__.py - _load_handler - ERROR - Loading "scrapy.core.downloader.handlers.http.HTTPDownloadHandler" for scheme "https"
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\__init__.py", line 48, in _load_handler
    dhcls = load_object(path)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\http.py", line 3, in <module>
    from .http11 import HTTP11DownloadHandler as HTTPDownloadHandler
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 16, in <module>
    from twisted.web.client import Agent, ProxyAgent, ResponseDone, \
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - telnet.py - __init__ - INFO - Telnet Password: b7806ccc7d4bbc93
2019-02-07 16:36:19 - __init__.py - _load_handler - ERROR - Loading "scrapy.core.downloader.handlers.http.HTTPDownloadHandler" for scheme "http"
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\__init__.py", line 48, in _load_handler
    dhcls = load_object(path)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\http.py", line 3, in <module>
    from .http11 import HTTP11DownloadHandler as HTTPDownloadHandler
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 16, in <module>
    from twisted.web.client import Agent, ProxyAgent, ResponseDone, \
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - __init__.py - _load_handler - ERROR - Loading "scrapy.core.downloader.handlers.s3.S3DownloadHandler" for scheme "s3"
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\__init__.py", line 48, in _load_handler
    dhcls = load_object(path)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\s3.py", line 6, in <module>
    from .http import HTTPDownloadHandler
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\http.py", line 3, in <module>
    from .http11 import HTTP11DownloadHandler as HTTPDownloadHandler
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 16, in <module>
    from twisted.web.client import Agent, ProxyAgent, ResponseDone, \
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - __init__.py - _load_handler - ERROR - Loading "scrapy.core.downloader.handlers.http.HTTPDownloadHandler" for scheme "https"
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\__init__.py", line 48, in _load_handler
    dhcls = load_object(path)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\http.py", line 3, in <module>
    from .http11 import HTTP11DownloadHandler as HTTPDownloadHandler
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 16, in <module>
    from twisted.web.client import Agent, ProxyAgent, ResponseDone, \
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - telnet.py - __init__ - INFO - Telnet Password: 601c615c0c361fdd
2019-02-07 16:36:19 - __init__.py - _load_handler - ERROR - Loading "scrapy.core.downloader.handlers.http.HTTPDownloadHandler" for scheme "http"
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\__init__.py", line 48, in _load_handler
    dhcls = load_object(path)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\http.py", line 3, in <module>
    from .http11 import HTTP11DownloadHandler as HTTPDownloadHandler
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 16, in <module>
    from twisted.web.client import Agent, ProxyAgent, ResponseDone, \
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - __init__.py - _load_handler - ERROR - Loading "scrapy.core.downloader.handlers.s3.S3DownloadHandler" for scheme "s3"
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\__init__.py", line 48, in _load_handler
    dhcls = load_object(path)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\s3.py", line 6, in <module>
    from .http import HTTPDownloadHandler
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\http.py", line 3, in <module>
    from .http11 import HTTP11DownloadHandler as HTTPDownloadHandler
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 16, in <module>
    from twisted.web.client import Agent, ProxyAgent, ResponseDone, \
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - __init__.py - _load_handler - ERROR - Loading "scrapy.core.downloader.handlers.http.HTTPDownloadHandler" for scheme "https"
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\__init__.py", line 48, in _load_handler
    dhcls = load_object(path)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\http.py", line 3, in <module>
    from .http11 import HTTP11DownloadHandler as HTTPDownloadHandler
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 16, in <module>
    from twisted.web.client import Agent, ProxyAgent, ResponseDone, \
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - telnet.py - __init__ - INFO - Telnet Password: 4b52147bce761116
2019-02-07 16:36:19 - __init__.py - _load_handler - ERROR - Loading "scrapy.core.downloader.handlers.http.HTTPDownloadHandler" for scheme "http"
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\__init__.py", line 48, in _load_handler
    dhcls = load_object(path)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\http.py", line 3, in <module>
    from .http11 import HTTP11DownloadHandler as HTTPDownloadHandler
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 16, in <module>
    from twisted.web.client import Agent, ProxyAgent, ResponseDone, \
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - __init__.py - _load_handler - ERROR - Loading "scrapy.core.downloader.handlers.s3.S3DownloadHandler" for scheme "s3"
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\__init__.py", line 48, in _load_handler
    dhcls = load_object(path)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\s3.py", line 6, in <module>
    from .http import HTTPDownloadHandler
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\http.py", line 3, in <module>
    from .http11 import HTTP11DownloadHandler as HTTPDownloadHandler
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 16, in <module>
    from twisted.web.client import Agent, ProxyAgent, ResponseDone, \
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - __init__.py - _load_handler - ERROR - Loading "scrapy.core.downloader.handlers.http.HTTPDownloadHandler" for scheme "https"
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\__init__.py", line 48, in _load_handler
    dhcls = load_object(path)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\http.py", line 3, in <module>
    from .http11 import HTTP11DownloadHandler as HTTPDownloadHandler
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 16, in <module>
    from twisted.web.client import Agent, ProxyAgent, ResponseDone, \
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - telnet.py - __init__ - INFO - Telnet Password: 945351855a0d40e0
2019-02-07 16:36:19 - __init__.py - _load_handler - ERROR - Loading "scrapy.core.downloader.handlers.http.HTTPDownloadHandler" for scheme "http"
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\__init__.py", line 48, in _load_handler
    dhcls = load_object(path)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\http.py", line 3, in <module>
    from .http11 import HTTP11DownloadHandler as HTTPDownloadHandler
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 16, in <module>
    from twisted.web.client import Agent, ProxyAgent, ResponseDone, \
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - __init__.py - _load_handler - ERROR - Loading "scrapy.core.downloader.handlers.s3.S3DownloadHandler" for scheme "s3"
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\__init__.py", line 48, in _load_handler
    dhcls = load_object(path)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\s3.py", line 6, in <module>
    from .http import HTTPDownloadHandler
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\http.py", line 3, in <module>
    from .http11 import HTTP11DownloadHandler as HTTPDownloadHandler
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 16, in <module>
    from twisted.web.client import Agent, ProxyAgent, ResponseDone, \
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - __init__.py - _load_handler - ERROR - Loading "scrapy.core.downloader.handlers.http.HTTPDownloadHandler" for scheme "https"
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\__init__.py", line 48, in _load_handler
    dhcls = load_object(path)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\http.py", line 3, in <module>
    from .http11 import HTTP11DownloadHandler as HTTPDownloadHandler
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 16, in <module>
    from twisted.web.client import Agent, ProxyAgent, ResponseDone, \
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - telnet.py - __init__ - INFO - Telnet Password: 0e78863b6972fe77
2019-02-07 16:36:19 - __init__.py - _load_handler - ERROR - Loading "scrapy.core.downloader.handlers.http.HTTPDownloadHandler" for scheme "http"
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\__init__.py", line 48, in _load_handler
    dhcls = load_object(path)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\http.py", line 3, in <module>
    from .http11 import HTTP11DownloadHandler as HTTPDownloadHandler
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 16, in <module>
    from twisted.web.client import Agent, ProxyAgent, ResponseDone, \
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - __init__.py - _load_handler - ERROR - Loading "scrapy.core.downloader.handlers.s3.S3DownloadHandler" for scheme "s3"
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\__init__.py", line 48, in _load_handler
    dhcls = load_object(path)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\s3.py", line 6, in <module>
    from .http import HTTPDownloadHandler
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\http.py", line 3, in <module>
    from .http11 import HTTP11DownloadHandler as HTTPDownloadHandler
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 16, in <module>
    from twisted.web.client import Agent, ProxyAgent, ResponseDone, \
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - __init__.py - _load_handler - ERROR - Loading "scrapy.core.downloader.handlers.http.HTTPDownloadHandler" for scheme "https"
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\__init__.py", line 48, in _load_handler
    dhcls = load_object(path)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\http.py", line 3, in <module>
    from .http11 import HTTP11DownloadHandler as HTTPDownloadHandler
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 16, in <module>
    from twisted.web.client import Agent, ProxyAgent, ResponseDone, \
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - telnet.py - __init__ - INFO - Telnet Password: 7848903f5536aa2a
2019-02-07 16:36:19 - __init__.py - _load_handler - ERROR - Loading "scrapy.core.downloader.handlers.http.HTTPDownloadHandler" for scheme "http"
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\__init__.py", line 48, in _load_handler
    dhcls = load_object(path)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\http.py", line 3, in <module>
    from .http11 import HTTP11DownloadHandler as HTTPDownloadHandler
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 16, in <module>
    from twisted.web.client import Agent, ProxyAgent, ResponseDone, \
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - __init__.py - _load_handler - ERROR - Loading "scrapy.core.downloader.handlers.s3.S3DownloadHandler" for scheme "s3"
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\__init__.py", line 48, in _load_handler
    dhcls = load_object(path)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\s3.py", line 6, in <module>
    from .http import HTTPDownloadHandler
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\http.py", line 3, in <module>
    from .http11 import HTTP11DownloadHandler as HTTPDownloadHandler
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 16, in <module>
    from twisted.web.client import Agent, ProxyAgent, ResponseDone, \
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:36:19 - __init__.py - _load_handler - ERROR - Loading "scrapy.core.downloader.handlers.http.HTTPDownloadHandler" for scheme "https"
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\__init__.py", line 48, in _load_handler
    dhcls = load_object(path)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\http.py", line 3, in <module>
    from .http11 import HTTP11DownloadHandler as HTTPDownloadHandler
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 16, in <module>
    from twisted.web.client import Agent, ProxyAgent, ResponseDone, \
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:40:55 - telnet.py - __init__ - INFO - Telnet Password: 2becf87f43608a8d
2019-02-07 16:40:55 - __init__.py - _load_handler - ERROR - Loading "scrapy.core.downloader.handlers.http.HTTPDownloadHandler" for scheme "http"
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\__init__.py", line 48, in _load_handler
    dhcls = load_object(path)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\http.py", line 3, in <module>
    from .http11 import HTTP11DownloadHandler as HTTPDownloadHandler
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 16, in <module>
    from twisted.web.client import Agent, ProxyAgent, ResponseDone, \
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:40:55 - __init__.py - _load_handler - ERROR - Loading "scrapy.core.downloader.handlers.s3.S3DownloadHandler" for scheme "s3"
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\__init__.py", line 48, in _load_handler
    dhcls = load_object(path)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\s3.py", line 6, in <module>
    from .http import HTTPDownloadHandler
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\http.py", line 3, in <module>
    from .http11 import HTTP11DownloadHandler as HTTPDownloadHandler
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 16, in <module>
    from twisted.web.client import Agent, ProxyAgent, ResponseDone, \
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:40:55 - __init__.py - _load_handler - ERROR - Loading "scrapy.core.downloader.handlers.http.HTTPDownloadHandler" for scheme "https"
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\__init__.py", line 48, in _load_handler
    dhcls = load_object(path)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\http.py", line 3, in <module>
    from .http11 import HTTP11DownloadHandler as HTTPDownloadHandler
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 16, in <module>
    from twisted.web.client import Agent, ProxyAgent, ResponseDone, \
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:41:02 - telnet.py - __init__ - INFO - Telnet Password: 7850c0af3c13eca7
2019-02-07 16:41:02 - __init__.py - _load_handler - ERROR - Loading "scrapy.core.downloader.handlers.http.HTTPDownloadHandler" for scheme "http"
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\__init__.py", line 48, in _load_handler
    dhcls = load_object(path)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\http.py", line 3, in <module>
    from .http11 import HTTP11DownloadHandler as HTTPDownloadHandler
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 16, in <module>
    from twisted.web.client import Agent, ProxyAgent, ResponseDone, \
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:41:02 - __init__.py - _load_handler - ERROR - Loading "scrapy.core.downloader.handlers.s3.S3DownloadHandler" for scheme "s3"
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\__init__.py", line 48, in _load_handler
    dhcls = load_object(path)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\s3.py", line 6, in <module>
    from .http import HTTPDownloadHandler
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\http.py", line 3, in <module>
    from .http11 import HTTP11DownloadHandler as HTTPDownloadHandler
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 16, in <module>
    from twisted.web.client import Agent, ProxyAgent, ResponseDone, \
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:41:02 - __init__.py - _load_handler - ERROR - Loading "scrapy.core.downloader.handlers.http.HTTPDownloadHandler" for scheme "https"
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\__init__.py", line 48, in _load_handler
    dhcls = load_object(path)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\http.py", line 3, in <module>
    from .http11 import HTTP11DownloadHandler as HTTPDownloadHandler
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 16, in <module>
    from twisted.web.client import Agent, ProxyAgent, ResponseDone, \
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:41:02 - telnet.py - __init__ - INFO - Telnet Password: 05f3a21d63207706
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - Unhandled error in Deferred:
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:41:02 - _legacy.py - publishToNewObserver - CRITICAL - 
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:41:02 - __init__.py - _load_handler - ERROR - Loading "scrapy.core.downloader.handlers.http.HTTPDownloadHandler" for scheme "http"
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\__init__.py", line 48, in _load_handler
    dhcls = load_object(path)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\http.py", line 3, in <module>
    from .http11 import HTTP11DownloadHandler as HTTPDownloadHandler
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 16, in <module>
    from twisted.web.client import Agent, ProxyAgent, ResponseDone, \
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:41:02 - __init__.py - _load_handler - ERROR - Loading "scrapy.core.downloader.handlers.s3.S3DownloadHandler" for scheme "s3"
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\__init__.py", line 48, in _load_handler
    dhcls = load_object(path)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\s3.py", line 6, in <module>
    from .http import HTTPDownloadHandler
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\http.py", line 3, in <module>
    from .http11 import HTTP11DownloadHandler as HTTPDownloadHandler
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 16, in <module>
    from twisted.web.client import Agent, ProxyAgent, ResponseDone, \
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:41:02 - __init__.py - _load_handler - ERROR - Loading "scrapy.core.downloader.handlers.http.HTTPDownloadHandler" for scheme "https"
Traceback (most recent call last):
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\__init__.py", line 48, in _load_handler
    dhcls = load_object(path)
  File "C:\Python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\http.py", line 3, in <module>
    from .http11 import HTTP11DownloadHandler as HTTPDownloadHandler
  File "C:\Python27\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 16, in <module>
    from twisted.web.client import Agent, ProxyAgent, ResponseDone, \
  File "C:\Python27\lib\site-packages\twisted\web\client.py", line 41, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "C:\Python27\lib\site-packages\twisted\internet\endpoints.py", line 41, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "C:\Python27\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "C:\Python27\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2019-02-07 16:48:30 - run.py - <module> - INFO - Start Execution ... 
2019-02-07 16:48:30 - run.py - <module> - INFO - SETUP global variables
2019-02-07 16:48:31 - run.py - <module> - INFO - CREATE pipeline
2019-02-07 16:48:31 - run.py - <module> - INFO - SETUP pipeline
2019-02-07 16:48:31 - run.py - <module> - INFO - setup module: <DB.schema_definition.DB instance at 0x00000000306D1748>
2019-02-07 16:48:31 - run.py - <module> - INFO - setup module: <webcrawlers.webcrawlers.WebCrawlers object at 0x000000002FC756D8>
2019-02-07 16:48:31 - run.py - <module> - INFO - checking module definition
2019-02-07 16:48:31 - run.py - <module> - INFO - module <DB.schema_definition.DB instance at 0x00000000306D1748> is well defined
2019-02-07 16:48:31 - run.py - <module> - INFO - module <webcrawlers.webcrawlers.WebCrawlers object at 0x000000002FC756D8> is well defined
2019-02-07 16:48:31 - run.py - <module> - INFO - execute module: <DB.schema_definition.DB instance at 0x00000000306D1748>
2019-02-07 16:48:31 - run.py - <module> - INFO - *********Started executing DB
2019-02-07 16:48:31 - run.py - <module> - INFO - *********Finished executing DB
2019-02-07 16:48:31 - run.py - <module> - INFO - execute module: <webcrawlers.webcrawlers.WebCrawlers object at 0x000000002FC756D8>
2019-02-07 16:48:31 - run.py - <module> - INFO - *********Started executing WebCrawlers
2019-02-07 16:48:46 - telnet.py - __init__ - INFO - Telnet Password: 2d6ce010c7cd57a2
2019-02-07 16:48:46 - logstats.py - log - INFO - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-02-07 16:48:46 - telnet.py - start_listening - INFO - Telnet console listening on 127.0.0.1:6023
2019-02-07 16:48:46 - statscollectors.py - close_spider - INFO - Dumping Scrapy stats:
{'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 2, 7, 16, 48, 46, 763000),
 'log_count/INFO': 3,
 'start_time': datetime.datetime(2019, 2, 7, 16, 48, 46, 748000)}
2019-02-07 16:53:57 - telnet.py - __init__ - INFO - Telnet Password: 54e6d9cdebc4f751
2019-02-07 16:53:57 - logstats.py - log - INFO - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-02-07 16:53:57 - telnet.py - start_listening - INFO - Telnet console listening on 127.0.0.1:6024
2019-02-07 16:54:16 - run.py - <module> - ERROR - *********Failed in executing : WebCrawlers
Traceback (most recent call last):
  File "C:\Users\Administrator\Documents\GitHub\measurement-of-online-discussion-authenticity\bad_actors\run.py", line 213, in <module>
    module.execute(window_start)
  File "C:\Users\Administrator\Documents\GitHub\measurement-of-online-discussion-authenticity\bad_actors\commons\method_executor.py", line 19, in execute
    getattr(self, action_name)()
  File "C:\Users\Administrator\Documents\GitHub\measurement-of-online-discussion-authenticity\bad_actors\webcrawlers\webcrawlers.py", line 30, in get_most_popular_posts_by_google_trends
    self._generic_webcrawlers.retrieve_and_save_data_from_newsapi_by_terms(terms)
  File "C:\Users\Administrator\Documents\GitHub\measurement-of-online-discussion-authenticity\bad_actors\webcrawlers\generic_webcrawlers.py", line 24, in retrieve_and_save_data_from_newsapi_by_terms
    posts_lst, claims_lst, articles_lst, article_items_lst = self.get_articles_by_terms(terms)
  File "C:\Users\Administrator\Documents\GitHub\measurement-of-online-discussion-authenticity\bad_actors\webcrawlers\generic_webcrawlers.py", line 39, in get_articles_by_terms
    all_articles.append(self._webcrawlers_client.get_everything(q=term, **params))
  File "C:\Users\Administrator\Documents\GitHub\measurement-of-online-discussion-authenticity\bad_actors\webcrawlers_api\webcrawlers_client.py", line 93, in get_everything
    return self._get_everything(payload)  # Returns a dictionary. with 'articles', , , keys.
  File "C:\Users\Administrator\Documents\GitHub\measurement-of-online-discussion-authenticity\bad_actors\webcrawlers_api\webcrawlers_client.py", line 104, in _get_everything
    articles = self._crawl_site(payload['site'])
  File "C:\Users\Administrator\Documents\GitHub\measurement-of-online-discussion-authenticity\bad_actors\webcrawlers_api\webcrawlers_client.py", line 117, in _crawl_site
    process.start()  # the script will block here until the crawling is finished
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "C:\Python27\lib\site-packages\twisted\internet\base.py", line 1266, in run
    self.startRunning(installSignalHandlers=installSignalHandlers)
  File "C:\Python27\lib\site-packages\twisted\internet\base.py", line 1246, in startRunning
    ReactorBase.startRunning(self)
  File "C:\Python27\lib\site-packages\twisted\internet\base.py", line 754, in startRunning
    raise error.ReactorNotRestartable()
ReactorNotRestartable
2019-02-07 16:54:45 - run.py - <module> - INFO - Start Execution ... 
2019-02-07 16:54:45 - run.py - <module> - INFO - SETUP global variables
2019-02-07 16:54:45 - run.py - <module> - INFO - CREATE pipeline
2019-02-07 16:54:45 - run.py - <module> - INFO - SETUP pipeline
2019-02-07 16:54:45 - run.py - <module> - INFO - setup module: <DB.schema_definition.DB instance at 0x000000003007F688>
2019-02-07 16:54:45 - run.py - <module> - INFO - setup module: <webcrawlers.webcrawlers.WebCrawlers object at 0x000000002F6776D8>
2019-02-07 16:54:45 - run.py - <module> - INFO - checking module definition
2019-02-07 16:54:45 - run.py - <module> - INFO - module <DB.schema_definition.DB instance at 0x000000003007F688> is well defined
2019-02-07 16:54:45 - run.py - <module> - INFO - module <webcrawlers.webcrawlers.WebCrawlers object at 0x000000002F6776D8> is well defined
2019-02-07 16:54:45 - run.py - <module> - INFO - execute module: <DB.schema_definition.DB instance at 0x000000003007F688>
2019-02-07 16:54:45 - run.py - <module> - INFO - *********Started executing DB
2019-02-07 16:54:45 - run.py - <module> - INFO - *********Finished executing DB
2019-02-07 16:54:45 - run.py - <module> - INFO - execute module: <webcrawlers.webcrawlers.WebCrawlers object at 0x000000002F6776D8>
2019-02-07 16:54:45 - run.py - <module> - INFO - *********Started executing WebCrawlers
2019-02-07 16:54:47 - telnet.py - __init__ - INFO - Telnet Password: 74b01c4562531802
2019-02-07 16:54:47 - logstats.py - log - INFO - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-02-07 16:54:47 - telnet.py - start_listening - INFO - Telnet console listening on 127.0.0.1:6023
2019-02-07 16:54:47 - statscollectors.py - close_spider - INFO - Dumping Scrapy stats:
{'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 2, 7, 16, 54, 47, 298000),
 'log_count/INFO': 3,
 'start_time': datetime.datetime(2019, 2, 7, 16, 54, 47, 283000)}
2019-02-07 16:54:47 - telnet.py - __init__ - INFO - Telnet Password: 3b817da3fc5ebf52
2019-02-07 16:54:47 - logstats.py - log - INFO - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-02-07 16:54:47 - telnet.py - start_listening - INFO - Telnet console listening on 127.0.0.1:6024
2019-02-07 16:54:47 - run.py - <module> - ERROR - *********Failed in executing : WebCrawlers
Traceback (most recent call last):
  File "C:\Users\Administrator\Documents\GitHub\measurement-of-online-discussion-authenticity\bad_actors\run.py", line 213, in <module>
    module.execute(window_start)
  File "C:\Users\Administrator\Documents\GitHub\measurement-of-online-discussion-authenticity\bad_actors\commons\method_executor.py", line 19, in execute
    getattr(self, action_name)()
  File "C:\Users\Administrator\Documents\GitHub\measurement-of-online-discussion-authenticity\bad_actors\webcrawlers\webcrawlers.py", line 30, in get_most_popular_posts_by_google_trends
    self._generic_webcrawlers.retrieve_and_save_data_from_newsapi_by_terms(terms)
  File "C:\Users\Administrator\Documents\GitHub\measurement-of-online-discussion-authenticity\bad_actors\webcrawlers\generic_webcrawlers.py", line 24, in retrieve_and_save_data_from_newsapi_by_terms
    posts_lst, claims_lst, articles_lst, article_items_lst = self.get_articles_by_terms(terms)
  File "C:\Users\Administrator\Documents\GitHub\measurement-of-online-discussion-authenticity\bad_actors\webcrawlers\generic_webcrawlers.py", line 39, in get_articles_by_terms
    all_articles.append(self._webcrawlers_client.get_everything(q=term, **params))
  File "C:\Users\Administrator\Documents\GitHub\measurement-of-online-discussion-authenticity\bad_actors\webcrawlers_api\webcrawlers_client.py", line 93, in get_everything
    return self._get_everything(payload)  # Returns a dictionary. with 'articles', , , keys.
  File "C:\Users\Administrator\Documents\GitHub\measurement-of-online-discussion-authenticity\bad_actors\webcrawlers_api\webcrawlers_client.py", line 104, in _get_everything
    articles = self._crawl_site(payload['site'])
  File "C:\Users\Administrator\Documents\GitHub\measurement-of-online-discussion-authenticity\bad_actors\webcrawlers_api\webcrawlers_client.py", line 117, in _crawl_site
    process.start()  # the script will block here until the crawling is finished
  File "C:\Python27\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "C:\Python27\lib\site-packages\twisted\internet\base.py", line 1266, in run
    self.startRunning(installSignalHandlers=installSignalHandlers)
  File "C:\Python27\lib\site-packages\twisted\internet\base.py", line 1246, in startRunning
    ReactorBase.startRunning(self)
  File "C:\Python27\lib\site-packages\twisted\internet\base.py", line 754, in startRunning
    raise error.ReactorNotRestartable()
ReactorNotRestartable
2019-02-07 16:57:25 - run.py - <module> - INFO - Start Execution ... 
2019-02-07 16:57:25 - run.py - <module> - INFO - SETUP global variables
2019-02-07 16:57:25 - run.py - <module> - INFO - CREATE pipeline
2019-02-07 16:57:25 - run.py - <module> - INFO - SETUP pipeline
2019-02-07 16:57:25 - run.py - <module> - INFO - setup module: <DB.schema_definition.DB instance at 0x000000002FE0B688>
2019-02-07 16:57:25 - run.py - <module> - INFO - setup module: <webcrawlers.webcrawlers.WebCrawlers object at 0x0000000029DBAB70>
2019-02-07 16:57:25 - run.py - <module> - INFO - checking module definition
2019-02-07 16:57:25 - run.py - <module> - INFO - module <DB.schema_definition.DB instance at 0x000000002FE0B688> is well defined
2019-02-07 16:57:25 - run.py - <module> - INFO - module <webcrawlers.webcrawlers.WebCrawlers object at 0x0000000029DBAB70> is well defined
2019-02-07 16:57:25 - run.py - <module> - INFO - execute module: <DB.schema_definition.DB instance at 0x000000002FE0B688>
2019-02-07 16:57:25 - run.py - <module> - INFO - *********Started executing DB
2019-02-07 16:57:25 - run.py - <module> - INFO - *********Finished executing DB
2019-02-07 16:57:25 - run.py - <module> - INFO - execute module: <webcrawlers.webcrawlers.WebCrawlers object at 0x0000000029DBAB70>
2019-02-07 16:57:25 - run.py - <module> - INFO - *********Started executing WebCrawlers
2019-02-07 16:57:26 - telnet.py - __init__ - INFO - Telnet Password: 9b2060ba9f850351
2019-02-07 16:57:27 - logstats.py - log - INFO - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-02-07 16:57:27 - telnet.py - start_listening - INFO - Telnet console listening on 127.0.0.1:6023
2019-02-07 16:57:48 - statscollectors.py - close_spider - INFO - Dumping Scrapy stats:
{'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 2, 7, 16, 57, 48, 214000),
 'log_count/INFO': 3,
 'start_time': datetime.datetime(2019, 2, 7, 16, 57, 27, 90000)}
2019-02-07 16:58:09 - crawler.py - spiders - WARNING - C:\Users\Administrator\.p2\pool\plugins\org.python.pydev.core_6.5.0.201809011628\pysrc\_pydevd_bundle\pydevd_resolver.py:166: ScrapyDeprecationWarning: CrawlerRunner.spiders attribute is renamed to CrawlerRunner.spider_loader.
  attr = getattr(var, n)

