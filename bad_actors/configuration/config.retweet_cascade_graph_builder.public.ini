[DEFAULT]
logger_name = root
logger_conf_file = configuration/logging.conf
start_date = date('2000-06-07 00:00:00')
end_date = date('2019-06-14 23:59:59')
step_size_in_sec = 691200
#step_size_in_sec = 12960000
#five days in sec = 432000
window_analyze_size_in_sec = 691200
keep_results_for = 2246400
max_concurrent_jobs = 1
domain=Microblog
#domain=Claim
#domain=Blog
#domain=News
#domain=Article
targeted_classes = ['author_type']
#social_network_name = Clickbait_Challenge
#social_network_name = Fake_News
#social_network_name = SBP-BRiMS_2017
social_network_name = Twitter
#social_network_name = PolitiFact
#social_network_url = "https://Clickbait_Challenge.com/"
#social_network_url = "https://SBP-BRiMS_2017.com/"
#social_network_url = "https://politifact.com/"
social_network_url = "https://twitter.com/"


[Logger]
logger_conf_file = configuration/logging.conf
logger_name = root
file_name = log/bad_actors.log
level = logging.INFO

[OperatingSystem]
linux=False
windows=True

[DB]
DB_path = data/input/
DB_name_prefix = bad_actors_
DB_name_suffix = .db
DB_path_to_extension = lib/extension-functions
dialect_name = sqlalchemy.dialects.sqlite

remove_on_setup = False
remove_on_teardown = False
dropall_on_setup = True
dropall_on_teardown = False
start_date = date('2010-01-01 00:00:00')


[LeadspottingPostsImporter]
data_folder = "data/input/datasets/Leadspotting/posts/"


[DatasetBuilderConfig]
clean_authors_features_table = False

;[MissingDataComplementor]
;actions = ['fill_tweet_retweet_connection','fill_data_for_sources','fill_data_for_followers','fill_data_for_friends','fill_authors_time_line'
#                   ,'assign_manually_labeled_authors','assign_acquired_and_crowdturfer_profiles','delete_acquired_authors','delete_manually_labeled_authors']
;actions = ['fill_data_for_followers']
;max_users_without_saving = 10000
;minimal_num_of_posts = 10000
;limit_friend_follower_number = 1000000
# maximal_tweets_count_in_timeline maximal value is 200 according to Twitter API
;maximal_tweets_count_in_timeline = 5


##################################################################################
###########################Graph Builder##########################################
##################################################################################

[GraphBuilder_RetweetCascade]
connection_type = retweet_cascade
max_objects_without_saving = 30
num_of_random_authors_for_graph = 20
min_number_of_posts_per_author = None
sample_top_followers_users = 30

[TwitterApiRequester]

sleep_on_rate_limit = False
consumer_key = '<KEY>'
consumer_secret = '<KEY>'
access_token_key = '<KEY>'
access_token_secret = '<KEY>'

user_id = <you'r user id>
screen_name = "<you'r screen name>"


[Twitter_Rest_Api]
#can be 1, 2, or 3
working_app_number = 2
maximal_get_friend_ids_requests_in_window = 15
maximal_get_follower_ids_requests_in_window = 15
maximal_get_user_requests_in_window = 180
maximal_user_ids_allowed_in_single_get_user_request = 98
num_of_requests_without_checking = 9999999999
num_of_twitter_status_id_requests_without_checking = 9999999999
num_of_twitter_timeline_requests_without_checking = 9999999999
maximal_number_of_retrieved_users = 1000
max_tweet_ids_allowed_in_single_get_tweets_by_tweet_ids_request = 100
max_num_of_tweet_ids_requests_without_checking = 900



;[TimelineOverlapVisualizationGenerator] check if needed
;common_posts_threshold = 1
;# unlabeled bad author - an author that wasn't manually labeled, i.e. was automatically classified by the model as bad actor
;#unlabeled_bad_authors = ["NewAndroidApps", "PeopleSource_UK", "Niko360","couponsaday", "JuJu_Carbo","LearningroomLMS"]
;# labeled bad author - an author that was manually labeled as bad actor
;#labeled_bad_authors = ["nb95591", "T2Alice", "hjcbizsolutions"]
;output_dir = "overlapping_visualization"
;output_path = "data/output"
;
;;end_date =  ''



