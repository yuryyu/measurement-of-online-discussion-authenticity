[DEFAULT]
logger_name = root
logger_conf_file = configuration/logging.conf
start_date = date('2000-06-07 00:00:00')
end_date = date('2019-06-14 23:59:59')
step_size_in_sec = 691200
window_analyze_size_in_sec = 691200
keep_results_for = 2246400
max_concurrent_jobs = 1
domain = Microblog
#domain=Claim
targeted_classes = ['author_type']
social_network_name = twitter
social_network_url = "https://twitter.com/"

[Logger]
logger_conf_file = configuration/logging.conf
logger_name = root
file_name = log/leadspotting.log
level = logging.INFO

[OperatingSystem]
linux=False
windows=True

[DB]
DB_path = data/input/
DB_name_prefix = Leadspotting_
DB_name_suffix = _database.db
DB_path_to_extension = lib/extension-functions
dialect_name = sqlalchemy.dialects.sqlite
remove_on_setup = False
remove_on_teardown = False
dropall_on_setup = False
dropall_on_teardown = False

[DataFrameCreator]
all_authors = True
normalize = False

#[CsvImporter]
#data_folder = "data/input/datasets/Leadspotting/posts/"
#data_folder = "data/input/datasets/default/"

; [FakeNewsSnopesImporter]
; input_csv_file="data/input/FakeNewsSnopesImporter/Fake_News_Snopes_V8.csv"
#[FakeNewsSnopesImporter]
#input_csv_file = 'data/input/snopes_importer_data/Fake_News_Snopes_V8.csv'

# ************** DATASET BUILDER MODULE **********************
[DatasetBuilderConfig]
clean_authors_features_table = False

#[Image_Downloader]
#path_for_downloaded_images = 'data/output/Image_Downloader/'


; [MissingDataComplementor]
; #actions = ['fill_tweet_retweet_connection','fill_data_for_sources','fill_data_for_followers','fill_data_for_friends','fill_authors_time_line'
; #                   ,'assign_manually_labeled_authors','assign_acquired_and_crowdturfer_profiles','delete_acquired_authors','delete_manually_labeled_authors']
; actions = ['fill_data_for_sources']
; max_users_without_saving = 1000
; minimal_num_of_posts = 1000
; limit_friend_follower_number = 5
; # maximal_tweets_count_in_timeline maximal value is 200 according to Twitter API
; maximal_tweets_count_in_timeline = 5

# if you need to export features to arff file - uncomment the next
# [DataExporter]
# #arff_file = 'data/output/clickbait_challenge_validation_training_set2.arff'
# arff_file = 'data/output/footprint_features.arff'
# #author_type_classes = ["bad_actor", "good_actor"]
# author_type_classes = ["False", "True"]




#[LDATopicModel]
#number_of_topics=10
#num_of_terms_in_topic = 12
#stopword_file = lib/eng_stopwords.txt
#stem_language = ENG

; [FeatureExtractor]
; table_name = "author_features"







; [ExperimentalEnvironment]
; #actions = ['perform_k_fold_cross_validation_and_predict', 'predict_on_prepared_clssifier', 'train_one_class_classifier_and_predict',
; #            'train_one_class_classifier_by_k_best_and_predict', 'transfer_learning']
; actions = ['predict_on_prepared_clssifier']
; #actions = ['perform_k_fold_cross_validation_and_predict']

; # training_size = 1% so test set = 99%
; divide_lableled_by_percent_training_size = [0.01, 0.02, 0.05, 0.1, 0.2, 0.4]
; k_for_fold = 10
; classifier_type_names = ["RandomForest", "DecisionTree", "AdaBoost", "XGBoost"]
; selected_features = ["AccountPropertiesFeatureGenerator_account_age",
; "AccountPropertiesFeatureGenerator_default_profile",
; "AccountPropertiesFeatureGenerator_friends_followers_ratio",
; "AccountPropertiesFeatureGenerator_listed_count",
; "AccountPropertiesFeatureGenerator_number_followers",
; "BehaviorFeatureGenerator_average_minutes_between_posts",
; "BehaviorFeatureGenerator_average_posts_per_day_active_days",
; "SyntaxFeatureGenerator_average_hashtags",
; "SyntaxFeatureGenerator_average_links",
; "SyntaxFeatureGenerator_average_user_mentions"
; ]
; #targeted_class_name = author_type
; targeted_class_name = AccountPropertiesFeatureGenerator_author_type
; ##removed_features = ["author_sub_type", "author_type", "author_screen_name"]
; removed_features = []
; num_iterations = [5]
; source_domains = "ClickBait_Challange"
; target_domains = "ClickBait_Challange"
; optional_classes = ["good_actor", "bad_actor"]
; index_field = AccountPropertiesFeatureGenerator_author_screen_name
; #index_field = name
; results_file_name = Fake_News_Snopes_Dataset_Classifiers_results2.txt
; results_table_file_name = Fake_News_Snopes_Dataset_Classifiers_results2.csv
; path = data/output/expermintal_environment/
; backup_path = data\output\results\backup\
; is_rank_influential_features = False
; num_of_features_to_train = [5,10,20,'all']
; full_path_model_directory = data/output/expermintal_environment/Virtual_TV_Manually_Labeled_Accounts/
; #full_path_model_directory = data/output/expermintal_environment/Virtual_TV_Verified_Crowdturfers/
; #full_path_model_directory = data/output/expermintal_environment/Cyber_Security/
; #full_path_model_directory = data/output/expermintal_environment/Arabic_Honeypot/
; #prepared_classifier_name = Virtual_TV_Manually_Labeled_trained_classifier_RandomForest_10_features.pkl
; #prepared_classifier_name = Verified_Cowdturfers_trained_classifier_RandomForest_10_features.pkl
; #prepared_classifier_name = Cyber_Security_trained_classifier_RandomForest_10_features.pkl
; prepared_classifier_name = Virtual_TV_Manually_Labeled_10_Features_Trained_Classifier.pkl

; order_of_results_dictionary = ['targeted_class_field_name', 'similarity_functions', 'k', 'decision_models', 'link_prediction_models']
; column_names_for_results_table = ["Targeted_class", "Selected_classifier", "Num_of_features", "Correctly_classified",
; "Incorrectly_classified", "Total", "AUC", "Accuracy", "Precision", "Recall"
; ]
; replace_missing_values = 'zero'
; num_of_iterations = 5
; #trained_classifier
; trained_classifier_type_name = RandomForest
; trained_classifier_num_of_features = 10


; [TopicDistrobutionVisualizationGenerator]
; # If it is false you should insert a CSV file under prediction_csv_path
; read_predictions_from_db = False
; include_unlabeled_predictions = True
; include_labeled_authors_in_visualization = True
; targeted_class_field_name = author_type
; optional_classes = {'good_actor': 0, 'bad_actor': 1}
; font_path = "topic_distribution_visualization/Mukadimah.ttf"
; #prediction_csv_path = "data/output/topic_distribution_visualization/predictions.csv"
; prediction_csv_path = "data/output/expermintal_environment/predictions_on_unlabeled_authors_AccountPropertiesFeatureGenerator_author_type_RandomForest_10_features.csv"
; output_dir = "data/output/topic_distribution_visualization/"
; buckets = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]
; extend_posts_by_retweets = False


; [ClaimFeatureGenerator]
; ;features_list = ['claim_type', 'claim_id']
; features_list = ['claim_type']
; good_claim_type = ['TRUE', 'mostly-true']
; bad_claim_type = ['FALSE', 'mostly-false', 'Mostly False', 'pants-fire']


## Footprint Part
######Graph Builder##########
; [GraphBuilder_RetweetCascade]
; connection_type = retweet_cascade
; max_objects_without_saving = 30
; num_of_random_authors_for_graph = 20
; min_number_of_posts_per_author = None
; sample_top_followers_users = 30

######Footprint Feature generator##########
#### used for feature extraction from authors table
; [FootprintFeatureGenerator]
; features_list = ['avg_num_of_followers','std_dev_num_of_followers','min_num_of_followers', 'max_num_of_followers',
; 'avg_num_of_friends','std_dev_num_of_friends','min_num_of_friends', 'max_num_of_friends',
; 'avg_num_of_statuses','std_dev_num_of_statuses','min_num_of_statuses', 'max_num_of_statuses',
; 'avg_num_of_favorites','std_dev_num_of_favorites','min_num_of_favorites', 'max_num_of_favorites',
; 'avg_num_of_listed_count','std_dev_num_of_listed_count','min_num_of_listed_count', 'max_num_of_listed_count',
; 'avg_num_of_protected','std_dev_num_of_protected','min_num_of_protected', 'max_num_of_protected',
; 'avg_num_of_verified','std_dev_num_of_verified','min_num_of_verified', 'max_num_of_verified',
; 'avg_friends_followers_ratio','std_dev_friends_followers_ratio']


######Networkx Feature generator##########
#### used for 30 features extraction from author_friends and author_followers tables
;[NetworkxFeatureGenerator]
;table_names = ['author_friend','author_follower']
;features_list = ['betweenness_centrality','closeness_centrality','communicability_centrality',
;'load_centrality','eigenvector_centrality', 'katz_centrality',
;'degree', 'density', 'average_clustering'] 
				 

[TwitterApiRequester]
sleep_on_rate_limit = False
consumer_key = '<your data>'
consumer_secret = '<your data>'
access_token_key = '<your data>'
access_token_secret = '<your data>'
user_id = '<your data>'
screen_name = '<your data>'

[Twitter_Rest_Api]
#can be 1, 2, or 3
working_app_number = 2
maximal_get_friend_ids_requests_in_window = 15
maximal_get_follower_ids_requests_in_window = 15
maximal_get_user_requests_in_window = 180
maximal_user_ids_allowed_in_single_get_user_request = 100
num_of_requests_without_checking = 9999999999
num_of_twitter_status_id_requests_without_checking = 9999999999
num_of_twitter_timeline_requests_without_checking = 9999999999
maximal_number_of_retrieved_users = 1000
max_tweet_ids_allowed_in_single_get_tweets_by_tweet_ids_request = 100
max_num_of_tweet_ids_requests_without_checking = 900


